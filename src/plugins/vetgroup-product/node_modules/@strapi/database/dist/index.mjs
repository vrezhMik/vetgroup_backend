import path$1 from 'node:path';
import path from 'path';
import fse from 'fs-extra';
import createDebug from 'debug';
import _, { isNil, castArray, prop, omit, isInteger, snakeCase, partition, sumBy, cloneDeep, toString, toNumber, isString as isString$1, padCharsEnd, isArray, isPlainObject, isFinite, curry, groupBy, pipe, mapValues, map, isEmpty, maxBy, pick, has, uniqBy, isNull, compact, differenceWith, isEqual, difference, isObject, isNumber as isNumber$1, isUndefined, uniqWith } from 'lodash/fp';
import crypto from 'crypto';
import crypto$1 from 'node:crypto';
import * as dateFns from 'date-fns';
import { AsyncLocalStorage } from 'node:async_hooks';
import KnexBuilder from 'knex/lib/query/querybuilder';
import KnexRaw from 'knex/lib/raw';
import { isOperatorOfType, isOperator } from '@strapi/utils';
import { Readable } from 'stream';
import _$1 from 'lodash';
import { Umzug } from 'umzug';
import { createId } from '@paralleldrive/cuid2';
import { strict } from 'assert';
import knex from 'knex';

class Dialect {
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    configure(conn) {}
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    async initialize(_nativeConnection) {
    // noop
    }
    getTables() {
        throw new Error('getTables not implemented for this dialect');
    }
    getSqlType(type) {
        return type;
    }
    canAlterConstraints() {
        return true;
    }
    usesForeignKeys() {
        return false;
    }
    useReturning() {
        return false;
    }
    supportsUnsigned() {
        return false;
    }
    supportsOperator() {
        return true;
    }
    async startSchemaUpdate() {
    // noop
    }
    async endSchemaUpdate() {
    // noop
    }
    transformErrors(error) {
        if (error instanceof Error) {
            throw error;
        }
        throw new Error(error.message);
    }
    canAddIncrements() {
        return true;
    }
    constructor(db, client){
        this.schemaInspector = {};
        this.db = db;
        this.client = client;
    }
}

class DatabaseError extends Error {
    constructor(message = 'A database error occured', details = {}){
        super();
        this.name = 'DatabaseError';
        this.message = message;
        this.details = details;
    }
}

class NotNullError extends DatabaseError {
    constructor({ column = '' } = {}){
        super(`Not null constraint violation${column ? ` on column ${column}` : ''}.`);
        this.name = 'NotNullError';
        this.details = {
            column
        };
        this.stack = '';
    }
}

class InvalidTimeError extends DatabaseError {
    constructor(message = 'Invalid time format, expected HH:mm:ss.SSS'){
        super(message);
        this.name = 'InvalidTimeFormat';
    }
}

class InvalidDateError extends DatabaseError {
    constructor(message = 'Invalid date format, expected YYYY-MM-DD'){
        super(message);
        this.name = 'InvalidDateFormat';
    }
}

class InvalidDateTimeError extends DatabaseError {
    constructor(message = 'Invalid relation format'){
        super(message);
        this.name = 'InvalidDatetimeFormat';
    }
}

class InvalidRelationError extends DatabaseError {
    constructor(message = 'Invalid relation format'){
        super(message);
        this.name = 'InvalidRelationFormat';
    }
}

var index = /*#__PURE__*/Object.freeze({
  __proto__: null,
  DatabaseError: DatabaseError,
  InvalidDateError: InvalidDateError,
  InvalidDateTimeError: InvalidDateTimeError,
  InvalidRelationError: InvalidRelationError,
  InvalidTimeError: InvalidTimeError,
  NotNullError: NotNullError
});

const SQL_QUERIES$3 = {
    TABLE_LIST: /* sql */ `
    SELECT *
    FROM information_schema.tables
    WHERE
      table_schema = ?
      AND table_type = 'BASE TABLE'
      AND table_name != 'geometry_columns'
      AND table_name != 'spatial_ref_sys';
  `,
    LIST_COLUMNS: /* sql */ `
    SELECT data_type, column_name, character_maximum_length, column_default, is_nullable
    FROM information_schema.columns
    WHERE table_schema = ? AND table_name = ?;
  `,
    INDEX_LIST: /* sql */ `
    SELECT
      ix.indexrelid,
      i.relname as index_name,
      a.attname as column_name,
      ix.indisunique as is_unique,
      ix.indisprimary as is_primary
    FROM
      pg_class t,
      pg_namespace s,
      pg_class i,
      pg_index ix,
      pg_attribute a
    WHERE
      t.oid = ix.indrelid
      AND i.oid = ix.indexrelid
      AND a.attrelid = t.oid
      AND a.attnum = ANY(ix.indkey)
      AND t.relkind = 'r'
      AND t.relnamespace = s.oid
      AND s.nspname = ?
      AND t.relname = ?;
  `,
    FOREIGN_KEY_LIST: /* sql */ `
    SELECT
      tco."constraint_name" as constraint_name
    FROM information_schema.table_constraints tco
    WHERE
      tco.constraint_type = 'FOREIGN KEY'
      AND tco.constraint_schema = ?
      AND tco.table_name = ?
  `,
    FOREIGN_KEY_REFERENCES: /* sql */ `
    SELECT
      kcu."constraint_name" as constraint_name,
      kcu."column_name" as column_name

    FROM information_schema.key_column_usage kcu
    WHERE kcu.constraint_name=ANY(?)
    AND kcu.table_schema = ?
    AND kcu.table_name = ?;
  `,
    FOREIGN_KEY_REFERENCES_CONSTRAIN: /* sql */ `
  SELECT
  rco.update_rule as on_update,
  rco.delete_rule as on_delete,
  rco."unique_constraint_name" as unique_constraint_name
  FROM information_schema.referential_constraints rco
  WHERE rco.constraint_name=ANY(?)
  AND rco.constraint_schema = ?
`,
    FOREIGN_KEY_REFERENCES_CONSTRAIN_RFERENCE: /* sql */ `
  SELECT
  rel_kcu."table_name" as foreign_table,
  rel_kcu."column_name" as fk_column_name
    FROM information_schema.key_column_usage rel_kcu
    WHERE rel_kcu.constraint_name=?
    AND rel_kcu.table_schema = ?
`
};
const toStrapiType$2 = (column)=>{
    const rootType = column.data_type.toLowerCase().match(/[^(), ]+/)?.[0];
    switch(rootType){
        case 'integer':
            {
                // find a way to figure out the increments
                return {
                    type: 'integer'
                };
            }
        case 'text':
            {
                return {
                    type: 'text',
                    args: [
                        'longtext'
                    ]
                };
            }
        case 'boolean':
            {
                return {
                    type: 'boolean'
                };
            }
        case 'character':
            {
                return {
                    type: 'string',
                    args: [
                        column.character_maximum_length
                    ]
                };
            }
        case 'timestamp':
            {
                return {
                    type: 'datetime',
                    args: [
                        {
                            useTz: false,
                            precision: 6
                        }
                    ]
                };
            }
        case 'date':
            {
                return {
                    type: 'date'
                };
            }
        case 'time':
            {
                return {
                    type: 'time',
                    args: [
                        {
                            precision: 3
                        }
                    ]
                };
            }
        case 'numeric':
            {
                return {
                    type: 'decimal',
                    args: [
                        10,
                        2
                    ]
                };
            }
        case 'real':
        case 'double':
            {
                return {
                    type: 'double'
                };
            }
        case 'bigint':
            {
                return {
                    type: 'bigInteger'
                };
            }
        case 'jsonb':
            {
                return {
                    type: 'jsonb'
                };
            }
        default:
            {
                return {
                    type: 'specificType',
                    args: [
                        column.data_type
                    ]
                };
            }
    }
};
const getIndexType = (index)=>{
    if (index.is_primary) {
        return 'primary';
    }
    if (index.is_unique) {
        return 'unique';
    }
};
class PostgresqlSchemaInspector {
    async getSchema() {
        const schema = {
            tables: []
        };
        const tables = await this.getTables();
        schema.tables = await Promise.all(tables.map(async (tableName)=>{
            const columns = await this.getColumns(tableName);
            const indexes = await this.getIndexes(tableName);
            const foreignKeys = await this.getForeignKeys(tableName);
            return {
                name: tableName,
                columns,
                indexes,
                foreignKeys
            };
        }));
        return schema;
    }
    getDatabaseSchema() {
        return this.db.getSchemaName() || 'public';
    }
    async getTables() {
        const { rows } = await this.db.connection.raw(SQL_QUERIES$3.TABLE_LIST, [
            this.getDatabaseSchema()
        ]);
        return rows.map((row)=>row.table_name);
    }
    async getColumns(tableName) {
        const { rows } = await this.db.connection.raw(SQL_QUERIES$3.LIST_COLUMNS, [
            this.getDatabaseSchema(),
            tableName
        ]);
        return rows.map((row)=>{
            const { type, args = [], ...rest } = toStrapiType$2(row);
            const defaultTo = row.column_default && row.column_default.includes('nextval(') ? null : row.column_default;
            return {
                type,
                args,
                defaultTo,
                name: row.column_name,
                notNullable: row.is_nullable === 'NO',
                unsigned: false,
                ...rest
            };
        });
    }
    async getIndexes(tableName) {
        const { rows } = await this.db.connection.raw(SQL_QUERIES$3.INDEX_LIST, [
            this.getDatabaseSchema(),
            tableName
        ]);
        const ret = {};
        for (const index of rows){
            if (index.column_name === 'id') {
                continue;
            }
            if (!ret[index.indexrelid]) {
                ret[index.indexrelid] = {
                    columns: [
                        index.column_name
                    ],
                    name: index.index_name,
                    type: getIndexType(index)
                };
            } else {
                ret[index.indexrelid].columns.push(index.column_name);
            }
        }
        return Object.values(ret);
    }
    async getForeignKeys(tableName) {
        const { rows } = await this.db.connection.raw(SQL_QUERIES$3.FOREIGN_KEY_LIST, [
            this.getDatabaseSchema(),
            tableName
        ]);
        const ret = {};
        for (const fk of rows){
            ret[fk.constraint_name] = {
                name: fk.constraint_name,
                columns: [],
                referencedColumns: [],
                referencedTable: null,
                onUpdate: null,
                onDelete: null
            };
        }
        const constraintNames = Object.keys(ret);
        const dbSchema = this.getDatabaseSchema();
        if (constraintNames.length > 0) {
            const { rows: fkReferences } = await this.db.connection.raw(SQL_QUERIES$3.FOREIGN_KEY_REFERENCES, [
                [
                    constraintNames
                ],
                dbSchema,
                tableName
            ]);
            for (const fkReference of fkReferences){
                ret[fkReference.constraint_name].columns.push(fkReference.column_name);
                const { rows: fkReferencesConstraint } = await this.db.connection.raw(SQL_QUERIES$3.FOREIGN_KEY_REFERENCES_CONSTRAIN, [
                    [
                        fkReference.constraint_name
                    ],
                    dbSchema
                ]);
                for (const fkReferenceC of fkReferencesConstraint){
                    const { rows: fkReferencesConstraintReferece } = await this.db.connection.raw(SQL_QUERIES$3.FOREIGN_KEY_REFERENCES_CONSTRAIN_RFERENCE, [
                        fkReferenceC.unique_constraint_name,
                        dbSchema
                    ]);
                    for (const fkReferenceConst of fkReferencesConstraintReferece){
                        ret[fkReference.constraint_name].referencedTable = fkReferenceConst.foreign_table;
                        ret[fkReference.constraint_name].referencedColumns.push(fkReferenceConst.fk_column_name);
                    }
                    ret[fkReference.constraint_name].onUpdate = fkReferenceC.on_update.toUpperCase();
                    ret[fkReference.constraint_name].onDelete = fkReferenceC.on_delete.toUpperCase();
                }
            }
        }
        return Object.values(ret);
    }
    constructor(db){
        this.db = db;
    }
}

class PostgresDialect extends Dialect {
    useReturning() {
        return true;
    }
    async initialize(nativeConnection) {
        // Don't cast DATE string to Date()
        this.db.connection.client.driver.types.setTypeParser(this.db.connection.client.driver.types.builtins.DATE, 'text', (v)=>v);
        // Don't parse JSONB automatically
        this.db.connection.client.driver.types.setTypeParser(this.db.connection.client.driver.types.builtins.JSONB, 'text', (v)=>v);
        this.db.connection.client.driver.types.setTypeParser(this.db.connection.client.driver.types.builtins.NUMERIC, 'text', parseFloat);
        // If we're using a schema, set the default path for all table names in queries to use that schema
        // Ideally we would rely on Knex config.searchPath to do this for us
        // However, createConnection must remain synchronous and if the user is using a connection function,
        // we do not know what their schema is until after the connection is resolved
        const schemaName = this.db.getSchemaName();
        if (schemaName) {
            await this.db.connection.raw(`SET search_path TO "${schemaName}"`).connection(nativeConnection);
        }
    }
    usesForeignKeys() {
        return true;
    }
    getSqlType(type) {
        switch(type){
            case 'timestamp':
                {
                    return 'datetime';
                }
            default:
                {
                    return type;
                }
        }
    }
    transformErrors(error) {
        switch(error.code){
            case '23502':
                {
                    throw new NotNullError({
                        column: 'column' in error ? `${error.column}` : undefined
                    });
                }
            default:
                {
                    super.transformErrors(error);
                }
        }
    }
    constructor(db){
        super(db, 'postgres');
        this.schemaInspector = new PostgresqlSchemaInspector(db);
    }
}

const SQL_QUERIES$2 = {
    TABLE_LIST: /* sql */ `
    SELECT
      t.table_name as table_name
    FROM information_schema.tables t
    WHERE table_type = 'BASE TABLE'
    AND table_schema = schema();
  `,
    LIST_COLUMNS: /* sql */ `
    SELECT
      c.data_type as data_type,
      c.column_name as column_name,
      c.character_maximum_length as character_maximum_length,
      c.column_default as column_default,
      c.is_nullable as is_nullable,
      c.column_type as column_type,
      c.column_key as column_key
    FROM information_schema.columns c
    WHERE table_schema = database()
    AND table_name = ?;
  `,
    INDEX_LIST: /* sql */ `
    show index from ??;
  `,
    FOREIGN_KEY_LIST: /* sql */ `
    SELECT
      tc.constraint_name as constraint_name
    FROM information_schema.table_constraints tc
    WHERE tc.constraint_type = 'FOREIGN KEY'
    AND tc.table_schema = database()
    AND tc.table_name = ?;
  `,
    FOREIGN_KEY_REFERENCES: /* sql */ `
    SELECT
      kcu.constraint_name as constraint_name,
      kcu.column_name as column_name,
      kcu.referenced_table_name as referenced_table_name,
      kcu.referenced_column_name as referenced_column_name
    FROM information_schema.key_column_usage kcu
    WHERE kcu.constraint_name in (?)
    AND kcu.table_schema = database()
    AND kcu.table_name = ?;
  `,
    FOREIGN_KEY_REFERENTIALS_CONSTRAINTS: /* sql */ `
    SELECT
      rc.constraint_name as constraint_name,
      rc.update_rule as on_update,
      rc.delete_rule as on_delete
    FROM information_schema.referential_constraints AS rc
    WHERE rc.constraint_name in (?)
    AND rc.constraint_schema = database()
    AND rc.table_name = ?;
  `
};
const toStrapiType$1 = (column)=>{
    const rootType = column.data_type.toLowerCase().match(/[^(), ]+/)?.[0];
    switch(rootType){
        case 'int':
            {
                if (column.column_key === 'PRI') {
                    return {
                        type: 'increments',
                        args: [
                            {
                                primary: true,
                                primaryKey: true
                            }
                        ],
                        unsigned: false
                    };
                }
                return {
                    type: 'integer'
                };
            }
        case 'decimal':
            {
                return {
                    type: 'decimal',
                    args: [
                        10,
                        2
                    ]
                };
            }
        case 'double':
            {
                return {
                    type: 'double'
                };
            }
        case 'bigint':
            {
                return {
                    type: 'bigInteger'
                };
            }
        case 'enum':
            {
                return {
                    type: 'string'
                };
            }
        case 'tinyint':
            {
                return {
                    type: 'boolean'
                };
            }
        case 'longtext':
            {
                return {
                    type: 'text',
                    args: [
                        'longtext'
                    ]
                };
            }
        case 'varchar':
            {
                return {
                    type: 'string',
                    args: [
                        column.character_maximum_length
                    ]
                };
            }
        case 'datetime':
            {
                return {
                    type: 'datetime',
                    args: [
                        {
                            useTz: false,
                            precision: 6
                        }
                    ]
                };
            }
        case 'date':
            {
                return {
                    type: 'date'
                };
            }
        case 'time':
            {
                return {
                    type: 'time',
                    args: [
                        {
                            precision: 3
                        }
                    ]
                };
            }
        case 'timestamp':
            {
                return {
                    type: 'timestamp',
                    args: [
                        {
                            useTz: false,
                            precision: 6
                        }
                    ]
                };
            }
        case 'json':
            {
                return {
                    type: 'jsonb'
                };
            }
        default:
            {
                return {
                    type: 'specificType',
                    args: [
                        column.data_type
                    ]
                };
            }
    }
};
class MysqlSchemaInspector {
    async getSchema() {
        const schema = {
            tables: []
        };
        const tables = await this.getTables();
        schema.tables = await Promise.all(tables.map(async (tableName)=>{
            const columns = await this.getColumns(tableName);
            const indexes = await this.getIndexes(tableName);
            const foreignKeys = await this.getForeignKeys(tableName);
            return {
                name: tableName,
                columns,
                indexes,
                foreignKeys
            };
        }));
        return schema;
    }
    async getTables() {
        const [rows] = await this.db.connection.raw(SQL_QUERIES$2.TABLE_LIST);
        return rows.map((row)=>row.table_name);
    }
    async getColumns(tableName) {
        const [rows] = await this.db.connection.raw(SQL_QUERIES$2.LIST_COLUMNS, [
            tableName
        ]);
        return rows.map((row)=>{
            const { type, args = [], ...rest } = toStrapiType$1(row);
            return {
                type,
                args,
                defaultTo: row.column_default,
                name: row.column_name,
                notNullable: row.is_nullable === 'NO',
                unsigned: row.column_type.endsWith(' unsigned'),
                ...rest
            };
        });
    }
    async getIndexes(tableName) {
        const [rows] = await this.db.connection.raw(SQL_QUERIES$2.INDEX_LIST, [
            tableName
        ]);
        const ret = {};
        for (const index of rows){
            if (index.Column_name === 'id') {
                continue;
            }
            if (!ret[index.Key_name]) {
                const indexInfo = {
                    columns: [
                        index.Column_name
                    ],
                    name: index.Key_name
                };
                if (!index.Non_unique || index.Non_unique === '0') {
                    indexInfo.type = 'unique';
                }
                ret[index.Key_name] = indexInfo;
            } else {
                ret[index.Key_name].columns.push(index.Column_name);
            }
        }
        return Object.values(ret);
    }
    async getForeignKeys(tableName) {
        const [rows] = await this.db.connection.raw(SQL_QUERIES$2.FOREIGN_KEY_LIST, [
            tableName
        ]);
        const ret = {};
        for (const fk of rows){
            ret[fk.constraint_name] = {
                name: fk.constraint_name,
                columns: [],
                referencedColumns: [],
                referencedTable: null,
                onUpdate: null,
                onDelete: null
            };
        }
        const contraintNames = Object.keys(ret);
        if (contraintNames.length > 0) {
            const [fkReferences] = await this.db.connection.raw(SQL_QUERIES$2.FOREIGN_KEY_REFERENCES, [
                contraintNames,
                tableName
            ]);
            for (const fkReference of fkReferences){
                ret[fkReference.constraint_name].referencedTable = fkReference.referenced_table_name;
                ret[fkReference.constraint_name].columns.push(fkReference.column_name);
                ret[fkReference.constraint_name].referencedColumns.push(fkReference.referenced_column_name);
            }
            const [fkReferentialConstraints] = await this.db.connection.raw(SQL_QUERIES$2.FOREIGN_KEY_REFERENTIALS_CONSTRAINTS, [
                contraintNames,
                tableName
            ]);
            for (const fkReferentialConstraint of fkReferentialConstraints){
                ret[fkReferentialConstraint.constraint_name].onUpdate = fkReferentialConstraint.on_update.toUpperCase();
                ret[fkReferentialConstraint.constraint_name].onDelete = fkReferentialConstraint.on_delete.toUpperCase();
            }
        }
        return Object.values(ret);
    }
    constructor(db){
        this.db = db;
    }
}

const MYSQL = 'MYSQL';
const MARIADB = 'MARIADB';

const SQL_QUERIES$1 = {
    VERSION: `SELECT version() as version`
};
class MysqlDatabaseInspector {
    async getInformation(nativeConnection) {
        let database;
        let versionNumber;
        try {
            const [results] = await this.db.connection.raw(SQL_QUERIES$1.VERSION).connection(nativeConnection);
            const versionSplit = results[0].version.split('-');
            const databaseName = versionSplit[1];
            versionNumber = versionSplit[0];
            database = databaseName && databaseName.toLowerCase() === 'mariadb' ? MARIADB : MYSQL;
        } catch (e) {
            return {
                database: null,
                version: null
            };
        }
        return {
            database,
            version: versionNumber
        };
    }
    constructor(db){
        this.db = db;
    }
}

class MysqlDialect extends Dialect {
    configure() {
        const connection = this.db.config.connection.connection;
        connection.supportBigNumbers = true;
        // Only allow bigNumberStrings option set to be true if no connection option passed
        // Otherwise bigNumberStrings option should be allowed to used from DB config
        if (connection.bigNumberStrings === undefined) {
            connection.bigNumberStrings = true;
        }
        connection.typeCast = (field, next)=>{
            if (field.type === 'DECIMAL' || field.type === 'NEWDECIMAL') {
                const value = field.string();
                return value === null ? null : Number(value);
            }
            if (field.type === 'TINY' && field.length === 1) {
                const value = field.string();
                return value ? value === '1' : null;
            }
            if (field.type === 'DATE') {
                return field.string();
            }
            return next();
        };
    }
    async initialize(nativeConnection) {
        try {
            await this.db.connection.raw(`set session sql_require_primary_key = 0;`).connection(nativeConnection);
        } catch (err) {
        // Ignore error due to lack of session permissions
        }
        // We only need to get info on the first connection in the pool
        /**
     * Note: There is a race condition here where if two connections are opened at the same time, both will retrieve
     * db info, but it doesn't cause issues, it's just one wasted query one time, so we can safely leave it to avoid
     * adding extra complexity
     * */ if (!this.info) {
            this.info = await this.databaseInspector.getInformation(nativeConnection);
        }
    }
    async startSchemaUpdate() {
        try {
            await this.db.connection.raw(`set foreign_key_checks = 0;`);
            await this.db.connection.raw(`set session sql_require_primary_key = 0;`);
        } catch (err) {
        // Ignore error due to lack of session permissions
        }
    }
    async endSchemaUpdate() {
        await this.db.connection.raw(`set foreign_key_checks = 1;`);
    }
    supportsUnsigned() {
        return true;
    }
    usesForeignKeys() {
        return true;
    }
    transformErrors(error) {
        super.transformErrors(error);
    }
    constructor(db){
        super(db, 'mysql');
        this.info = null;
        this.schemaInspector = new MysqlSchemaInspector(db);
        this.databaseInspector = new MysqlDatabaseInspector(db);
    }
}

const SQL_QUERIES = {
    TABLE_LIST: `select name from sqlite_master where type = 'table' and name NOT LIKE 'sqlite%'`,
    TABLE_INFO: `pragma table_info(??)`,
    INDEX_LIST: 'pragma index_list(??)',
    INDEX_INFO: 'pragma index_info(??)',
    FOREIGN_KEY_LIST: 'pragma foreign_key_list(??)'
};
const toStrapiType = (column)=>{
    const { type } = column;
    const rootType = type.toLowerCase().match(/[^(), ]+/)?.[0];
    switch(rootType){
        case 'integer':
            {
                if (column.pk) {
                    return {
                        type: 'increments',
                        args: [
                            {
                                primary: true,
                                primaryKey: true
                            }
                        ]
                    };
                }
                return {
                    type: 'integer'
                };
            }
        case 'float':
            {
                return {
                    type: 'float',
                    args: [
                        10,
                        2
                    ]
                };
            }
        case 'bigint':
            {
                return {
                    type: 'bigInteger'
                };
            }
        case 'varchar':
            {
                const length = type.slice(8, type.length - 1);
                return {
                    type: 'string',
                    args: [
                        Number(length)
                    ]
                };
            }
        case 'text':
            {
                return {
                    type: 'text',
                    args: [
                        'longtext'
                    ]
                };
            }
        case 'json':
            {
                return {
                    type: 'jsonb'
                };
            }
        case 'boolean':
            {
                return {
                    type: 'boolean'
                };
            }
        case 'datetime':
            {
                return {
                    type: 'datetime',
                    args: [
                        {
                            useTz: false,
                            precision: 6
                        }
                    ]
                };
            }
        case 'date':
            {
                return {
                    type: 'date'
                };
            }
        case 'time':
            {
                return {
                    type: 'time',
                    args: [
                        {
                            precision: 3
                        }
                    ]
                };
            }
        default:
            {
                return {
                    type: 'specificType',
                    args: [
                        column.data_type
                    ]
                };
            }
    }
};
class SqliteSchemaInspector {
    async getSchema() {
        const schema = {
            tables: []
        };
        const tables = await this.getTables();
        for (const tableName of tables){
            const columns = await this.getColumns(tableName);
            const indexes = await this.getIndexes(tableName);
            const foreignKeys = await this.getForeignKeys(tableName);
            schema.tables.push({
                name: tableName,
                columns,
                indexes,
                foreignKeys
            });
        }
        return schema;
    }
    async getTables() {
        const rows = await this.db.connection.raw(SQL_QUERIES.TABLE_LIST);
        return rows.map((row)=>row.name);
    }
    async getColumns(tableName) {
        const rows = await this.db.connection.raw(SQL_QUERIES.TABLE_INFO, [
            tableName
        ]);
        return rows.map((row)=>{
            const { type, args = [], ...rest } = toStrapiType(row);
            return {
                type,
                args,
                name: row.name,
                defaultTo: row.dflt_value,
                notNullable: row.notnull !== null ? Boolean(row.notnull) : null,
                unsigned: false,
                ...rest
            };
        });
    }
    async getIndexes(tableName) {
        const indexes = await this.db.connection.raw(SQL_QUERIES.INDEX_LIST, [
            tableName
        ]);
        const ret = [];
        for (const index of indexes.filter((index)=>!index.name.startsWith('sqlite_'))){
            const res = await this.db.connection.raw(SQL_QUERIES.INDEX_INFO, [
                index.name
            ]);
            const indexInfo = {
                columns: res.map((row)=>row.name),
                name: index.name
            };
            if (index.unique) {
                indexInfo.type = 'unique';
            }
            ret.push(indexInfo);
        }
        return ret;
    }
    async getForeignKeys(tableName) {
        const fks = await this.db.connection.raw(SQL_QUERIES.FOREIGN_KEY_LIST, [
            tableName
        ]);
        const ret = {};
        for (const fk of fks){
            if (!ret[fk.id]) {
                ret[fk.id] = {
                    // TODO: name, //  find name
                    name: '',
                    columns: [
                        fk.from
                    ],
                    referencedColumns: [
                        fk.to
                    ],
                    referencedTable: fk.table,
                    onUpdate: fk.on_update.toUpperCase(),
                    onDelete: fk.on_delete.toUpperCase()
                };
            } else {
                ret[fk.id].columns.push(fk.from);
                ret[fk.id].referencedColumns.push(fk.to);
            }
        }
        return Object.values(ret);
    }
    constructor(db){
        this.db = db;
    }
}

const UNSUPPORTED_OPERATORS = [
    '$jsonSupersetOf'
];
class SqliteDialect extends Dialect {
    configure(conn) {
        const connection = conn || this.db.config.connection.connection;
        if (typeof connection !== 'string') {
            connection.filename = path.resolve(connection.filename);
        }
        const dbDir = path.dirname(connection.filename);
        fse.ensureDirSync(dbDir);
    }
    useReturning() {
        return true;
    }
    async initialize(nativeConnection) {
        await this.db.connection.raw('pragma foreign_keys = on').connection(nativeConnection);
    }
    canAlterConstraints() {
        return false;
    }
    getSqlType(type) {
        switch(type){
            case 'enum':
                {
                    return 'text';
                }
            case 'double':
            case 'decimal':
                {
                    return 'float';
                }
            case 'timestamp':
                {
                    return 'datetime';
                }
            default:
                {
                    return type;
                }
        }
    }
    supportsOperator(operator) {
        return !UNSUPPORTED_OPERATORS.includes(operator);
    }
    async startSchemaUpdate() {
        await this.db.connection.raw(`pragma foreign_keys = off`);
    }
    async endSchemaUpdate() {
        await this.db.connection.raw(`pragma foreign_keys = on`);
    }
    transformErrors(error) {
        switch(error.errno){
            case 19:
                {
                    throw new NotNullError(); // TODO: extract column name
                }
            default:
                {
                    super.transformErrors(error);
                }
        }
    }
    canAddIncrements() {
        return false;
    }
    constructor(db){
        super(db, 'sqlite');
        this.schemaInspector = new SqliteSchemaInspector(db);
    }
}

/**
 * Require our dialect-specific code
 */ const getDialectClass = (client)=>{
    switch(client){
        case 'postgres':
            return PostgresDialect;
        case 'mysql':
            return MysqlDialect;
        case 'sqlite':
            return SqliteDialect;
        default:
            throw new Error(`Unknown dialect ${client}`);
    }
};
/**
 * Get the dialect of a database client
 */ const getDialectName = (client)=>{
    switch(client){
        case 'postgres':
            return 'postgres';
        case 'mysql':
            return 'mysql';
        case 'sqlite':
            return 'sqlite';
        default:
            throw new Error(`Unknown dialect ${client}`);
    }
};
const getDialect = (db)=>{
    const { client } = db.config.connection;
    const dialectName = getDialectName(client);
    const constructor = getDialectClass(dialectName);
    const dialect = new constructor(db, dialectName);
    return dialect;
};

const debug$2 = createDebug('strapi::database');
var createSchemaBuilder = ((db)=>{
    const helpers = createHelpers(db);
    return {
        /**
     * Returns a knex schema builder instance
     * @param {string} table - table name
     */ getSchemaBuilder (trx) {
            return db.getSchemaConnection(trx);
        },
        /**
     * Creates schema in DB
     */ async createSchema (schema) {
            await db.connection.transaction(async (trx)=>{
                await this.createTables(schema.tables, trx);
            });
        },
        /**
     * Creates a list of tables in a schema
     * @param {KnexInstance} trx
     * @param {Table[]} tables
     */ async createTables (tables, trx) {
            for (const table of tables){
                debug$2(`Creating table: ${table.name}`);
                const schemaBuilder = this.getSchemaBuilder(trx);
                await helpers.createTable(schemaBuilder, table);
            }
            // create FKs once all the tables exist
            for (const table of tables){
                debug$2(`Creating table foreign keys: ${table.name}`);
                const schemaBuilder = this.getSchemaBuilder(trx);
                await helpers.createTableForeignKeys(schemaBuilder, table);
            }
        },
        /**
     * Drops schema from DB
     */ async dropSchema (schema, { dropDatabase = false } = {}) {
            if (dropDatabase) {
                // TODO: drop database & return as it will drop everything
                return;
            }
            await db.connection.transaction(async (trx)=>{
                for (const table of schema.tables.reverse()){
                    const schemaBuilder = this.getSchemaBuilder(trx);
                    await helpers.dropTable(schemaBuilder, table);
                }
            });
        },
        /**
     * Applies a schema diff update in the DB
     * @param {*} schemaDiff
     */ // TODO: implement force option to disable removal in DB
        async updateSchema (schemaDiff) {
            const forceMigration = db.config.settings?.forceMigration;
            await db.dialect.startSchemaUpdate();
            // Pre-fetch metadata for all updated tables
            const existingMetadata = {};
            for (const table of schemaDiff.tables.updated){
                existingMetadata[table.name] = {
                    indexes: await db.dialect.schemaInspector.getIndexes(table.name),
                    foreignKeys: await db.dialect.schemaInspector.getForeignKeys(table.name)
                };
            }
            await db.connection.transaction(async (trx)=>{
                await this.createTables(schemaDiff.tables.added, trx);
                if (forceMigration) {
                    // drop all delete table foreign keys then delete the tables
                    for (const table of schemaDiff.tables.removed){
                        debug$2(`Removing table foreign keys: ${table.name}`);
                        const schemaBuilder = this.getSchemaBuilder(trx);
                        await helpers.dropTableForeignKeys(schemaBuilder, table);
                    }
                    for (const table of schemaDiff.tables.removed){
                        debug$2(`Removing table: ${table.name}`);
                        const schemaBuilder = this.getSchemaBuilder(trx);
                        await helpers.dropTable(schemaBuilder, table);
                    }
                }
                for (const table of schemaDiff.tables.updated){
                    debug$2(`Updating table: ${table.name}`);
                    // alter table
                    const schemaBuilder = this.getSchemaBuilder(trx);
                    const { indexes, foreignKeys } = existingMetadata[table.name];
                    await helpers.alterTable(schemaBuilder, table, {
                        indexes,
                        foreignKeys
                    });
                }
            });
            await db.dialect.endSchemaUpdate();
        }
    };
});
const createHelpers = (db)=>{
    /**
   *  Creates a foreign key on a table
   */ const createForeignKey = (tableBuilder, foreignKey)=>{
        const { name, columns, referencedColumns, referencedTable, onDelete, onUpdate } = foreignKey;
        const constraint = tableBuilder.foreign(columns, name).references(referencedColumns).inTable(db.getSchemaName() ? `${db.getSchemaName()}.${referencedTable}` : referencedTable);
        if (onDelete) {
            constraint.onDelete(onDelete);
        }
        if (onUpdate) {
            constraint.onUpdate(onUpdate);
        }
    };
    /**
   * Drops a foreign key from a table
   */ const dropForeignKey = (tableBuilder, foreignKey, existingForeignKeys)=>{
        const { name, columns } = foreignKey;
        // Check if the index exists in existingIndexes, and return early if it doesn't
        if (existingForeignKeys && !existingForeignKeys.some((existingIndex)=>existingIndex?.name === name)) {
            debug$2(`Foreign Key ${name} not found in existing foreign keys. Skipping drop.`);
            return;
        }
        tableBuilder.dropForeign(columns, name);
    };
    /**
   * Creates an index on a table
   */ const createIndex = (tableBuilder, index)=>{
        const { type, columns, name } = index;
        switch(type){
            case 'primary':
                {
                    return tableBuilder.primary(columns, {
                        constraintName: name
                    });
                }
            case 'unique':
                {
                    return tableBuilder.unique(columns, {
                        indexName: name
                    });
                }
            default:
                {
                    return tableBuilder.index(columns, name, type);
                }
        }
    };
    /**
   * Drops an index from table
   * @param {Knex.TableBuilder} tableBuilder
   * @param {Index} index
   */ const dropIndex = (tableBuilder, index, existingIndexes)=>{
        if (!db.config.settings?.forceMigration) {
            return;
        }
        const { type, columns, name } = index;
        // Check if the index exists in existingIndexes, and return early if it doesn't
        if (existingIndexes && !existingIndexes.some((existingIndex)=>existingIndex?.name === name)) {
            debug$2(`Index ${index.name} not found in existingIndexes. Skipping drop.`);
            return;
        }
        switch(type){
            case 'primary':
                {
                    return tableBuilder.dropPrimary(name);
                }
            case 'unique':
                {
                    return tableBuilder.dropUnique(columns, name);
                }
            default:
                {
                    return tableBuilder.dropIndex(columns, name);
                }
        }
    };
    /**
   * Creates a column in a table
   */ const createColumn = (tableBuilder, column)=>{
        const { type, name, args = [], defaultTo, unsigned, notNullable } = column;
        const col = tableBuilder[type](name, ...args);
        if (unsigned === true) {
            col.unsigned();
        }
        if (!isNil(defaultTo)) {
            const [value, opts] = castArray(defaultTo);
            if (prop('isRaw', opts)) {
                col.defaultTo(db.connection.raw(value), omit('isRaw', opts));
            } else {
                col.defaultTo(value, opts);
            }
        }
        if (notNullable === true) {
            col.notNullable();
        } else {
            col.nullable();
        }
        return col;
    };
    /**
   * Drops a column from a table
   */ const dropColumn = (tableBuilder, column)=>{
        if (!db.config.settings?.forceMigration) {
            return;
        }
        return tableBuilder.dropColumn(column.name);
    };
    /**
   * Creates a table in a database
   */ const createTable = async (schemaBuilder, table)=>{
        await schemaBuilder.createTable(table.name, (tableBuilder)=>{
            // columns
            (table.columns || []).forEach((column)=>createColumn(tableBuilder, column));
            // indexes
            (table.indexes || []).forEach((index)=>createIndex(tableBuilder, index));
            // foreign keys
            if (!db.dialect.canAlterConstraints()) {
                (table.foreignKeys || []).forEach((foreignKey)=>createForeignKey(tableBuilder, foreignKey));
            }
        });
    };
    /**
   * Alters a database table by applying a set of schema changes including updates to columns, indexes, and foreign keys.
   * This function ensures proper ordering of operations to avoid conflicts (e.g., foreign key errors) and handles
   * MySQL-specific quirks where dropping a foreign key can implicitly drop an associated index.
   *
   * @param {Knex.SchemaBuilder} schemaBuilder - Knex SchemaBuilder instance to perform schema operations.
   * @param {TableDiff['diff']} table - A diff object representing the schema changes to be applied to the table.
   * @param {{ indexes: Index[]; foreignKeys: ForeignKey[] }} existingMetadata - Metadata about existing indexes and
   *   foreign keys in the table. Used to ensure safe operations and avoid unnecessary modifications.
   *   - indexes: Array of existing index definitions.
   *   - foreignKeys: Array of existing foreign key definitions.
   */ const alterTable = async (schemaBuilder, table, existingMetadata = {
        indexes: [],
        foreignKeys: []
    })=>{
        let existingIndexes = [
            ...existingMetadata.indexes
        ];
        const existingForeignKeys = [
            ...existingMetadata.foreignKeys
        ];
        // Track dropped foreign keys
        const droppedForeignKeyNames = [];
        await schemaBuilder.alterTable(table.name, async (tableBuilder)=>{
            // Drop foreign keys first to avoid foreign key errors in the following steps
            for (const removedForeignKey of table.foreignKeys.removed){
                debug$2(`Dropping foreign key ${removedForeignKey.name} on ${table.name}`);
                dropForeignKey(tableBuilder, removedForeignKey, existingForeignKeys);
                droppedForeignKeyNames.push(removedForeignKey.name);
            }
            for (const updatedForeignKey of table.foreignKeys.updated){
                debug$2(`Dropping updated foreign key ${updatedForeignKey.name} on ${table.name}`);
                dropForeignKey(tableBuilder, updatedForeignKey.object, existingForeignKeys);
                droppedForeignKeyNames.push(updatedForeignKey.object.name);
            }
            // In MySQL, dropping a foreign key can also implicitly drop an index with the same name
            // Remove dropped foreign keys from existingIndexes for MySQL
            if (db.config.connection.client === 'mysql') {
                existingIndexes = existingIndexes.filter((index)=>!droppedForeignKeyNames.includes(index.name));
            }
            for (const removedIndex of table.indexes.removed){
                debug$2(`Dropping index ${removedIndex.name} on ${table.name}`);
                dropIndex(tableBuilder, removedIndex, existingIndexes);
            }
            for (const updatedIndex of table.indexes.updated){
                debug$2(`Dropping updated index ${updatedIndex.name} on ${table.name}`);
                dropIndex(tableBuilder, updatedIndex.object, existingIndexes);
            }
            // Drop columns after FKs have been removed to avoid FK errors
            for (const removedColumn of table.columns.removed){
                debug$2(`Dropping column ${removedColumn.name} on ${table.name}`);
                dropColumn(tableBuilder, removedColumn);
            }
            // Update existing columns
            for (const updatedColumn of table.columns.updated){
                debug$2(`Updating column ${updatedColumn.name} on ${table.name}`);
                const { object } = updatedColumn;
                if (object.type === 'increments') {
                    createColumn(tableBuilder, {
                        ...object,
                        type: 'integer'
                    }).alter();
                } else {
                    createColumn(tableBuilder, object).alter();
                }
            }
            // Add any new columns
            for (const addedColumn of table.columns.added){
                debug$2(`Creating column ${addedColumn.name} on ${table.name}`);
                if (addedColumn.type === 'increments' && !db.dialect.canAddIncrements()) {
                    tableBuilder.integer(addedColumn.name).unsigned();
                    tableBuilder.primary([
                        addedColumn.name
                    ]);
                } else {
                    createColumn(tableBuilder, addedColumn);
                }
            }
            // once the columns have all been updated, we can create indexes again
            for (const updatedForeignKey of table.foreignKeys.updated){
                debug$2(`Recreating updated foreign key ${updatedForeignKey.name} on ${table.name}`);
                createForeignKey(tableBuilder, updatedForeignKey.object);
            }
            for (const updatedIndex of table.indexes.updated){
                debug$2(`Recreating updated index ${updatedIndex.name} on ${table.name}`);
                createIndex(tableBuilder, updatedIndex.object);
            }
            for (const addedForeignKey of table.foreignKeys.added){
                debug$2(`Creating foreign key ${addedForeignKey.name} on ${table.name}`);
                createForeignKey(tableBuilder, addedForeignKey);
            }
            for (const addedIndex of table.indexes.added){
                debug$2(`Creating index ${addedIndex.name} on ${table.name}`);
                createIndex(tableBuilder, addedIndex);
            }
        });
    };
    /**
   * Drops a table from a database
   */ const dropTable = (schemaBuilder, table)=>{
        if (!db.config.settings.forceMigration) {
            return;
        }
        return schemaBuilder.dropTableIfExists(table.name);
    };
    /**
   * Creates a table foreign keys constraints
   */ const createTableForeignKeys = async (schemaBuilder, table)=>{
        // foreign keys
        await schemaBuilder.table(table.name, (tableBuilder)=>{
            (table.foreignKeys || []).forEach((foreignKey)=>createForeignKey(tableBuilder, foreignKey));
        });
    };
    /**
   * Drops a table foreign keys constraints
   */ const dropTableForeignKeys = async (schemaBuilder, table)=>{
        if (!db.config.settings.forceMigration) {
            return;
        }
        // foreign keys
        await schemaBuilder.table(table.name, (tableBuilder)=>{
            (table.foreignKeys || []).forEach((foreignKey)=>dropForeignKey(tableBuilder, foreignKey));
        });
    };
    return {
        createTable,
        alterTable,
        dropTable,
        createTableForeignKeys,
        dropTableForeignKeys
    };
};

// TODO: get that list dynamically instead
const RESERVED_TABLE_NAMES = [
    'strapi_migrations',
    'strapi_migrations_internal',
    'strapi_database_schema'
];
const statuses = {
    CHANGED: 'CHANGED',
    UNCHANGED: 'UNCHANGED'
};
// NOTE:We could move the schema to use maps of tables & columns instead of arrays to make it easier to diff
// => this will make the creation a bit more complicated (ordering, Object.values(tables | columns)) -> not a big pbl
const helpers = {
    hasTable (schema, tableName) {
        return schema.tables.findIndex((table)=>table.name === tableName) !== -1;
    },
    findTable (schema, tableName) {
        return schema.tables.find((table)=>table.name === tableName);
    },
    hasColumn (table, columnName) {
        return table.columns.findIndex((column)=>column.name === columnName) !== -1;
    },
    findColumn (table, columnName) {
        return table.columns.find((column)=>column.name === columnName);
    },
    hasIndex (table, columnName) {
        return table.indexes.findIndex((column)=>column.name === columnName) !== -1;
    },
    findIndex (table, columnName) {
        return table.indexes.find((column)=>column.name === columnName);
    },
    hasForeignKey (table, columnName) {
        return table.foreignKeys.findIndex((column)=>column.name === columnName) !== -1;
    },
    findForeignKey (table, columnName) {
        return table.foreignKeys.find((column)=>column.name === columnName);
    }
};
var createSchemaDiff = ((db)=>{
    const hasChangedStatus = (diff)=>diff.status === statuses.CHANGED;
    /**
   * Compares two indexes info
   * @param {Object} oldIndex - index info read from DB
   * @param {Object} index - newly generate index info
   */ const diffIndexes = (oldIndex, index)=>{
        const changes = [];
        // use xor to avoid differences in order
        if (_.xor(oldIndex.columns, index.columns).length > 0) {
            changes.push('columns');
        }
        if (oldIndex.type && index.type && _.toLower(oldIndex.type) !== _.toLower(index.type)) {
            changes.push('type');
        }
        return {
            status: changes.length > 0 ? statuses.CHANGED : statuses.UNCHANGED,
            diff: {
                name: index.name,
                object: index
            }
        };
    };
    /**
   * Compares two foreign keys info
   * @param {Object} oldForeignKey - foreignKey info read from DB
   * @param {Object} foreignKey - newly generate foreignKey info
   */ const diffForeignKeys = (oldForeignKey, foreignKey)=>{
        const changes = [];
        if (_.difference(oldForeignKey.columns, foreignKey.columns).length > 0) {
            changes.push('columns');
        }
        if (_.difference(oldForeignKey.referencedColumns, foreignKey.referencedColumns).length > 0) {
            changes.push('referencedColumns');
        }
        if (oldForeignKey.referencedTable !== foreignKey.referencedTable) {
            changes.push('referencedTable');
        }
        if (_.isNil(oldForeignKey.onDelete) || _.toUpper(oldForeignKey.onDelete) === 'NO ACTION') {
            if (!_.isNil(foreignKey.onDelete) && _.toUpper(oldForeignKey.onDelete ?? '') !== 'NO ACTION') {
                changes.push('onDelete');
            }
        } else if (_.toUpper(oldForeignKey.onDelete) !== _.toUpper(foreignKey.onDelete ?? '')) {
            changes.push('onDelete');
        }
        if (_.isNil(oldForeignKey.onUpdate) || _.toUpper(oldForeignKey.onUpdate) === 'NO ACTION') {
            if (!_.isNil(foreignKey.onUpdate) && _.toUpper(oldForeignKey.onUpdate ?? '') !== 'NO ACTION') {
                changes.push('onUpdate');
            }
        } else if (_.toUpper(oldForeignKey.onUpdate) !== _.toUpper(foreignKey.onUpdate ?? '')) {
            changes.push('onUpdate');
        }
        return {
            status: changes.length > 0 ? statuses.CHANGED : statuses.UNCHANGED,
            diff: {
                name: foreignKey.name,
                object: foreignKey
            }
        };
    };
    const diffDefault = (oldColumn, column)=>{
        const oldDefaultTo = oldColumn.defaultTo;
        const { defaultTo } = column;
        if (oldDefaultTo === null || _.toLower(oldDefaultTo) === 'null') {
            return _.isNil(defaultTo) || _.toLower(defaultTo) === 'null';
        }
        return _.toLower(oldDefaultTo) === _.toLower(column.defaultTo) || _.toLower(oldDefaultTo) === _.toLower(`'${column.defaultTo}'`);
    };
    /**
   * Compares two columns info
   * @param {Object} oldColumn - column info read from DB
   * @param {Object} column - newly generate column info
   */ const diffColumns = (oldColumn, column)=>{
        const changes = [];
        const isIgnoredType = [
            'increments'
        ].includes(column.type);
        const oldType = oldColumn.type;
        const type = db.dialect.getSqlType(column.type);
        if (oldType !== type && !isIgnoredType) {
            changes.push('type');
        }
        // NOTE: compare args at some point and split them into specific properties instead
        if (oldColumn.notNullable !== column.notNullable) {
            changes.push('notNullable');
        }
        const hasSameDefault = diffDefault(oldColumn, column);
        if (!hasSameDefault) {
            changes.push('defaultTo');
        }
        if (oldColumn.unsigned !== column.unsigned && db.dialect.supportsUnsigned()) {
            changes.push('unsigned');
        }
        return {
            status: changes.length > 0 ? statuses.CHANGED : statuses.UNCHANGED,
            diff: {
                name: column.name,
                object: column
            }
        };
    };
    const diffTableColumns = (diffCtx)=>{
        const { databaseTable, userSchemaTable, previousTable } = diffCtx;
        const addedColumns = [];
        const updatedColumns = [];
        const unchangedColumns = [];
        const removedColumns = [];
        for (const userSchemaColumn of userSchemaTable.columns){
            const databaseColumn = helpers.findColumn(databaseTable, userSchemaColumn.name);
            if (databaseColumn) {
                const { status, diff } = diffColumns(databaseColumn, userSchemaColumn);
                if (status === statuses.CHANGED) {
                    updatedColumns.push(diff);
                } else {
                    unchangedColumns.push(databaseColumn);
                }
            } else {
                addedColumns.push(userSchemaColumn);
            }
        }
        for (const databaseColumn of databaseTable.columns){
            if (!helpers.hasColumn(userSchemaTable, databaseColumn.name) && previousTable && helpers.hasColumn(previousTable, databaseColumn.name)) {
                removedColumns.push(databaseColumn);
            }
        }
        const hasChanged = [
            addedColumns,
            updatedColumns,
            removedColumns
        ].some((arr)=>arr.length > 0);
        return {
            status: hasChanged ? statuses.CHANGED : statuses.UNCHANGED,
            diff: {
                added: addedColumns,
                updated: updatedColumns,
                unchanged: unchangedColumns,
                removed: removedColumns
            }
        };
    };
    const diffTableIndexes = (diffCtx)=>{
        const { databaseTable, userSchemaTable, previousTable } = diffCtx;
        const addedIndexes = [];
        const updatedIndexes = [];
        const unchangedIndexes = [];
        const removedIndexes = [];
        for (const userSchemaIndex of userSchemaTable.indexes){
            const databaseIndex = helpers.findIndex(databaseTable, userSchemaIndex.name);
            if (databaseIndex) {
                const { status, diff } = diffIndexes(databaseIndex, userSchemaIndex);
                if (status === statuses.CHANGED) {
                    updatedIndexes.push(diff);
                } else {
                    unchangedIndexes.push(databaseIndex);
                }
            } else {
                addedIndexes.push(userSchemaIndex);
            }
        }
        for (const databaseIndex of databaseTable.indexes){
            if (!helpers.hasIndex(userSchemaTable, databaseIndex.name) && previousTable && helpers.hasIndex(previousTable, databaseIndex.name)) {
                removedIndexes.push(databaseIndex);
            }
        }
        const hasChanged = [
            addedIndexes,
            updatedIndexes,
            removedIndexes
        ].some((arr)=>arr.length > 0);
        return {
            status: hasChanged ? statuses.CHANGED : statuses.UNCHANGED,
            diff: {
                added: addedIndexes,
                updated: updatedIndexes,
                unchanged: unchangedIndexes,
                removed: removedIndexes
            }
        };
    };
    const diffTableForeignKeys = (diffCtx)=>{
        const { databaseTable, userSchemaTable, previousTable } = diffCtx;
        const addedForeignKeys = [];
        const updatedForeignKeys = [];
        const unchangedForeignKeys = [];
        const removedForeignKeys = [];
        if (!db.dialect.usesForeignKeys()) {
            return {
                status: statuses.UNCHANGED,
                diff: {
                    added: addedForeignKeys,
                    updated: updatedForeignKeys,
                    unchanged: unchangedForeignKeys,
                    removed: removedForeignKeys
                }
            };
        }
        for (const userSchemaForeignKeys of userSchemaTable.foreignKeys){
            const databaseForeignKeys = helpers.findForeignKey(databaseTable, userSchemaForeignKeys.name);
            if (databaseForeignKeys) {
                const { status, diff } = diffForeignKeys(databaseForeignKeys, userSchemaForeignKeys);
                if (status === statuses.CHANGED) {
                    updatedForeignKeys.push(diff);
                } else {
                    unchangedForeignKeys.push(databaseForeignKeys);
                }
            } else {
                addedForeignKeys.push(userSchemaForeignKeys);
            }
        }
        for (const databaseForeignKeys of databaseTable.foreignKeys){
            if (!helpers.hasForeignKey(userSchemaTable, databaseForeignKeys.name) && previousTable && helpers.hasForeignKey(previousTable, databaseForeignKeys.name)) {
                removedForeignKeys.push(databaseForeignKeys);
            }
        }
        const hasChanged = [
            addedForeignKeys,
            updatedForeignKeys,
            removedForeignKeys
        ].some((arr)=>arr.length > 0);
        return {
            status: hasChanged ? statuses.CHANGED : statuses.UNCHANGED,
            diff: {
                added: addedForeignKeys,
                updated: updatedForeignKeys,
                unchanged: unchangedForeignKeys,
                removed: removedForeignKeys
            }
        };
    };
    const diffTables = (diffCtx)=>{
        const { databaseTable } = diffCtx;
        const columnsDiff = diffTableColumns(diffCtx);
        const indexesDiff = diffTableIndexes(diffCtx);
        const foreignKeysDiff = diffTableForeignKeys(diffCtx);
        const hasChanged = [
            columnsDiff,
            indexesDiff,
            foreignKeysDiff
        ].some(hasChangedStatus);
        return {
            status: hasChanged ? statuses.CHANGED : statuses.UNCHANGED,
            diff: {
                name: databaseTable.name,
                indexes: indexesDiff.diff,
                foreignKeys: foreignKeysDiff.diff,
                columns: columnsDiff.diff
            }
        };
    };
    const diffSchemas = async (schemaDiffCtx)=>{
        const { previousSchema, databaseSchema, userSchema } = schemaDiffCtx;
        const addedTables = [];
        const updatedTables = [];
        const unchangedTables = [];
        const removedTables = [];
        // for each table in the user schema, check if it already exists in the database schema
        for (const userSchemaTable of userSchema.tables){
            const databaseTable = helpers.findTable(databaseSchema, userSchemaTable.name);
            const previousTable = previousSchema && helpers.findTable(previousSchema, userSchemaTable.name);
            if (databaseTable) {
                const { status, diff } = diffTables({
                    previousTable,
                    databaseTable,
                    userSchemaTable
                });
                if (status === statuses.CHANGED) {
                    updatedTables.push(diff);
                } else {
                    unchangedTables.push(databaseTable);
                }
            } else {
                addedTables.push(userSchemaTable);
            }
        }
        // maintain audit logs table from EE -> CE
        const parsePersistedTable = (persistedTable)=>{
            if (typeof persistedTable === 'string') {
                return persistedTable;
            }
            return persistedTable.name;
        };
        const persistedTables = helpers.hasTable(databaseSchema, 'strapi_core_store_settings') ? await strapi.store.get({
            type: 'core',
            key: 'persisted_tables'
        }) ?? [] : [];
        const reservedTables = [
            ...RESERVED_TABLE_NAMES,
            ...persistedTables.map(parsePersistedTable)
        ];
        // for all tables in the database schema, check if they are not in the user schema
        for (const databaseTable of databaseSchema.tables){
            const isInUserSchema = helpers.hasTable(userSchema, databaseTable.name);
            const wasTracked = previousSchema && helpers.hasTable(previousSchema, databaseTable.name);
            const isReserved = reservedTables.includes(databaseTable.name);
            // NOTE: if db table is not in the user schema and is not in the previous stored schema leave it alone. it is a user custom table that we should not touch
            if (!isInUserSchema && !wasTracked) {
                continue;
            }
            // if a db table is not in the user schema I want to delete it
            if (!isInUserSchema && wasTracked && !isReserved) {
                const dependencies = persistedTables.filter((table)=>{
                    const dependsOn = table?.dependsOn;
                    if (!_.isArray(dependsOn)) {
                        return;
                    }
                    return dependsOn.some((table)=>table.name === databaseTable.name);
                }).map((dependsOnTable)=>{
                    return databaseSchema.tables.find((databaseTable)=>databaseTable.name === dependsOnTable.name);
                })// In case the table is not found, filter undefined values
                .filter((table)=>!_.isNil(table));
                removedTables.push(databaseTable, ...dependencies);
            }
        }
        const hasChanged = [
            addedTables,
            updatedTables,
            removedTables
        ].some((arr)=>arr.length > 0);
        return {
            status: hasChanged ? statuses.CHANGED : statuses.UNCHANGED,
            diff: {
                tables: {
                    added: addedTables,
                    updated: updatedTables,
                    unchanged: unchangedTables,
                    removed: removedTables
                }
            }
        };
    };
    return {
        diff: diffSchemas
    };
});

const TABLE_NAME = 'strapi_database_schema';
var createSchemaStorage = ((db)=>{
    const hasSchemaTable = ()=>db.getSchemaConnection().hasTable(TABLE_NAME);
    const createSchemaTable = ()=>{
        return db.getSchemaConnection().createTable(TABLE_NAME, (t)=>{
            t.increments('id');
            t.json('schema');
            t.datetime('time', {
                useTz: false
            });
            t.string('hash');
        });
    };
    const checkTableExists = async ()=>{
        if (!await hasSchemaTable()) {
            await createSchemaTable();
        }
    };
    return {
        async read () {
            await checkTableExists();
            const res = await db.getConnection().select('*').from(TABLE_NAME).orderBy('time', 'DESC').first();
            if (!res) {
                return null;
            }
            const parsedSchema = typeof res.schema === 'object' ? res.schema : JSON.parse(res.schema);
            return {
                ...res,
                schema: parsedSchema
            };
        },
        hashSchema (schema) {
            return crypto.createHash('md5').update(JSON.stringify(schema)).digest('hex');
        },
        async add (schema) {
            await checkTableExists();
            // NOTE: we can remove this to add history
            await db.getConnection(TABLE_NAME).delete();
            const time = new Date();
            await db.getConnection().insert({
                schema: JSON.stringify(schema),
                hash: this.hashSchema(schema),
                time
            }).into(TABLE_NAME);
        },
        async clear () {
            await checkTableExists();
            await db.getConnection(TABLE_NAME).truncate();
        }
    };
});

const SCALAR_TYPES = [
    'increments',
    'password',
    'email',
    'string',
    'uid',
    'richtext',
    'text',
    'json',
    'enumeration',
    'integer',
    'biginteger',
    'float',
    'decimal',
    'date',
    'time',
    'datetime',
    'timestamp',
    'boolean',
    'blocks'
];
const STRING_TYPES = [
    'string',
    'text',
    'uid',
    'email',
    'enumeration',
    'richtext'
];
const NUMBER_TYPES = [
    'biginteger',
    'integer',
    'decimal',
    'float'
];
const isString = (type)=>STRING_TYPES.includes(type);
const isNumber = (type)=>NUMBER_TYPES.includes(type);
const isScalar = (type)=>SCALAR_TYPES.includes(type);
const isRelation = (type)=>type === 'relation';
const isScalarAttribute = (attribute)=>isScalar(attribute.type);
const isRelationalAttribute = (attribute)=>isRelation(attribute.type);

/**
 * Creates a hash of the given data with the specified string length as a string of hex characters
 *
 * @example
 * createHash("myData", 5); // "03f85"
 * createHash("myData", 2); // "03"
 * createHash("myData", 1); // "0"
 *
 * @param data - The data to be hashed
 * @param len - The length of the hash
 * @returns The generated hash
 * @throws Error if the length is not a positive integer
 * @internal
 */ function createHash(data, len) {
    if (!isInteger(len) || len <= 0) {
        throw new Error(`createHash length must be a positive integer, received ${len}`);
    }
    const hash = crypto$1.createHash('shake256', {
        outputLength: Math.ceil(len / 2)
    }).update(data);
    return hash.digest('hex').substring(0, len);
}

/**
 * This file contains utility functions for generating names used in the database.
 * These names include table names, column names, join table names, index names, and more.
 * The generated names can be customized with prefixes, suffixes, and maximum length.
 * These utility functions are used throughout the codebase to ensure consistent and standardized naming conventions in the database.
 *
 * The reason for checking maxLength for suffixes and prefixes and using the long ones from Strapi 4 is so that we always
 * have access to the full length names, in particular for migration purposes, but also so that (in theory) the feature
 * could be disabled and stay compatible with v4 database structure.
 */ function _class_private_field_loose_base(receiver, privateKey) {
    if (!Object.prototype.hasOwnProperty.call(receiver, privateKey)) {
        throw new TypeError("attempted to use private field on non-instance");
    }
    return receiver;
}
var id = 0;
function _class_private_field_loose_key(name) {
    return "__private_" + id++ + "_" + name;
}
const IDENTIFIER_MAX_LENGTH = 55;
var // Fixed compression map for suffixes and prefixes
_replacementMap = /*#__PURE__*/ _class_private_field_loose_key("_replacementMap"), _options = /*#__PURE__*/ _class_private_field_loose_key("_options");
class Identifiers {
    get replacementMap() {
        return _class_private_field_loose_base(this, _replacementMap)[_replacementMap];
    }
    get options() {
        return _class_private_field_loose_base(this, _options)[_options];
    }
    constructor(options){
        Object.defineProperty(this, _replacementMap, {
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, _options, {
            writable: true,
            value: void 0
        });
        this.ID_COLUMN = 'id';
        this.ORDER_COLUMN = 'order';
        this.FIELD_COLUMN = 'field';
        this.HASH_LENGTH = 5;
        this.HASH_SEPARATOR = '' // no separator is needed, we will just attach hash directly to shortened name
        ;
        this.IDENTIFIER_SEPARATOR = '_';
        this.MIN_TOKEN_LENGTH = 3 // the min characters required at the beginning of a name part
        ;
        _class_private_field_loose_base(this, _replacementMap)[_replacementMap] = {
            links: 'lnk',
            order_inv_fk: 'oifk',
            order: 'ord',
            morphs: 'mph',
            index: 'idx',
            inv_fk: 'ifk',
            order_fk: 'ofk',
            id_column_index: 'idix',
            order_index: 'oidx',
            unique: 'uq',
            primary: 'pk'
        };
        this.mapshortNames = (name)=>{
            if (name in this.replacementMap) {
                return this.replacementMap[name];
            }
            return undefined;
        };
        // Generic name handler that must be used by all helper functions
        /**
   * TODO: we should be requiring snake_case inputs for all names here, but we
   * aren't and it will require some refactoring to make it work. Currently if
   * we get names 'myModel' and 'my_model' they would be converted to the same
   * final string my_model which generally works but is not entirely safe
   * */ this.getName = (names, options)=>{
            const tokens = _.castArray(names).map((name)=>{
                return {
                    name,
                    compressible: true
                };
            });
            if (options?.suffix) {
                tokens.push({
                    name: options.suffix,
                    compressible: false,
                    shortName: this.mapshortNames(options.suffix)
                });
            }
            if (options?.prefix) {
                tokens.unshift({
                    name: options.prefix,
                    compressible: false,
                    shortName: this.mapshortNames(options.prefix)
                });
            }
            return this.getNameFromTokens(tokens);
        };
        /**
   * TABLES
   */ this.getTableName = (name, options)=>{
            return this.getName(name, options);
        };
        this.getJoinTableName = (collectionName, attributeName, options)=>{
            return this.getName([
                collectionName,
                attributeName
            ], {
                suffix: 'links',
                ...options
            });
        };
        this.getMorphTableName = (collectionName, attributeName, options)=>{
            return this.getName([
                snakeCase(collectionName),
                snakeCase(attributeName)
            ], {
                suffix: 'morphs',
                ...options
            });
        };
        /**
   * COLUMNS
   */ this.getColumnName = (attributeName, options)=>{
            return this.getName(attributeName, options);
        };
        this.getJoinColumnAttributeIdName = (attributeName, options)=>{
            return this.getName(attributeName, {
                suffix: 'id',
                ...options
            });
        };
        this.getInverseJoinColumnAttributeIdName = (attributeName, options)=>{
            return this.getName(snakeCase(attributeName), {
                suffix: 'id',
                prefix: 'inv',
                ...options
            });
        };
        this.getOrderColumnName = (singularName, options)=>{
            return this.getName(singularName, {
                suffix: 'order',
                ...options
            });
        };
        this.getInverseOrderColumnName = (singularName, options)=>{
            return this.getName(singularName, {
                suffix: 'order',
                prefix: 'inv',
                ...options
            });
        };
        /**
   * Morph Join Tables
   */ this.getMorphColumnJoinTableIdName = (singularName, options)=>{
            return this.getName(snakeCase(singularName), {
                suffix: 'id',
                ...options
            });
        };
        this.getMorphColumnAttributeIdName = (attributeName, options)=>{
            return this.getName(snakeCase(attributeName), {
                suffix: 'id',
                ...options
            });
        };
        this.getMorphColumnTypeName = (attributeName, options)=>{
            return this.getName(snakeCase(attributeName), {
                suffix: 'type',
                ...options
            });
        };
        /**
   * INDEXES
   * Note that these methods are generally used to reference full table names + attribute(s), which
   * may already be shortened strings rather than individual parts.
   * That is fine and expected to compress the previously incompressible parts of those strings,
   * because in these cases the relevant information is the table name and we can't really do
   * any better; shortening the individual parts again might make it even more confusing.
   *
   * So for example, the fk for the table `mytable_myattr4567d_localizations` will become
   * mytable_myattr4567d_loc63bf2_fk
   */ // base index types
        this.getIndexName = (names, options)=>{
            return this.getName(names, {
                suffix: 'index',
                ...options
            });
        };
        this.getFkIndexName = (names, options)=>{
            return this.getName(names, {
                suffix: 'fk',
                ...options
            });
        };
        this.getUniqueIndexName = (names, options)=>{
            return this.getName(names, {
                suffix: 'unique',
                ...options
            });
        };
        this.getPrimaryIndexName = (names, options)=>{
            return this.getName(names, {
                suffix: 'primary',
                ...options
            });
        };
        // custom index types
        this.getInverseFkIndexName = (names, options)=>{
            return this.getName(names, {
                suffix: 'inv_fk',
                ...options
            });
        };
        this.getOrderFkIndexName = (names, options)=>{
            return this.getName(names, {
                suffix: 'order_fk',
                ...options
            });
        };
        this.getOrderInverseFkIndexName = (names, options)=>{
            return this.getName(names, {
                suffix: 'order_inv_fk',
                ...options
            });
        };
        this.getIdColumnIndexName = (names, options)=>{
            return this.getName(names, {
                suffix: 'id_column_index',
                ...options
            });
        };
        this.getOrderIndexName = (names, options)=>{
            return this.getName(names, {
                suffix: 'order_index',
                ...options
            });
        };
        /**
   * Generates a string with a max length, appending a hash at the end if necessary to keep it unique
   *
   * @example
   * // if we have strings such as "longstring1" and "longstring2" with a max length of 9,
   * // we don't want to end up with "longstrin" and "longstrin"
   * // we want something such as    "longs0b23" and "longs953f"
   * const token1 = generateToken("longstring1", 9); // "longs0b23"
   * const token2 = generateToken("longstring2", 9); // "longs953f"
   *
   * @param name - The base name
   * @param len - The desired length of the token.
   * @returns The generated token with hash.
   * @throws Error if the length is not a positive integer, or if the length is too short for the token.
   * @internal
   */ this.getShortenedName = (name, len)=>{
            if (!isInteger(len) || len <= 0) {
                throw new Error(`tokenWithHash length must be a positive integer, received ${len}`);
            }
            if (name.length <= len) {
                return name;
            }
            if (len < this.MIN_TOKEN_LENGTH + this.HASH_LENGTH) {
                throw new Error(`length for part of identifier too short, minimum is hash length (${this.HASH_LENGTH}) plus min token length (${this.MIN_TOKEN_LENGTH}), received ${len} for token ${name}`);
            }
            const availableLength = len - this.HASH_LENGTH - this.HASH_SEPARATOR.length;
            if (availableLength < this.MIN_TOKEN_LENGTH) {
                throw new Error(`length for part of identifier minimum is less than min token length (${this.MIN_TOKEN_LENGTH}), received ${len} for token ${name}`);
            }
            return `${name.substring(0, availableLength)}${this.HASH_SEPARATOR}${createHash(name, this.HASH_LENGTH)}`;
        };
        /**
   * Constructs a name from an array of name tokens within a specified maximum length. It ensures the final name does not exceed
   * this limit by selectively compressing tokens marked as compressible. If the name exceeds the maximum length and cannot be
   * compressed sufficiently, an error is thrown. This function supports dynamic adjustment of token lengths to fit within the
   * maxLength constraint (that is, it will always make use of all available space), while also ensuring the preservation of
   * incompressible tokens.
   * @internal
   */ this.getNameFromTokens = (nameTokens)=>{
            const { maxLength } = this.options;
            if (!isInteger(maxLength) || maxLength < 0) {
                throw new Error('maxLength must be a positive integer or 0 (for unlimited length)');
            }
            const unshortenedName = nameTokens.map((token)=>{
                return token.name;
            }).join(this.IDENTIFIER_SEPARATOR);
            // if maxLength == 0 we want the legacy v4 name without any shortening
            if (maxLength === 0) {
                this.setUnshortenedName(unshortenedName, unshortenedName);
                return unshortenedName;
            }
            // check the full length name (but with incompressible tokens using shortNames if available)
            const fullLengthName = nameTokens.map((token)=>{
                if (token.compressible) {
                    return token.name;
                }
                return token.shortName ?? token.name;
            }).join(this.IDENTIFIER_SEPARATOR);
            if (fullLengthName.length <= maxLength) {
                this.setUnshortenedName(fullLengthName, unshortenedName);
                return fullLengthName;
            }
            // Split tokens by compressibility
            const [compressible, incompressible] = partition((token)=>token.compressible, nameTokens);
            const totalIncompressibleLength = sumBy((token)=>token.compressible === false && token.shortName !== undefined ? token.shortName.length : token.name.length)(incompressible);
            const totalSeparatorsLength = nameTokens.length * this.IDENTIFIER_SEPARATOR.length - 1;
            const available = maxLength - totalIncompressibleLength - totalSeparatorsLength;
            const availablePerToken = Math.floor(available / compressible.length);
            if (totalIncompressibleLength + totalSeparatorsLength > maxLength || availablePerToken < this.MIN_TOKEN_LENGTH) {
                throw new Error('Maximum length is too small to accommodate all tokens');
            }
            // Calculate the remainder from the division and add it to the surplus
            let surplus = available % compressible.length;
            // Check that it's even possible to proceed
            const minHashedLength = this.HASH_LENGTH + this.HASH_SEPARATOR.length + this.MIN_TOKEN_LENGTH;
            const totalLength = nameTokens.reduce((total, token)=>{
                if (token.compressible) {
                    if (token.name.length < availablePerToken) {
                        return total + token.name.length;
                    }
                    return total + minHashedLength;
                }
                const tokenName = token.shortName ?? token.name;
                return total + tokenName.length;
            }, nameTokens.length * this.IDENTIFIER_SEPARATOR.length - 1);
            // TODO: this is the weakest thing of the shortener, but fortunately it can be improved later without a breaking change if it turns out to be a problem (for example, if there is some case we need 6+ name parts in one identifier). We could take this "shortest string we could generate" that is too long and apply the hash directly to that, which would work fine even though it would be very difficult to determine what it was actually referring to
            // Check if the maximum length is less than the total length
            if (maxLength < totalLength) {
                throw new Error('Maximum length is too small to accommodate all tokens');
            }
            // Calculate total surplus length from shorter strings and total deficit length from longer strings
            let deficits = [];
            compressible.forEach((token)=>{
                const actualLength = token.name.length;
                if (actualLength < availablePerToken) {
                    surplus += availablePerToken - actualLength;
                    token.allocatedLength = actualLength;
                } else {
                    token.allocatedLength = availablePerToken;
                    deficits.push(token);
                }
            });
            // Redistribute surplus length to longer strings, one character at a time
            // This way we avoid issues with greed and trying to handle floating points by dividing available length
            function filterAndIncreaseLength(token) {
                if (token.allocatedLength < token.name.length && surplus > 0) {
                    token.allocatedLength += 1;
                    surplus -= 1;
                    // if it hasn't reached its full length, keep it in array for next round
                    return token.allocatedLength < token.name.length;
                }
                return false; // Remove this token from the deficits array
            }
            // Redistribute surplus length to longer strings, one character at a time
            let previousSurplus = surplus + 1; // infinite loop protection
            while(surplus > 0 && deficits.length > 0){
                deficits = deficits.filter((token)=>filterAndIncreaseLength(token));
                // infinite loop protection; if the surplus hasn't changed, there was nothing left to distribute it to
                if (surplus === previousSurplus) {
                    break;
                }
                previousSurplus = surplus;
            }
            // Build final string
            const shortenedName = nameTokens.map((token)=>{
                // if it is compressible, shorten it
                if (token.compressible && 'allocatedLength' in token && token.allocatedLength !== undefined) {
                    return this.getShortenedName(token.name, token.allocatedLength);
                }
                // if is is only compressible as a fixed value, use that
                if (token.compressible === false && token.shortName) {
                    return token.shortName;
                }
                // otherwise return it as-is
                return token.name;
            }).join(this.IDENTIFIER_SEPARATOR);
            // this should be unreachable, but add a final check for potential edge cases we missed
            if (shortenedName.length > maxLength) {
                throw new Error(`name shortening failed to generate a name of the correct maxLength; name ${shortenedName}`);
            }
            this.setUnshortenedName(shortenedName, unshortenedName);
            return shortenedName;
        };
        // We need to be able to find the full-length name for any shortened name, primarily for migration purposes
        // Therefore we store every name that passes through so we can retrieve the original later
        this.nameMap = new Map();
        this.getUnshortenedName = (shortName)=>{
            return this.nameMap.get(this.serializeKey(shortName)) ?? shortName;
        };
        this.setUnshortenedName = (shortName, fullName)=>{
            // This is protection against cases where a name is shortened twice, for example shortened in a model outside of createMetadata
            // and then run through the shortener against inside createMetadata, which would do nothing at all but replace the original
            // name in this mapping
            if (this.nameMap.get(this.serializeKey(shortName)) && shortName === fullName) {
                return;
            }
            // set the name
            this.nameMap.set(this.serializeKey(shortName), fullName);
        };
        this.serializeKey = (shortName)=>{
            return `${shortName}.${this.options.maxLength}`;
        };
        _class_private_field_loose_base(this, _options)[_options] = options;
    }
}
// TODO: instead of instantiating this here as a global metadata should create its own to use
// However, that would require refactoring all of the metadata methods to be instantiated to keep a centralized identifiers
const identifiers = new Identifiers({
    maxLength: IDENTIFIER_MAX_LENGTH
});

/**
 * TODO: This needs to be refactored to support incoming names such as
 * (column, table, index) that are of the form string | NameToken[] so
 * that pieces can be passed through and shortened here.
 *
 * Currently, we are potentially shortening twice, although in reality
 * that won't happen since the shortened attribute column names will
 * fit here because they are already shortened to the max identifier
 * length
 *
 * That is the reason we use getName() here and not getColumnName();
 * we just want the exact shortened name for the value without doing
 * any other potential manipulation to it
 * */ const createColumn = (name, attribute)=>{
    const { type, args = [], ...opts } = getColumnType(attribute);
    return {
        name: identifiers.getName(name),
        type,
        args,
        defaultTo: null,
        notNullable: false,
        unsigned: false,
        ...opts,
        ...'column' in attribute ? attribute.column ?? {} : {}
    };
};
const createTable = (meta)=>{
    const table = {
        name: meta.tableName,
        indexes: meta.indexes || [],
        foreignKeys: meta.foreignKeys || [],
        columns: []
    };
    for (const key of Object.keys(meta.attributes)){
        const attribute = meta.attributes[key];
        // if (types.isRelation(attribute.type)) {
        if (attribute.type === 'relation') {
            if ('morphColumn' in attribute && attribute.morphColumn && attribute.owner) {
                const { idColumn, typeColumn } = attribute.morphColumn;
                const idColumnName = identifiers.getName(idColumn.name);
                const typeColumnName = identifiers.getName(typeColumn.name);
                table.columns.push(createColumn(idColumnName, {
                    type: 'integer',
                    column: {
                        unsigned: true
                    }
                }));
                table.columns.push(createColumn(typeColumnName, {
                    type: 'string'
                }));
            } else if ('joinColumn' in attribute && attribute.joinColumn && attribute.owner && attribute.joinColumn.referencedTable) {
                // NOTE: we could pass uniquness for oneToOne to avoid creating more than one to one
                const { name: columnNameFull, referencedColumn, referencedTable, columnType = 'integer' } = attribute.joinColumn;
                const columnName = identifiers.getName(columnNameFull);
                const column = createColumn(columnName, {
                    // TODO: find the column type automatically, or allow passing all the column params
                    type: columnType,
                    column: {
                        unsigned: true
                    }
                });
                table.columns.push(column);
                const fkName = identifiers.getFkIndexName([
                    table.name,
                    columnName
                ]);
                table.foreignKeys.push({
                    name: fkName,
                    columns: [
                        column.name
                    ],
                    referencedTable,
                    referencedColumns: [
                        referencedColumn
                    ],
                    // NOTE: could allow configuration
                    onDelete: 'SET NULL'
                });
                table.indexes.push({
                    name: fkName,
                    columns: [
                        column.name
                    ]
                });
            }
        } else if (isScalarAttribute(attribute)) {
            const columnName = identifiers.getName(attribute.columnName || key);
            const column = createColumn(columnName, attribute);
            if (column.unique) {
                table.indexes.push({
                    type: 'unique',
                    name: identifiers.getUniqueIndexName([
                        table.name,
                        column.name
                    ]),
                    columns: [
                        columnName
                    ]
                });
            }
            if (column.primary) {
                table.indexes.push({
                    type: 'primary',
                    name: identifiers.getPrimaryIndexName([
                        table.name,
                        column.name
                    ]),
                    columns: [
                        columnName
                    ]
                });
            }
            table.columns.push(column);
        }
    }
    return table;
};
const getColumnType = (attribute)=>{
    if ('columnType' in attribute && attribute.columnType) {
        return attribute.columnType;
    }
    switch(attribute.type){
        case 'increments':
            {
                return {
                    type: 'increments',
                    args: [
                        {
                            primary: true,
                            primaryKey: true
                        }
                    ],
                    notNullable: true
                };
            }
        // We might want to convert email/password to string types before going into the orm with specific validators & transformers
        case 'password':
        case 'email':
        case 'string':
        case 'enumeration':
            {
                return {
                    type: 'string'
                };
            }
        case 'uid':
            {
                return {
                    type: 'string'
                };
            }
        case 'richtext':
        case 'text':
            {
                return {
                    type: 'text',
                    args: [
                        'longtext'
                    ]
                };
            }
        case 'blocks':
        case 'json':
            {
                return {
                    type: 'jsonb'
                };
            }
        case 'integer':
            {
                return {
                    type: 'integer'
                };
            }
        case 'biginteger':
            {
                return {
                    type: 'bigInteger'
                };
            }
        case 'float':
            {
                return {
                    type: 'double'
                };
            }
        case 'decimal':
            {
                return {
                    type: 'decimal',
                    args: [
                        10,
                        2
                    ]
                };
            }
        case 'date':
            {
                return {
                    type: 'date'
                };
            }
        case 'time':
            {
                return {
                    type: 'time',
                    args: [
                        {
                            precision: 3
                        }
                    ]
                };
            }
        case 'datetime':
            {
                return {
                    type: 'datetime',
                    args: [
                        {
                            useTz: false,
                            precision: 6
                        }
                    ]
                };
            }
        case 'timestamp':
            {
                return {
                    type: 'timestamp',
                    args: [
                        {
                            useTz: false,
                            precision: 6
                        }
                    ]
                };
            }
        case 'boolean':
            {
                return {
                    type: 'boolean'
                };
            }
        default:
            {
                throw new Error(`Unknown type ${attribute.type}`);
            }
    }
};
const metadataToSchema = (metadata)=>{
    const schema = {
        tables: []
    };
    metadata.forEach((metadata)=>{
        schema.tables.push(createTable(metadata));
    });
    return schema;
};

const debug$1 = createDebug('strapi::database');
const createSchemaProvider = (db)=>{
    const state = {};
    return {
        get schema () {
            if (!state.schema) {
                debug$1('Converting metadata to database schema');
                state.schema = metadataToSchema(db.metadata);
            }
            return state.schema;
        },
        builder: createSchemaBuilder(db),
        schemaDiff: createSchemaDiff(db),
        schemaStorage: createSchemaStorage(db),
        /**
     * Drops the database schema
     */ async drop () {
            debug$1('Dropping database schema');
            const DBSchema = await db.dialect.schemaInspector.getSchema();
            await this.builder.dropSchema(DBSchema);
        },
        /**
     * Creates the database schema
     */ async create () {
            debug$1('Created database schema');
            await this.builder.createSchema(this.schema);
        },
        /**
     * Resets the database schema
     */ async reset () {
            debug$1('Resetting database schema');
            await this.drop();
            await this.create();
        },
        async syncSchema () {
            debug$1('Synchronizing database schema');
            const databaseSchema = await db.dialect.schemaInspector.getSchema();
            const storedSchema = await this.schemaStorage.read();
            /*
        3way diff - DB schema / previous metadataSchema / new metadataSchema

        - When something doesn't exist in the previous metadataSchema -> It's not tracked by us and should be ignored
        - If no previous metadataSchema => use new metadataSchema so we start tracking them and ignore everything else
        - Apply this logic to Tables / Columns / Indexes / FKs ...
        - Handle errors (indexes or fks on incompatible stuff ...)

      */ const { status, diff } = await this.schemaDiff.diff({
                previousSchema: storedSchema?.schema,
                databaseSchema,
                userSchema: this.schema
            });
            if (status === 'CHANGED') {
                await this.builder.updateSchema(diff);
            }
            await this.schemaStorage.add(this.schema);
            return status;
        },
        // TODO: support options to migrate softly or forcefully
        // TODO: support option to disable auto migration & run a CLI command instead to avoid doing it at startup
        // TODO: Allow keeping extra indexes / extra tables / extra columns (globally or on a per table basis)
        async sync () {
            if (await db.migrations.shouldRun()) {
                debug$1('Found migrations to run');
                await db.migrations.up();
                return this.syncSchema();
            }
            const oldSchema = await this.schemaStorage.read();
            if (!oldSchema) {
                debug$1('Schema not persisted yet');
                return this.syncSchema();
            }
            const { hash: oldHash } = oldSchema;
            const hash = await this.schemaStorage.hashSchema(this.schema);
            if (oldHash !== hash) {
                debug$1('Schema changed');
                return this.syncSchema();
            }
            debug$1('Schema unchanged');
            return 'UNCHANGED';
        }
    };
};

const ID = identifiers.ID_COLUMN;
const ORDER = identifiers.ORDER_COLUMN;
const FIELD = identifiers.FIELD_COLUMN;
const hasInversedBy = (attr)=>'inversedBy' in attr;
const hasMappedBy = (attr)=>'mappedBy' in attr;
const isOneToAny = (attribute)=>[
        'oneToOne',
        'oneToMany'
    ].includes(attribute.relation);
const isManyToAny = (attribute)=>[
        'manyToMany',
        'manyToOne'
    ].includes(attribute.relation);
const isAnyToOne = (attribute)=>[
        'oneToOne',
        'manyToOne'
    ].includes(attribute.relation);
const isAnyToMany = (attribute)=>[
        'oneToMany',
        'manyToMany'
    ].includes(attribute.relation);
const isBidirectional = (attribute)=>hasInversedBy(attribute) || hasMappedBy(attribute);
const isOwner = (attribute)=>!isBidirectional(attribute) || hasInversedBy(attribute);
const shouldUseJoinTable = (attribute)=>!('useJoinTable' in attribute) || attribute.useJoinTable !== false;
const hasOrderColumn = (attribute)=>isAnyToMany(attribute);
const hasInverseOrderColumn = (attribute)=>isBidirectional(attribute) && isManyToAny(attribute);
/**
 * Creates a oneToOne relation metadata
 *
 * if owner then
 *   if with join table then
 *     create join table
 *   else
 *     create joinColumn
 *   if bidirectional then
 *     set inverse attribute joinCol or joinTable info correctly
 * else
 *   this property must be set by the owner side
 *   verify the owner side is valid // should be done before or at the same time ?
 */ const createOneToOne = (attributeName, attribute, meta, metadata)=>{
    if (isOwner(attribute)) {
        if (shouldUseJoinTable(attribute)) {
            createJoinTable(metadata, {
                attribute,
                attributeName,
                meta
            });
        } else {
            createJoinColumn(metadata, {
                attribute,
                attributeName,
                meta
            });
        }
    }
};
/**
 * Creates a oneToMany relation metadata
 *
 * if unidirectional then
 *   create join table
 * if bidirectional then
 *   cannot be owning side
 *   do nothing
 */ const createOneToMany = (attributeName, attribute, meta, metadata)=>{
    if (shouldUseJoinTable(attribute) && !isBidirectional(attribute)) {
        createJoinTable(metadata, {
            attribute,
            attributeName,
            meta
        });
    } else if (isOwner(attribute)) {
        throw new Error('one side of a oneToMany cannot be the owner side in a bidirectional relation');
    }
};
/**
 * Creates a manyToOne relation metadata
 *
 * if unidirectional then
 *   if with join table then
 *     create join table
 *   else
 *     create join column
 * else
 *   must be the owner side
 *   if with join table then
 *     create join table
 *   else
 *     create join column
 *   set inverse attribute joinCol or joinTable info correctly
 */ const createManyToOne = (attributeName, attribute, meta, metadata)=>{
    if (isBidirectional(attribute) && !isOwner(attribute)) {
        throw new Error('The many side of a manyToOne must be the owning side');
    }
    if (shouldUseJoinTable(attribute)) {
        createJoinTable(metadata, {
            attribute,
            attributeName,
            meta
        });
    } else {
        createJoinColumn(metadata, {
            attribute,
            attributeName,
            meta
        });
    }
};
/**
 * Creates a manyToMany relation metadata
 *
 * if unidirectional
 *   create join table
 * else
 *   if owner then
 *     if with join table then
 *       create join table
 *   else
 *     do nothing
 */ const createManyToMany = (attributeName, attribute, meta, metadata)=>{
    if (shouldUseJoinTable(attribute) && (!isBidirectional(attribute) || isOwner(attribute))) {
        createJoinTable(metadata, {
            attribute,
            attributeName,
            meta
        });
    }
};
/**
 * Creates a morphToOne relation metadata
 *
 * if with join table then
 *   create join table
 * else
 *  create join columnsa
 *
 * if bidirectionnal
 *  set info in the traget
 */ const createMorphToOne = (attributeName, attribute)=>{
    const idColumnName = identifiers.getJoinColumnAttributeIdName('target');
    const typeColumnName = identifiers.getMorphColumnTypeName('target');
    Object.assign(attribute, {
        owner: true,
        morphColumn: attribute.morphColumn ?? {
            typeColumn: {
                name: typeColumnName
            },
            idColumn: {
                name: idColumnName,
                referencedColumn: ID
            }
        }
    });
};
/**
 * Creates a morphToMany relation metadata
 */ const createMorphToMany = (attributeName, attribute, meta, metadata)=>{
    if ('joinTable' in attribute && attribute.joinTable && !attribute.joinTable.__internal__) {
        return;
    }
    const joinTableName = identifiers.getMorphTableName(meta.tableName, attributeName);
    const joinColumnName = identifiers.getMorphColumnJoinTableIdName(snakeCase(meta.singularName));
    const idColumnName = identifiers.getMorphColumnAttributeIdName(attributeName);
    const typeColumnName = identifiers.getMorphColumnTypeName(attributeName);
    const fkIndexName = identifiers.getFkIndexName(joinTableName);
    metadata.add({
        singularName: joinTableName,
        uid: joinTableName,
        tableName: joinTableName,
        attributes: {
            [ID]: {
                type: 'increments'
            },
            [joinColumnName]: {
                type: 'integer',
                column: {
                    unsigned: true
                },
                // This must be set explicitly so that it is used instead of shortening the attribute name, which is already shortened
                columnName: joinColumnName
            },
            [idColumnName]: {
                type: 'integer',
                column: {
                    unsigned: true
                }
            },
            [typeColumnName]: {
                type: 'string'
            },
            [FIELD]: {
                type: 'string'
            },
            [ORDER]: {
                type: 'float',
                column: {
                    unsigned: true
                }
            }
        },
        indexes: [
            {
                name: fkIndexName,
                columns: [
                    joinColumnName
                ]
            },
            {
                name: identifiers.getOrderIndexName(joinTableName),
                columns: [
                    ORDER
                ]
            },
            {
                name: identifiers.getIdColumnIndexName(joinTableName),
                columns: [
                    idColumnName
                ]
            }
        ],
        foreignKeys: [
            {
                name: fkIndexName,
                columns: [
                    joinColumnName
                ],
                referencedColumns: [
                    ID
                ],
                referencedTable: meta.tableName,
                onDelete: 'CASCADE'
            }
        ],
        lifecycles: {},
        columnToAttribute: {}
    });
    const joinTable = {
        __internal__: true,
        name: joinTableName,
        joinColumn: {
            name: joinColumnName,
            referencedColumn: ID
        },
        morphColumn: {
            typeColumn: {
                name: typeColumnName
            },
            idColumn: {
                name: idColumnName,
                referencedColumn: ID
            }
        },
        orderBy: {
            order: 'asc'
        },
        pivotColumns: [
            joinColumnName,
            typeColumnName,
            idColumnName
        ]
    };
    attribute.joinTable = joinTable;
};
/**
 * Creates a morphOne relation metadata
 */ const createMorphOne = (attributeName, attribute, meta, metadata)=>{
    const targetMeta = metadata.get(attribute.target);
    if (!targetMeta) {
        throw new Error(`Morph target not found. Looking for ${attribute.target}`);
    }
    if (attribute.morphBy && !_.has(attribute.morphBy, targetMeta.attributes)) {
        throw new Error(`Morph target attribute not found. Looking for ${attribute.morphBy}`);
    }
};
/**
 * Creates a morphMany relation metadata
 */ const createMorphMany = (attributeName, attribute, meta, metadata)=>{
    const targetMeta = metadata.get(attribute.target);
    if (!targetMeta) {
        throw new Error(`Morph target not found. Looking for ${attribute.target}`);
    }
    if (attribute.morphBy && !_.has(attribute.morphBy, targetMeta.attributes)) {
        throw new Error(`Morph target attribute not found. Looking for ${attribute.morphBy}`);
    }
};
/**
 * Creates a join column info and add them to the attribute meta
 */ const createJoinColumn = (metadata, { attribute, attributeName })=>{
    const targetMeta = metadata.get(attribute.target);
    if (!targetMeta) {
        throw new Error(`Unknown target ${attribute.target}`);
    }
    const joinColumnName = identifiers.getJoinColumnAttributeIdName(snakeCase(attributeName));
    const joinColumn = {
        name: joinColumnName,
        referencedColumn: ID,
        referencedTable: targetMeta.tableName
    };
    if ('joinColumn' in attribute) {
        Object.assign(joinColumn, attribute.joinColumn);
    }
    Object.assign(attribute, {
        owner: true,
        joinColumn
    });
    if (isBidirectional(attribute)) {
        const inverseAttribute = targetMeta.attributes[attribute.inversedBy];
        Object.assign(inverseAttribute, {
            joinColumn: {
                name: joinColumn.referencedColumn,
                referencedColumn: joinColumnName
            }
        });
    }
};
/**
 * Creates a join table and add it to the attribute meta
 */ const createJoinTable = (metadata, { attributeName, attribute, meta })=>{
    if (!shouldUseJoinTable(attribute)) {
        throw new Error('Attempted to create join table when useJoinTable is false');
    }
    const targetMeta = metadata.get(attribute.target);
    if (!targetMeta) {
        throw new Error(`Unknown target ${attribute.target}`);
    }
    // TODO: implement overwrite logic instead
    if ('joinTable' in attribute && attribute.joinTable && !attribute.joinTable.__internal__) {
        return;
    }
    const joinTableName = identifiers.getJoinTableName(snakeCase(meta.tableName), snakeCase(attributeName));
    const joinColumnName = identifiers.getJoinColumnAttributeIdName(snakeCase(meta.singularName));
    let inverseJoinColumnName = identifiers.getJoinColumnAttributeIdName(snakeCase(targetMeta.singularName));
    // if relation is self referencing
    if (joinColumnName === inverseJoinColumnName) {
        inverseJoinColumnName = identifiers.getInverseJoinColumnAttributeIdName(snakeCase(targetMeta.singularName));
    }
    const orderColumnName = identifiers.getOrderColumnName(snakeCase(targetMeta.singularName));
    // TODO: should this plus the conditional below be rolled into one method?
    let inverseOrderColumnName = identifiers.getOrderColumnName(snakeCase(meta.singularName));
    // if relation is self referencing
    if (attribute.relation === 'manyToMany' && orderColumnName === inverseOrderColumnName) {
        inverseOrderColumnName = identifiers.getInverseOrderColumnName(snakeCase(meta.singularName));
    }
    const fkIndexName = identifiers.getFkIndexName(joinTableName);
    const invFkIndexName = identifiers.getInverseFkIndexName(joinTableName);
    const metadataSchema = {
        singularName: joinTableName,
        uid: joinTableName,
        tableName: joinTableName,
        attributes: {
            [ID]: {
                type: 'increments'
            },
            [joinColumnName]: {
                type: 'integer',
                column: {
                    unsigned: true
                },
                // This must be set explicitly so that it is used instead of shortening the attribute name, which is already shortened
                columnName: joinColumnName
            },
            [inverseJoinColumnName]: {
                type: 'integer',
                column: {
                    unsigned: true
                },
                // This must be set explicitly so that it is used instead of shortening the attribute name, which is already shortened
                columnName: inverseJoinColumnName
            }
        },
        indexes: [
            {
                name: fkIndexName,
                columns: [
                    joinColumnName
                ]
            },
            {
                name: invFkIndexName,
                columns: [
                    inverseJoinColumnName
                ]
            },
            {
                name: identifiers.getUniqueIndexName(joinTableName),
                columns: [
                    joinColumnName,
                    inverseJoinColumnName
                ],
                type: 'unique'
            }
        ],
        foreignKeys: [
            {
                name: fkIndexName,
                columns: [
                    joinColumnName
                ],
                referencedColumns: [
                    ID
                ],
                referencedTable: meta.tableName,
                onDelete: 'CASCADE'
            },
            {
                name: invFkIndexName,
                columns: [
                    inverseJoinColumnName
                ],
                referencedColumns: [
                    ID
                ],
                referencedTable: targetMeta.tableName,
                onDelete: 'CASCADE'
            }
        ],
        lifecycles: {},
        columnToAttribute: {}
    };
    const joinTable = {
        __internal__: true,
        name: joinTableName,
        joinColumn: {
            name: joinColumnName,
            referencedColumn: ID,
            referencedTable: meta.tableName
        },
        inverseJoinColumn: {
            name: inverseJoinColumnName,
            referencedColumn: ID,
            referencedTable: targetMeta.tableName
        },
        pivotColumns: [
            joinColumnName,
            inverseJoinColumnName
        ]
    };
    // order
    if (isAnyToMany(attribute)) {
        metadataSchema.attributes[orderColumnName] = {
            type: 'float',
            column: {
                unsigned: true,
                defaultTo: null
            },
            columnName: orderColumnName
        };
        metadataSchema.indexes.push({
            name: identifiers.getOrderFkIndexName(joinTableName),
            columns: [
                orderColumnName
            ]
        });
        joinTable.orderColumnName = orderColumnName;
        joinTable.orderBy = {
            [orderColumnName]: 'asc'
        };
    }
    // inv order
    if (isBidirectional(attribute) && isManyToAny(attribute)) {
        metadataSchema.attributes[inverseOrderColumnName] = {
            type: 'float',
            column: {
                unsigned: true,
                defaultTo: null
            },
            columnName: inverseOrderColumnName
        };
        metadataSchema.indexes.push({
            name: identifiers.getOrderInverseFkIndexName(joinTableName),
            columns: [
                inverseOrderColumnName
            ]
        });
        joinTable.inverseOrderColumnName = inverseOrderColumnName;
    }
    metadata.add(metadataSchema);
    attribute.joinTable = joinTable;
    if (isBidirectional(attribute)) {
        const inverseAttribute = attribute.inversedBy ? targetMeta.attributes[attribute.inversedBy] : null;
        if (!inverseAttribute) {
            throw new Error(`inversedBy attribute ${attribute.inversedBy} not found target ${targetMeta.uid}`);
        }
        if (inverseAttribute.type !== 'relation') {
            throw new Error(`inversedBy attribute ${attribute.inversedBy} targets non relational attribute in ${targetMeta.uid}`);
        }
        inverseAttribute.joinTable = {
            __internal__: true,
            name: joinTableName,
            joinColumn: joinTable.inverseJoinColumn,
            inverseJoinColumn: joinTable.joinColumn,
            pivotColumns: joinTable.pivotColumns
        };
        if (isManyToAny(attribute)) {
            inverseAttribute.joinTable.orderColumnName = inverseOrderColumnName;
            inverseAttribute.joinTable.orderBy = {
                [inverseOrderColumnName]: 'asc'
            };
        }
        if (isAnyToMany(attribute)) {
            inverseAttribute.joinTable.inverseOrderColumnName = orderColumnName;
        }
    }
};
/**
 * Creates a relation metadata
 */ const createRelation = (attributeName, attribute, meta, metadata)=>{
    switch(attribute.relation){
        case 'oneToOne':
            return createOneToOne(attributeName, attribute, meta, metadata);
        case 'oneToMany':
            return createOneToMany(attributeName, attribute, meta, metadata);
        case 'manyToOne':
            return createManyToOne(attributeName, attribute, meta, metadata);
        case 'manyToMany':
            return createManyToMany(attributeName, attribute, meta, metadata);
        case 'morphToOne':
            return createMorphToOne(attributeName, attribute);
        case 'morphToMany':
            return createMorphToMany(attributeName, attribute, meta, metadata);
        case 'morphOne':
            return createMorphOne(attributeName, attribute, meta, metadata);
        case 'morphMany':
            return createMorphMany(attributeName, attribute, meta, metadata);
        default:
            {
                throw new Error(`Unknown relation`);
            }
    }
};

class Metadata extends Map {
    // TODO: we expose the global identifiers in this way so that in the future we can instantiate our own
    // However, it should NOT be done until all the methods used by metadata can be part of this metadata object
    // and access this one; currently they all access the global identifiers directly.
    get identifiers() {
        return identifiers;
    }
    get(key) {
        if (!super.has(key)) {
            throw new Error(`Metadata for "${key}" not found`);
        }
        return super.get(key);
    }
    add(meta) {
        return this.set(meta.uid, meta);
    }
    /**
   * Validate the DB metadata, throwing an error if a duplicate DB table name is detected
   */ validate() {
        const seenTables = new Map();
        for (const meta of this.values()){
            if (seenTables.get(meta.tableName)) {
                throw new Error(`DB table "${meta.tableName}" already exists. Change the collectionName of the related content type.`);
            }
            seenTables.set(meta.tableName, true);
        }
    }
    loadModels(models) {
        // init pass
        for (const model of cloneDeep(models ?? [])){
            const tableName = identifiers.getTableName(model.tableName);
            this.add({
                ...model,
                tableName,
                attributes: {
                    ...model.attributes
                },
                lifecycles: model.lifecycles ?? {},
                indexes: model.indexes ?? [],
                foreignKeys: model.foreignKeys ?? [],
                columnToAttribute: {}
            });
        }
        // build compos / relations
        for (const meta of this.values()){
            for (const [attributeName, attribute] of Object.entries(meta.attributes)){
                try {
                    if (attribute.unstable_virtual) {
                        continue;
                    }
                    if (isRelationalAttribute(attribute)) {
                        createRelation(attributeName, attribute, meta, this);
                        continue;
                    }
                    createAttribute(attributeName, attribute);
                } catch (error) {
                    if (error instanceof Error) {
                        throw new Error(`Error on attribute ${attributeName} in model ${meta.singularName}(${meta.uid}): ${error.message}`);
                    }
                }
            }
        }
        for (const meta of this.values()){
            const columnToAttribute = Object.keys(meta.attributes).reduce((acc, key)=>{
                const attribute = meta.attributes[key];
                if ('columnName' in attribute) {
                    return Object.assign(acc, {
                        [attribute.columnName || key]: key
                    });
                }
                return Object.assign(acc, {
                    [key]: key
                });
            }, {});
            meta.columnToAttribute = columnToAttribute;
        }
        this.validate();
    }
}
const createAttribute = (attributeName, attribute)=>{
    // if the attribute has already set its own column name, use that
    // this will prevent us from shortening a name twice
    if ('columnName' in attribute && attribute.columnName) {
        return;
    }
    const columnName = identifiers.getColumnName(snakeCase(attributeName));
    Object.assign(attribute, {
        columnName
    });
};

// TODO: check if there isn't an attribute with an id already
/**
 * Create Metadata from models configurations
 */ const createMetadata = (models)=>{
    const metadata = new Metadata();
    if (models.length) {
        metadata.loadModels(models);
    }
    return metadata;
};

class Field {
    toDB(value) {
        return value;
    }
    fromDB(value) {
        return value;
    }
    constructor(config){
        this.config = config;
    }
}

class StringField extends Field {
    toDB(value) {
        return toString(value);
    }
    fromDB(value) {
        return toString(value);
    }
}

class JSONField extends Field {
    toDB(value) {
        if (value == null) {
            return null;
        }
        if (typeof value === 'object') {
            return JSON.stringify(value);
        }
        return value;
    }
    fromDB(value) {
        try {
            if (typeof value === 'string') {
                const parsedValue = JSON.parse(value);
                /**
         * On Strapi 5 until 5.0.0-rc.7, the values were accidentally stringified twice when saved,
         * so in those cases we need to parse them twice to retrieve the actual value.
         */ if (typeof parsedValue === 'string') {
                    return JSON.parse(parsedValue);
                }
                return parsedValue;
            }
        } catch (error) {
            // Just return the value if it's not a valid JSON string
            return value;
        }
        return value;
    }
}

class BigIntegerField extends StringField {
}

class NumberField extends Field {
    toDB(value) {
        const numberValue = toNumber(value);
        if (Number.isNaN(numberValue)) {
            throw new Error(`Expected a valid Number, got ${value}`);
        }
        return numberValue;
    }
    fromDB(value) {
        return toNumber(value);
    }
}

const isDate = (value)=>{
    return dateFns.isDate(value);
};
const DATE_REGEX = /^\d{4}-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])$/;
const PARTIAL_DATE_REGEX = /^\d{4}-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])/g;
const TIME_REGEX = /^(2[0-3]|[01][0-9]):([0-5][0-9]):([0-5][0-9])(.[0-9]{1,3})?$/;
const parseDateTimeOrTimestamp = (value)=>{
    if (isDate(value)) {
        return value;
    }
    try {
        const date = dateFns.parseISO(toString(value));
        if (dateFns.isValid(date)) {
            return date;
        }
        const milliUnixDate = dateFns.parse(toString(value), 'T', new Date());
        if (dateFns.isValid(milliUnixDate)) {
            return milliUnixDate;
        }
        throw new InvalidDateTimeError(`Invalid format, expected a timestamp or an ISO date`);
    } catch (error) {
        throw new InvalidDateTimeError(`Invalid format, expected a timestamp or an ISO date`);
    }
};
const parseDate = (value)=>{
    if (isDate(value)) {
        return dateFns.format(value, 'yyyy-MM-dd');
    }
    const found = isString$1(value) ? value.match(PARTIAL_DATE_REGEX) || [] : [];
    const extractedValue = found[0];
    if (extractedValue && !DATE_REGEX.test(toString(value))) {
        // TODO V5: throw an error when format yyyy-MM-dd is not respected
        // throw new InvalidDateError(`Invalid format, expected yyyy-MM-dd`);
        process.emitWarning(`[deprecated] Using a date format other than YYYY-MM-DD will be removed in future versions. Date received: ${value}. Date stored: ${extractedValue}.`);
    }
    if (!extractedValue) {
        throw new InvalidDateError(`Invalid format, expected yyyy-MM-dd`);
    }
    const date = dateFns.parseISO(extractedValue);
    if (!dateFns.isValid(date)) {
        throw new InvalidDateError(`Invalid date`);
    }
    return extractedValue;
};
const parseTime = (value)=>{
    if (isDate(value)) {
        return dateFns.format(value, 'HH:mm:ss.SSS');
    }
    if (typeof value !== 'string') {
        throw new InvalidTimeError(`Expected a string, got a ${typeof value}`);
    }
    const result = value.match(TIME_REGEX);
    if (result === null) {
        throw new InvalidTimeError('Invalid time format, expected HH:mm:ss.SSS');
    }
    const [, hours, minutes, seconds, fraction = '.000'] = result;
    const fractionPart = padCharsEnd('0', 3, fraction.slice(1));
    return `${hours}:${minutes}:${seconds}.${fractionPart}`;
};

class DateField extends Field {
    toDB(value) {
        return parseDate(value);
    }
    fromDB(value) {
        return value;
    }
}

class TimeField extends Field {
    toDB(value) {
        return parseTime(value);
    }
    fromDB(value) {
        // make sure that's a string with valid format ?
        return value;
    }
}

class DatetimeField extends Field {
    toDB(value) {
        return parseDateTimeOrTimestamp(value);
    }
    fromDB(value) {
        const cast = new Date(value);
        return dateFns.isValid(cast) ? cast.toISOString() : null;
    }
}

class TimestampField extends Field {
    toDB(value) {
        return parseDateTimeOrTimestamp(value);
    }
    fromDB(value) {
        const cast = new Date(value);
        return dateFns.isValid(cast) ? dateFns.format(cast, 'T') : null;
    }
}

function isStringOrNumber(value) {
    return typeof value === 'string' || typeof value === 'number';
}
class BooleanField extends Field {
    toDB(value) {
        if (typeof value === 'boolean') {
            return value;
        }
        if (isStringOrNumber(value) && [
            'true',
            't',
            '1',
            1
        ].includes(value)) {
            return true;
        }
        if (isStringOrNumber(value) && [
            'false',
            'f',
            '0',
            0
        ].includes(value)) {
            return false;
        }
        return Boolean(value);
    }
    fromDB(value) {
        if (typeof value === 'boolean') {
            return value;
        }
        const strVal = toString(value);
        if (strVal === '1') {
            return true;
        }
        if (strVal === '0') {
            return false;
        }
        return null;
    }
}

const typeToFieldMap = {
    increments: Field,
    password: StringField,
    email: StringField,
    string: StringField,
    uid: StringField,
    richtext: StringField,
    text: StringField,
    enumeration: StringField,
    json: JSONField,
    biginteger: BigIntegerField,
    integer: NumberField,
    float: NumberField,
    decimal: NumberField,
    date: DateField,
    time: TimeField,
    datetime: DatetimeField,
    timestamp: TimestampField,
    boolean: BooleanField,
    blocks: JSONField
};
const createField = (attribute)=>{
    const { type } = attribute;
    if (_.has(type, typeToFieldMap)) {
        return new typeToFieldMap[type]({});
    }
    throw new Error(`Undefined field for type ${type}`);
};

const storage = new AsyncLocalStorage();
const transactionCtx = {
    async run (trx, cb) {
        const store = storage.getStore();
        return storage.run({
            trx,
            // Fill with existing callbacks if nesting transactions
            commitCallbacks: store?.commitCallbacks || [],
            rollbackCallbacks: store?.rollbackCallbacks || []
        }, cb);
    },
    get () {
        const store = storage.getStore();
        return store?.trx;
    },
    async commit (trx) {
        const store = storage.getStore();
        // Clear transaction from store
        if (store?.trx) {
            store.trx = null;
        }
        // Commit transaction
        await trx.commit();
        if (!store?.commitCallbacks.length) {
            return;
        }
        // Run callbacks
        store.commitCallbacks.forEach((cb)=>cb());
        store.commitCallbacks = [];
    },
    async rollback (trx) {
        const store = storage.getStore();
        // Clear transaction from store
        if (store?.trx) {
            store.trx = null;
        }
        // Rollback transaction
        await trx.rollback();
        if (!store?.rollbackCallbacks.length) {
            return;
        }
        // Run callbacks
        store.rollbackCallbacks.forEach((cb)=>cb());
        store.rollbackCallbacks = [];
    },
    onCommit (cb) {
        const store = storage.getStore();
        if (store?.commitCallbacks) {
            store.commitCallbacks.push(cb);
        }
    },
    onRollback (cb) {
        const store = storage.getStore();
        if (store?.rollbackCallbacks) {
            store.rollbackCallbacks.push(cb);
        }
    }
};

/**
 * @internal
 */ function isKnexQuery(value) {
    return value instanceof KnexBuilder || value instanceof KnexRaw;
}
/**
 * Adds the name of the schema to the table name if the schema was defined by the user.
 * Users can set the db schema only for Postgres in strapi database config.
 */ const addSchema = (db, tableName)=>{
    const schemaName = db.getSchemaName();
    return schemaName ? `${schemaName}.${tableName}` : tableName;
};

const fromSingleRow = (meta, row)=>{
    const { attributes } = meta;
    if (_.isNil(row)) {
        return null;
    }
    const obj = {};
    for(const column in row){
        if (!_.has(column, meta.columnToAttribute)) {
            continue;
        }
        const attributeName = meta.columnToAttribute[column];
        const attribute = attributes[attributeName];
        if (isScalar(attribute.type)) {
            const field = createField(attribute);
            const val = row[column] === null ? null : field.fromDB(row[column]);
            obj[attributeName] = val;
        }
        if (isRelation(attribute.type)) {
            obj[attributeName] = row[column];
        }
    }
    return obj;
};
const fromRow = (meta, row)=>{
    if (_.isNil(row)) {
        return null;
    }
    if (Array.isArray(row)) {
        return row.map((singleRow)=>fromSingleRow(meta, singleRow));
    }
    return fromSingleRow(meta, row);
};
const toSingleRow = (meta, data = {})=>{
    if (_.isNil(data)) {
        return data;
    }
    const { attributes } = meta;
    for (const key of Object.keys(data)){
        const attribute = attributes[key];
        if (!attribute || !('columnName' in attribute) || !attribute.columnName || attribute.columnName === key) {
            continue;
        }
        data[attribute.columnName] = data[key];
        delete data[key];
    }
    return data;
};
function toRow(meta, data) {
    if (_.isNil(data)) {
        return data;
    }
    if (_.isArray(data)) {
        return data.map((datum)=>toSingleRow(meta, datum));
    }
    return toSingleRow(meta, data);
}
const toColumnName = (meta, name)=>{
    if (!name) {
        throw new Error('Name cannot be null');
    }
    const attribute = meta.attributes[name];
    if (!attribute) {
        return name;
    }
    return 'columnName' in attribute && attribute.columnName || name;
};

const applySearch = (knex, query, ctx)=>{
    const { qb, uid, db } = ctx;
    const meta = db.metadata.get(uid);
    const { attributes } = meta;
    const searchColumns = [
        'id'
    ];
    const stringColumns = Object.keys(attributes).filter((attributeName)=>{
        const attribute = attributes[attributeName];
        return isScalarAttribute(attribute) && isString(attribute.type) && attribute.searchable !== false;
    });
    searchColumns.push(...stringColumns);
    if (!_.isNaN(_.toNumber(query))) {
        const numberColumns = Object.keys(attributes).filter((attributeName)=>{
            const attribute = attributes[attributeName];
            return isScalarAttribute(attribute) && isNumber(attribute.type) && attribute.searchable !== false;
        });
        searchColumns.push(...numberColumns);
    }
    switch(db.dialect.client){
        case 'postgres':
            {
                searchColumns.forEach((attr)=>{
                    const columnName = toColumnName(meta, attr);
                    return knex.orWhereRaw(`??::text ILIKE ?`, [
                        qb.aliasColumn(columnName),
                        `%${escapeQuery(query, '*%\\')}%`
                    ]);
                });
                break;
            }
        case 'sqlite':
            {
                searchColumns.forEach((attr)=>{
                    const columnName = toColumnName(meta, attr);
                    return knex.orWhereRaw(`?? LIKE ? ESCAPE '\\'`, [
                        qb.aliasColumn(columnName),
                        `%${escapeQuery(query, '*%\\')}%`
                    ]);
                });
                break;
            }
        case 'mysql':
            {
                searchColumns.forEach((attr)=>{
                    const columnName = toColumnName(meta, attr);
                    return knex.orWhereRaw(`?? LIKE ?`, [
                        qb.aliasColumn(columnName),
                        `%${escapeQuery(query, '*%\\')}%`
                    ]);
                });
                break;
            }
    }
};
const escapeQuery = (query, charsToEscape, escapeChar = '\\')=>{
    return query.split('').reduce((escapedQuery, char)=>charsToEscape.includes(char) ? `${escapedQuery}${escapeChar}${char}` : `${escapedQuery}${char}`, '');
};

const createPivotJoin = (ctx, { alias, refAlias, joinTable, targetMeta })=>{
    const { qb } = ctx;
    const joinAlias = qb.getAlias();
    qb.join({
        alias: joinAlias,
        referencedTable: joinTable.name,
        referencedColumn: joinTable.joinColumn.name,
        rootColumn: joinTable.joinColumn.referencedColumn,
        rootTable: alias,
        on: joinTable.on
    });
    const subAlias = refAlias || qb.getAlias();
    qb.join({
        alias: subAlias,
        referencedTable: targetMeta.tableName,
        referencedColumn: joinTable.inverseJoinColumn.referencedColumn,
        rootColumn: joinTable.inverseJoinColumn.name,
        rootTable: joinAlias
    });
    return subAlias;
};
const createJoin = (ctx, { alias, refAlias, attributeName, attribute })=>{
    const { db, qb, uid } = ctx;
    if (attribute.type !== 'relation') {
        throw new Error(`Cannot join on non relational field ${attributeName}`);
    }
    const targetMeta = db.metadata.get(attribute.target);
    if ([
        'morphOne',
        'morphMany'
    ].includes(attribute.relation)) {
        const targetAttribute = targetMeta.attributes[attribute.morphBy];
        // @ts-expect-error - morphBy is not defined on the attribute
        const { joinTable, morphColumn } = targetAttribute;
        if (morphColumn) {
            const subAlias = refAlias || qb.getAlias();
            qb.join({
                alias: subAlias,
                referencedTable: targetMeta.tableName,
                referencedColumn: morphColumn.idColumn.name,
                rootColumn: morphColumn.idColumn.referencedColumn,
                rootTable: alias,
                on: {
                    [morphColumn.typeColumn.name]: uid,
                    ...morphColumn.on
                }
            });
            return subAlias;
        }
        if (joinTable) {
            const joinAlias = qb.getAlias();
            qb.join({
                alias: joinAlias,
                referencedTable: joinTable.name,
                referencedColumn: joinTable.morphColumn.idColumn.name,
                rootColumn: joinTable.morphColumn.idColumn.referencedColumn,
                rootTable: alias,
                on: {
                    [joinTable.morphColumn.typeColumn.name]: uid,
                    field: attributeName
                }
            });
            const subAlias = refAlias || qb.getAlias();
            qb.join({
                alias: subAlias,
                referencedTable: targetMeta.tableName,
                referencedColumn: joinTable.joinColumn.referencedColumn,
                rootColumn: joinTable.joinColumn.name,
                rootTable: joinAlias
            });
            return subAlias;
        }
        return alias;
    }
    const { joinColumn } = attribute;
    if (joinColumn) {
        const subAlias = refAlias || qb.getAlias();
        qb.join({
            alias: subAlias,
            referencedTable: targetMeta.tableName,
            referencedColumn: joinColumn.referencedColumn,
            rootColumn: joinColumn.name,
            rootTable: alias
        });
        return subAlias;
    }
    const { joinTable } = attribute;
    if (joinTable) {
        return createPivotJoin(ctx, {
            alias,
            refAlias,
            joinTable,
            targetMeta
        });
    }
    return alias;
};
// TODO: toColumnName for orderBy & on
const applyJoin = (qb, join)=>{
    const { method = 'leftJoin', alias, referencedTable, referencedColumn, rootColumn, // FIXME: qb.alias can't exist here
    rootTable, on, orderBy } = join;
    qb[method](`${referencedTable} as ${alias}`, (inner)=>{
        inner.on(`${rootTable}.${rootColumn}`, `${alias}.${referencedColumn}`);
        if (on) {
            for (const key of Object.keys(on)){
                inner.onVal(`${alias}.${key}`, on[key]);
            }
        }
    });
    if (orderBy) {
        Object.keys(orderBy).forEach((column)=>{
            const direction = orderBy[column];
            qb.orderBy(`${alias}.${column}`, direction);
        });
    }
};
const applyJoins = (qb, joins)=>{
    return joins.forEach((join)=>applyJoin(qb, join));
};

const COL_STRAPI_ROW_NUMBER = '__strapi_row_number';
const COL_STRAPI_ORDER_BY_PREFIX = '__strapi_order_by';
const processOrderBy = (orderBy, ctx)=>{
    const { db, uid, qb, alias } = ctx;
    const meta = db.metadata.get(uid);
    const { attributes } = meta;
    if (typeof orderBy === 'string') {
        const attribute = attributes[orderBy];
        if (!attribute) {
            throw new Error(`Attribute ${orderBy} not found on model ${uid}`);
        }
        const columnName = toColumnName(meta, orderBy);
        return [
            {
                column: qb.aliasColumn(columnName, alias)
            }
        ];
    }
    if (Array.isArray(orderBy)) {
        return orderBy.flatMap((value)=>processOrderBy(value, ctx));
    }
    if (_.isPlainObject(orderBy)) {
        return Object.entries(orderBy).flatMap(([key, direction])=>{
            const value = orderBy[key];
            const attribute = attributes[key];
            if (!attribute) {
                throw new Error(`Attribute ${key} not found on model ${uid}`);
            }
            if (isScalar(attribute.type)) {
                const columnName = toColumnName(meta, key);
                return {
                    column: qb.aliasColumn(columnName, alias),
                    order: direction
                };
            }
            if (attribute.type === 'relation' && 'target' in attribute) {
                const subAlias = createJoin(ctx, {
                    alias: alias || qb.alias,
                    attributeName: key,
                    attribute
                });
                return processOrderBy(value, {
                    db,
                    qb,
                    alias: subAlias,
                    uid: attribute.target
                });
            }
            throw new Error(`You cannot order on ${attribute.type} types`);
        });
    }
    throw new Error('Invalid orderBy syntax');
};
const getStrapiOrderColumnAlias = (column)=>{
    const trimmedColumnName = column.replaceAll('.', '_');
    return `${COL_STRAPI_ORDER_BY_PREFIX}__${trimmedColumnName}`;
};
/**
 * Wraps the original Knex query with deep sorting functionality.
 *
 * The function takes an original query and an OrderByCtx object as parameters and returns a new Knex query with deep sorting applied.
 */ const wrapWithDeepSort = (originalQuery, ctx)=>{
    /**
   * Notes:
   * - The generated query has the following flow: baseQuery (filtered unsorted data) -> T (partitioned/sorted data) --> resultQuery (distinct, paginated, sorted data)
   * - Pagination and selection are transferred from the original query to the outer one to avoid pruning rows too early
   * - Filtering (where) has to be done in the deepest sub query possible to avoid processing invalid rows and corrupting the final results
   * - We assume that all necessary joins are done in the original query (`originalQuery`), and every needed column is available with the right name and alias.
   */ const { db, qb, uid } = ctx;
    const { tableName } = db.metadata.get(uid);
    // The orderBy is cloned to avoid unwanted mutations of the original object
    const orderBy = _.cloneDeep(qb.state.orderBy);
    // 0. Init a new Knex query instance (referenced as resultQuery) using the DB connection
    //    The connection reuse the original table name (aliased if needed)
    const resultQueryAlias = qb.getAlias();
    const aliasedTableName = qb.mustUseAlias() ? alias(resultQueryAlias, tableName) : tableName;
    const resultQuery = db.getConnection(aliasedTableName);
    // 1. Clone the original query to create the sub-query (referenced as baseQuery) and avoid any mutation on the initial object
    const baseQuery = originalQuery.clone();
    const baseQueryAlias = qb.getAlias();
    // Clear unwanted statements from the sub-query 'baseQuery'
    // Note: `first()` is cleared through the combination of `baseQuery.clear('limit')` and calling `baseQuery.select(...)` again
    // Note: Those statements will be re-applied when duplicates are removed from the final selection
    baseQuery// Columns selection
    .clear('select')// Pagination and sorting
    .clear('order').clear('limit').clear('offset');
    // Override the initial select and return only the columns needed for the partitioning.
    baseQuery.select(// Always select the row id for future manipulation
    prefix(qb.alias, 'id'), // Select every column used in an order by clause, but alias it for future reference
    // i.e. if t2.name is present in an order by clause:
    //      Then, "t2.name" will become "t2.name as __strapi_order_by__t2_name"
    ...orderBy.map((orderByClause)=>alias(getStrapiOrderColumnAlias(orderByClause.column), orderByClause.column)));
    // 2. Create a sub-query callback to extract and sort the partitions using row number
    const partitionedQueryAlias = qb.getAlias();
    const selectRowsAsNumberedPartitions = (partitionedQuery)=>{
        // Transform order by clause to their alias to reference them from baseQuery
        const prefixedOrderBy = orderBy.map((orderByClause)=>({
                column: prefix(baseQueryAlias, getStrapiOrderColumnAlias(orderByClause.column)),
                order: orderByClause.order
            }));
        // partitionedQuery select must contain every column used for sorting
        const orderByColumns = prefixedOrderBy.map(_.prop('column'));
        partitionedQuery.select(// Always select baseQuery.id
        prefix(baseQueryAlias, 'id'), // Sort columns
        ...orderByColumns)// The row number is used to assign an index to every row in every partition
        .rowNumber(COL_STRAPI_ROW_NUMBER, (subQuery)=>{
            for (const orderByClause of prefixedOrderBy){
                subQuery.orderBy(orderByClause.column, orderByClause.order, 'last');
            }
            // And each partition/group is created based on baseQuery.id
            subQuery.partitionBy(`${baseQueryAlias}.id`);
        }).from(baseQuery.as(baseQueryAlias)).as(partitionedQueryAlias);
    };
    // 3. Create the final resultQuery query, that select and sort the wanted data using T
    const originalSelect = _.difference(qb.state.select, // Remove order by columns from the initial select
    qb.state.orderBy.map(_.prop('column')))// Alias everything in resultQuery
    .map(prefix(resultQueryAlias));
    resultQuery.select(originalSelect)// Join T to resultQuery to access sorted data
    // Notes:
    // - Only select the first row for each partition
    // - Since we're applying the "where" statement directly on baseQuery (and not on resultQuery), we're using an inner join to avoid unwanted rows
    .innerJoin(selectRowsAsNumberedPartitions, function() {
        this// Only select rows that are returned by T
        .on(`${partitionedQueryAlias}.id`, `${resultQueryAlias}.id`)// By only selecting the rows number equal to 1, we make sure we don't have duplicate, and that
        // we're selecting rows in the correct order amongst the groups created by the "partition by"
        .andOnVal(`${partitionedQueryAlias}.${COL_STRAPI_ROW_NUMBER}`, '=', 1);
    });
    // Re-apply pagination params
    if (qb.state.limit) {
        resultQuery.limit(qb.state.limit);
    }
    if (qb.state.offset) {
        resultQuery.offset(qb.state.offset);
    }
    if (qb.state.first) {
        resultQuery.first();
    }
    // Re-apply the sort using T values
    resultQuery.orderBy([
        // Transform "order by" clause to their T alias and prefix them with T alias
        ...orderBy.map((orderByClause)=>({
                column: prefix(partitionedQueryAlias, getStrapiOrderColumnAlias(orderByClause.column)),
                order: orderByClause.order
            })),
        // Add T.id to the order by clause to get consistent results in case several rows have the exact same order
        {
            column: `${partitionedQueryAlias}.id`,
            order: 'asc'
        }
    ]);
    return resultQuery;
};
// Utils
const alias = _.curry((alias, value)=>`${value} as ${alias}`);
const prefix = _.curry((prefix, value)=>`${prefix}.${value}`);

// We must select the join column id, however whatever it is named will overwrite an attribute of the same name
// Therefore, we will prefix with something unlikely to conflict with a user attribute
// TODO: ...and completely restrict the strapi_ prefix for an attribute name in the future
const joinColPrefix = '__strapi';
/**
 * Populate oneToOne and manyToOne relation
 * @param {*} input
 * @param {*} ctx
 * @returns
 */ const XtoOne = async (input, ctx)=>{
    const { attribute, attributeName, results, populateValue, targetMeta, isCount } = input;
    const { db, qb } = ctx;
    const fromTargetRow = (rowOrRows)=>fromRow(targetMeta, rowOrRows);
    if ('joinColumn' in attribute && attribute.joinColumn) {
        const { name: joinColumnName, referencedColumn: referencedColumnName } = attribute.joinColumn;
        const referencedValues = _.uniq(results.map((r)=>r[joinColumnName]).filter((value)=>!_.isNil(value)));
        if (_.isEmpty(referencedValues)) {
            results.forEach((result)=>{
                result[attributeName] = null;
            });
            return;
        }
        const rows = await db.entityManager.createQueryBuilder(targetMeta.uid).init(populateValue).addSelect(`${qb.alias}.${referencedColumnName}`).where({
            [referencedColumnName]: referencedValues
        }).execute({
            mapResults: false
        });
        const map = _.groupBy(referencedColumnName)(rows);
        results.forEach((result)=>{
            result[attributeName] = fromTargetRow(_.first(map[result[joinColumnName]]));
        });
        return;
    }
    if ('joinTable' in attribute && attribute.joinTable) {
        const { joinTable } = attribute;
        const qb = db.entityManager.createQueryBuilder(targetMeta.uid);
        const { name: joinColumnName, referencedColumn: referencedColumnName } = joinTable.joinColumn;
        const alias = qb.getAlias();
        const joinColAlias = `${alias}.${joinColumnName}`;
        const joinColRenameAs = `${joinColPrefix}${joinColumnName}`;
        const joinColSelect = `${joinColAlias} as ${joinColRenameAs}`;
        const referencedValues = _.uniq(results.map((r)=>r[referencedColumnName]).filter((value)=>!_.isNil(value)));
        if (isCount) {
            if (_.isEmpty(referencedValues)) {
                results.forEach((result)=>{
                    result[attributeName] = {
                        count: 0
                    };
                });
                return;
            }
            const rows = await qb.init(populateValue).join({
                alias,
                referencedTable: joinTable.name,
                referencedColumn: joinTable.inverseJoinColumn.name,
                rootColumn: joinTable.inverseJoinColumn.referencedColumn,
                rootTable: qb.alias,
                on: joinTable.on
            }).select([
                joinColAlias,
                qb.raw('count(*) AS count')
            ]).where({
                [joinColAlias]: referencedValues
            }).groupBy(joinColAlias).execute({
                mapResults: false
            });
            const map = rows.reduce((map, row)=>{
                map[row[joinColumnName]] = {
                    count: Number(row.count)
                };
                return map;
            }, {});
            results.forEach((result)=>{
                result[attributeName] = map[result[referencedColumnName]] || {
                    count: 0
                };
            });
            return;
        }
        if (_.isEmpty(referencedValues)) {
            results.forEach((result)=>{
                result[attributeName] = null;
            });
            return;
        }
        const rows = await qb.init(populateValue).join({
            alias,
            referencedTable: joinTable.name,
            referencedColumn: joinTable.inverseJoinColumn.name,
            rootColumn: joinTable.inverseJoinColumn.referencedColumn,
            rootTable: qb.alias,
            on: joinTable.on,
            orderBy: joinTable.orderBy
        }).addSelect(joinColSelect).where({
            [joinColAlias]: referencedValues
        }).execute({
            mapResults: false
        });
        const map = _.groupBy(joinColRenameAs)(rows);
        results.forEach((result)=>{
            result[attributeName] = fromTargetRow(_.first(map[result[referencedColumnName]]));
        });
    }
};
const oneToMany = async (input, ctx)=>{
    const { attribute, attributeName, results, populateValue, targetMeta, isCount } = input;
    const { db, qb } = ctx;
    const fromTargetRow = (rowOrRows)=>fromRow(targetMeta, rowOrRows);
    if ('joinColumn' in attribute && attribute.joinColumn) {
        const { name: joinColumnName, referencedColumn: referencedColumnName, on } = attribute.joinColumn;
        const referencedValues = _.uniq(results.map((r)=>r[joinColumnName]).filter((value)=>!_.isNil(value)));
        if (_.isEmpty(referencedValues)) {
            results.forEach((result)=>{
                result[attributeName] = null;
            });
            return;
        }
        const rows = await db.entityManager.createQueryBuilder(targetMeta.uid).init(populateValue).addSelect(`${qb.alias}.${referencedColumnName}`).where({
            [referencedColumnName]: referencedValues,
            ...on && typeof on === 'function' ? on({
                populateValue,
                results
            }) : {}
        }).execute({
            mapResults: false
        });
        const map = _.groupBy(referencedColumnName)(rows);
        results.forEach((result)=>{
            result[attributeName] = fromTargetRow(map[result[joinColumnName]] || []);
        });
        return;
    }
    if ('joinTable' in attribute && attribute.joinTable) {
        const { joinTable } = attribute;
        const qb = db.entityManager.createQueryBuilder(targetMeta.uid);
        const { name: joinColumnName, referencedColumn: referencedColumnName } = joinTable.joinColumn;
        const alias = qb.getAlias();
        const joinColAlias = `${alias}.${joinColumnName}`;
        const joinColRenameAs = `${joinColPrefix}${joinColumnName}`;
        const joinColSelect = `${joinColAlias} as ${joinColRenameAs}`;
        const referencedValues = _.uniq(results.map((r)=>r[referencedColumnName]).filter((value)=>!_.isNil(value)));
        if (isCount) {
            if (_.isEmpty(referencedValues)) {
                results.forEach((result)=>{
                    result[attributeName] = {
                        count: 0
                    };
                });
                return;
            }
            const rows = await qb.init(populateValue).join({
                alias,
                referencedTable: joinTable.name,
                referencedColumn: joinTable.inverseJoinColumn.name,
                rootColumn: joinTable.inverseJoinColumn.referencedColumn,
                rootTable: qb.alias,
                on: joinTable.on
            }).select([
                joinColSelect,
                qb.raw('count(*) AS count')
            ]).where({
                [joinColAlias]: referencedValues
            }).groupBy(joinColAlias).execute({
                mapResults: false
            });
            const map = rows.reduce((map, row)=>{
                map[row[joinColRenameAs]] = {
                    count: Number(row.count)
                };
                return map;
            }, {});
            results.forEach((result)=>{
                result[attributeName] = map[result[referencedColumnName]] || {
                    count: 0
                };
            });
            return;
        }
        if (_.isEmpty(referencedValues)) {
            results.forEach((result)=>{
                result[attributeName] = [];
            });
            return;
        }
        const rows = await qb.init(populateValue).join({
            alias,
            referencedTable: joinTable.name,
            referencedColumn: joinTable.inverseJoinColumn.name,
            rootColumn: joinTable.inverseJoinColumn.referencedColumn,
            rootTable: qb.alias,
            on: joinTable.on,
            orderBy: _.mapValues((v)=>populateValue.ordering || v, joinTable.orderBy)
        }).addSelect(joinColSelect).where({
            [joinColAlias]: referencedValues
        }).execute({
            mapResults: false
        });
        const map = _.groupBy(joinColRenameAs)(rows);
        results.forEach((r)=>{
            r[attributeName] = fromTargetRow(map[r[referencedColumnName]] || []);
        });
    }
};
const manyToMany = async (input, ctx)=>{
    const { attribute, attributeName, results, populateValue, targetMeta, isCount } = input;
    const { db } = ctx;
    const fromTargetRow = (rowOrRows)=>fromRow(targetMeta, rowOrRows);
    const { joinTable } = attribute;
    const populateQb = db.entityManager.createQueryBuilder(targetMeta.uid);
    const { name: joinColumnName, referencedColumn: referencedColumnName } = joinTable.joinColumn;
    const alias = populateQb.getAlias();
    const joinColAlias = `${alias}.${joinColumnName}`;
    const joinColRenameAs = `${joinColPrefix}${joinColumnName}`;
    const joinColSelect = `${joinColAlias} as ${joinColRenameAs}`;
    const referencedValues = _.uniq(results.map((r)=>r[referencedColumnName]).filter((value)=>!_.isNil(value)));
    if (isCount) {
        if (_.isEmpty(referencedValues)) {
            results.forEach((result)=>{
                result[attributeName] = {
                    count: 0
                };
            });
            return;
        }
        const rows = await populateQb.init(populateValue).join({
            alias,
            referencedTable: joinTable.name,
            referencedColumn: joinTable.inverseJoinColumn.name,
            rootColumn: joinTable.inverseJoinColumn.referencedColumn,
            rootTable: populateQb.alias,
            on: joinTable.on
        }).select([
            joinColAlias,
            populateQb.raw('count(*) AS count')
        ]).where({
            [joinColAlias]: referencedValues
        }).groupBy(joinColAlias).execute({
            mapResults: false
        });
        const map = rows.reduce((map, row)=>{
            map[row[joinColumnName]] = {
                count: Number(row.count)
            };
            return map;
        }, {});
        results.forEach((result)=>{
            result[attributeName] = map[result[referencedColumnName]] || {
                count: 0
            };
        });
        return;
    }
    if (_.isEmpty(referencedValues)) {
        results.forEach((result)=>{
            result[attributeName] = [];
        });
        return;
    }
    const rows = await populateQb.init(populateValue).join({
        alias,
        referencedTable: joinTable.name,
        referencedColumn: joinTable.inverseJoinColumn.name,
        rootColumn: joinTable.inverseJoinColumn.referencedColumn,
        rootTable: populateQb.alias,
        on: joinTable.on,
        orderBy: _.mapValues((v)=>populateValue.ordering || v, joinTable.orderBy)
    }).addSelect(joinColSelect).where({
        [joinColAlias]: referencedValues
    }).execute({
        mapResults: false
    });
    const map = _.groupBy(joinColRenameAs)(rows);
    results.forEach((result)=>{
        result[attributeName] = fromTargetRow(map[result[referencedColumnName]] || []);
    });
};
const morphX = async (input, ctx)=>{
    const { attribute, attributeName, results, populateValue, targetMeta } = input;
    const { db, uid } = ctx;
    const fromTargetRow = (rowOrRows)=>fromRow(targetMeta, rowOrRows);
    const { target, morphBy } = attribute;
    const targetAttribute = db.metadata.get(target).attributes[morphBy];
    if (targetAttribute.type === 'relation' && targetAttribute.relation === 'morphToOne') {
        const { idColumn, typeColumn } = targetAttribute.morphColumn;
        const referencedValues = _.uniq(results.map((r)=>r[idColumn.referencedColumn]).filter((value)=>!_.isNil(value)));
        if (_.isEmpty(referencedValues)) {
            results.forEach((result)=>{
                result[attributeName] = null;
            });
            return;
        }
        const rows = await db.entityManager.createQueryBuilder(target).init(populateValue)// .addSelect(`${qb.alias}.${idColumn.referencedColumn}`)
        .where({
            [idColumn.name]: referencedValues,
            [typeColumn.name]: uid
        }).execute({
            mapResults: false
        });
        const map = _.groupBy(idColumn.name)(rows);
        results.forEach((result)=>{
            const matchingRows = map[result[idColumn.referencedColumn]];
            const matchingValue = attribute.relation === 'morphOne' ? _.first(matchingRows) : matchingRows;
            result[attributeName] = fromTargetRow(matchingValue);
        });
    } else if (targetAttribute.type === 'relation' && targetAttribute.relation === 'morphToMany') {
        const { joinTable } = targetAttribute;
        const { joinColumn, morphColumn } = joinTable;
        const { idColumn, typeColumn } = morphColumn;
        const referencedValues = _.uniq(results.map((r)=>r[idColumn.referencedColumn]).filter((value)=>!_.isNil(value)));
        if (_.isEmpty(referencedValues)) {
            results.forEach((result)=>{
                result[attributeName] = attribute.relation === 'morphOne' ? null : [];
            });
            return;
        }
        // find with join table
        const qb = db.entityManager.createQueryBuilder(target);
        const alias = qb.getAlias();
        const rows = await qb.init(populateValue).join({
            alias,
            referencedTable: joinTable.name,
            referencedColumn: joinColumn.name,
            rootColumn: joinColumn.referencedColumn,
            rootTable: qb.alias,
            on: {
                ...joinTable.on || {},
                field: attributeName
            },
            orderBy: _.mapValues((v)=>populateValue.ordering || v, joinTable.orderBy)
        }).addSelect([
            `${alias}.${idColumn.name}`,
            `${alias}.${typeColumn.name}`
        ]).where({
            [`${alias}.${idColumn.name}`]: referencedValues,
            [`${alias}.${typeColumn.name}`]: uid
        }).execute({
            mapResults: false
        });
        const map = _.groupBy(idColumn.name)(rows);
        results.forEach((result)=>{
            const matchingRows = map[result[idColumn.referencedColumn]];
            const matchingValue = attribute.relation === 'morphOne' ? _.first(matchingRows) : matchingRows;
            result[attributeName] = fromTargetRow(matchingValue);
        });
    }
};
const morphToMany = async (input, ctx)=>{
    const { attribute, attributeName, results, populateValue } = input;
    const { db } = ctx;
    // find with join table
    const { joinTable } = attribute;
    const { joinColumn, morphColumn } = joinTable;
    const { idColumn, typeColumn, typeField = '__type' } = morphColumn;
    // fetch join table to create the ids map then do the same as morphToOne without the first
    const referencedValues = _.uniq(results.map((r)=>r[joinColumn.referencedColumn]).filter((value)=>!_.isNil(value)));
    const qb = db.entityManager.createQueryBuilder(joinTable.name);
    const joinRows = await qb.where({
        [joinColumn.name]: referencedValues,
        ...joinTable.on || {},
        // If the populateValue contains an "on" property,
        // only populate the types defined in it
        ...'on' in populateValue ? {
            [morphColumn.typeColumn.name]: Object.keys(populateValue.on ?? {})
        } : {}
    }).orderBy([
        joinColumn.name,
        'order'
    ]).execute({
        mapResults: false
    });
    const joinMap = _.groupBy(joinColumn.name, joinRows);
    const idsByType = joinRows.reduce((acc, result)=>{
        const idValue = result[morphColumn.idColumn.name];
        const typeValue = result[morphColumn.typeColumn.name];
        if (!idValue || !typeValue) {
            return acc;
        }
        if (!_.has(typeValue, acc)) {
            acc[typeValue] = [];
        }
        acc[typeValue].push(idValue);
        return acc;
    }, {});
    const map = {};
    const { on, ...typePopulate } = populateValue;
    for (const type of Object.keys(idsByType)){
        const ids = idsByType[type];
        // type was removed but still in morph relation
        if (!db.metadata.get(type)) {
            map[type] = {};
            continue;
        }
        const qb = db.entityManager.createQueryBuilder(type);
        const rows = await qb.init(on?.[type] ?? typePopulate).addSelect(`${qb.alias}.${idColumn.referencedColumn}`).where({
            [idColumn.referencedColumn]: ids
        }).execute({
            mapResults: false
        });
        map[type] = _.groupBy(idColumn.referencedColumn)(rows);
    }
    results.forEach((result)=>{
        const joinResults = joinMap[result[joinColumn.referencedColumn]] || [];
        const matchingRows = joinResults.flatMap((joinResult)=>{
            const id = joinResult[idColumn.name];
            const type = joinResult[typeColumn.name];
            const targetMeta = db.metadata.get(type);
            const fromTargetRow = (rowOrRows)=>fromRow(targetMeta, rowOrRows);
            return (map[type][id] || []).map((row)=>{
                return {
                    [typeField]: type,
                    ...fromTargetRow(row)
                };
            });
        });
        result[attributeName] = matchingRows;
    });
};
const morphToOne = async (input, ctx)=>{
    const { attribute, attributeName, results, populateValue } = input;
    const { db } = ctx;
    const { morphColumn } = attribute;
    const { idColumn, typeColumn } = morphColumn;
    // make a map for each type what ids to return
    // make a nested map per id
    const idsByType = results.reduce((acc, result)=>{
        const idValue = result[morphColumn.idColumn.name];
        const typeValue = result[morphColumn.typeColumn.name];
        if (!idValue || !typeValue) {
            return acc;
        }
        if (!(typeValue in acc)) {
            acc[typeValue] = [];
        }
        acc[typeValue].push(idValue);
        return acc;
    }, {});
    const map = {};
    const { on, ...typePopulate } = populateValue;
    for (const type of Object.keys(idsByType)){
        const ids = idsByType[type];
        // type was removed but still in morph relation
        if (!db.metadata.get(type)) {
            map[type] = {};
            return;
        }
        const qb = db.entityManager.createQueryBuilder(type);
        const rows = await qb.init(on?.[type] ?? typePopulate).addSelect(`${qb.alias}.${idColumn.referencedColumn}`).where({
            [idColumn.referencedColumn]: ids
        }).execute({
            mapResults: false
        });
        map[type] = _.groupBy(idColumn.referencedColumn)(rows);
    }
    results.forEach((result)=>{
        const id = result[idColumn.name];
        const type = result[typeColumn.name];
        if (!type || !id) {
            result[attributeName] = null;
            return;
        }
        const matchingRows = map[type][id];
        const fromTargetRow = (rowOrRows)=>fromRow(db.metadata.get(type), rowOrRows);
        result[attributeName] = fromTargetRow(_.first(matchingRows));
    });
};
//  TODO: Omit limit & offset to avoid needing a query per result to avoid making too many queries
const pickPopulateParams = (populate)=>{
    const fieldsToPick = [
        'select',
        'count',
        'where',
        'populate',
        'orderBy',
        'filters',
        'ordering',
        'on'
    ];
    if (populate.count !== true) {
        fieldsToPick.push('limit', 'offset');
    }
    return _.pick(fieldsToPick, populate);
};
const applyPopulate = async (results, populate, ctx)=>{
    const { db, uid, qb } = ctx;
    const meta = db.metadata.get(uid);
    if (_.isEmpty(results)) {
        return results;
    }
    for (const attributeName of Object.keys(populate)){
        const attribute = meta.attributes[attributeName];
        if (attribute.type !== 'relation') {
            throw new Error(`Invalid populate attribute ${attributeName}`);
        }
        const populateValue = {
            filters: qb.state.filters,
            ...pickPopulateParams(populate[attributeName])
        };
        const isCount = 'count' in populateValue && populateValue.count === true;
        switch(attribute.relation){
            case 'oneToOne':
            case 'manyToOne':
                {
                    const targetMeta = db.metadata.get(attribute.target);
                    const input = {
                        attribute,
                        attributeName,
                        results,
                        populateValue,
                        targetMeta,
                        isCount
                    };
                    await XtoOne(input, ctx);
                    break;
                }
            case 'oneToMany':
                {
                    const targetMeta = db.metadata.get(attribute.target);
                    const input = {
                        attribute,
                        attributeName,
                        results,
                        populateValue,
                        targetMeta,
                        isCount
                    };
                    await oneToMany(input, ctx);
                    break;
                }
            case 'manyToMany':
                {
                    const targetMeta = db.metadata.get(attribute.target);
                    const input = {
                        attribute,
                        attributeName,
                        results,
                        populateValue,
                        targetMeta,
                        isCount
                    };
                    await manyToMany(input, ctx);
                    break;
                }
            case 'morphOne':
            case 'morphMany':
                {
                    const targetMeta = db.metadata.get(attribute.target);
                    const input = {
                        attribute,
                        attributeName,
                        results,
                        populateValue,
                        targetMeta,
                        isCount
                    };
                    await morphX(input, ctx);
                    break;
                }
            case 'morphToMany':
                {
                    const input = {
                        attribute,
                        attributeName,
                        results,
                        populateValue,
                        isCount
                    };
                    await morphToMany(input, ctx);
                    break;
                }
            case 'morphToOne':
                {
                    const input = {
                        attribute,
                        attributeName,
                        results,
                        populateValue,
                        isCount
                    };
                    await morphToOne(input, ctx);
                    break;
                }
        }
    }
};

const getRootLevelPopulate = (meta)=>{
    const populate = {};
    for (const attributeName of Object.keys(meta.attributes)){
        const attribute = meta.attributes[attributeName];
        if (attribute.type === 'relation') {
            populate[attributeName] = true;
        }
    }
    return populate;
};
/**
 * Converts and prepares the query for populate
 *
 * @param {boolean|string[]|object} populate populate param
 * @param {object} ctx query context
 * @param {object} ctx.db database instance
 * @param {object} ctx.qb query builder instance
 * @param {string} ctx.uid model uid
 */ const processPopulate = (populate, ctx)=>{
    const { qb, db, uid } = ctx;
    const meta = db.metadata.get(uid);
    let populateMap = {};
    if (populate === false || _.isNil(populate)) {
        return null;
    }
    if (populate === true) {
        populateMap = getRootLevelPopulate(meta);
    } else if (Array.isArray(populate)) {
        for (const key of populate){
            const [root, ...rest] = key.split('.');
            if (rest.length > 0) {
                const subPopulate = rest.join('.');
                if (populateMap[root]) {
                    const populateValue = populateMap[root];
                    if (populateValue === true) {
                        populateMap[root] = {
                            populate: [
                                subPopulate
                            ]
                        };
                    } else {
                        populateValue.populate = [
                            subPopulate
                        ].concat(populateValue.populate ?? []);
                    }
                } else {
                    populateMap[root] = {
                        populate: [
                            subPopulate
                        ]
                    };
                }
            } else {
                populateMap[root] = populateMap[root] ? populateMap[root] : true;
            }
        }
    } else {
        populateMap = populate;
    }
    if (!_.isPlainObject(populateMap)) {
        throw new Error('Populate must be an object');
    }
    const finalPopulate = {};
    for (const key of Object.keys(populateMap)){
        const attribute = meta.attributes[key];
        if (!attribute) {
            continue;
        }
        if (!isRelation(attribute.type)) {
            continue;
        }
        // Make sure to query the join column value if needed,
        // so that we can apply the populate later on
        if ('joinColumn' in attribute && attribute.joinColumn) {
            qb.addSelect(attribute.joinColumn.name);
        }
        // Make sure id is present for future populate queries
        if (_.has('id', meta.attributes)) {
            qb.addSelect('id');
        }
        finalPopulate[key] = populateMap[key];
    }
    return finalPopulate;
};

const isRecord$1 = (value)=>isPlainObject(value);
const castValue = (value, attribute)=>{
    if (!attribute) {
        return value;
    }
    if (isScalar(attribute.type) && !isKnexQuery(value)) {
        const field = createField(attribute);
        return value === null ? null : field.toDB(value);
    }
    return value;
};
const processSingleAttributeWhere = (attribute, where, operator = '$eq')=>{
    if (!isRecord$1(where)) {
        if (isOperatorOfType('cast', operator)) {
            return castValue(where, attribute);
        }
        return where;
    }
    const filters = {};
    for (const key of Object.keys(where)){
        const value = where[key];
        if (!isOperatorOfType('where', key)) {
            throw new Error(`Undefined attribute level operator ${key}`);
        }
        filters[key] = processAttributeWhere(attribute, value, key);
    }
    return filters;
};
const processAttributeWhere = (attribute, where, operator = '$eq')=>{
    if (isArray(where)) {
        return where.map((sub)=>processSingleAttributeWhere(attribute, sub, operator));
    }
    return processSingleAttributeWhere(attribute, where, operator);
};
const processNested = (where, ctx)=>{
    if (!isRecord$1(where)) {
        return where;
    }
    return processWhere(where, ctx);
};
const processRelationWhere = (where, ctx)=>{
    const { qb, alias } = ctx;
    const idAlias = qb.aliasColumn('id', alias);
    if (!isRecord$1(where)) {
        return {
            [idAlias]: where
        };
    }
    const keys = Object.keys(where);
    const operatorKeys = keys.filter((key)=>isOperator(key));
    if (operatorKeys.length > 0 && operatorKeys.length !== keys.length) {
        throw new Error(`Operator and non-operator keys cannot be mixed in a relation where clause`);
    }
    if (operatorKeys.length > 1) {
        throw new Error(`Only one operator key is allowed in a relation where clause, but found: ${operatorKeys}`);
    }
    if (operatorKeys.length === 1) {
        const operator = operatorKeys[0];
        if (isOperatorOfType('group', operator)) {
            return processWhere(where, ctx);
        }
        return {
            [idAlias]: {
                [operator]: processNested(where[operator], ctx)
            }
        };
    }
    return processWhere(where, ctx);
};
function processWhere(where, ctx) {
    if (!isArray(where) && !isRecord$1(where)) {
        throw new Error('Where must be an array or an object');
    }
    if (isArray(where)) {
        return where.map((sub)=>processWhere(sub, ctx));
    }
    const { db, uid, qb, alias } = ctx;
    const meta = db.metadata.get(uid);
    const filters = {};
    // for each key in where
    for (const key of Object.keys(where)){
        const value = where[key];
        // if operator $and $or -> process recursively
        if (isOperatorOfType('group', key)) {
            if (!Array.isArray(value)) {
                throw new Error(`Operator ${key} must be an array`);
            }
            filters[key] = value.map((sub)=>processNested(sub, ctx));
            continue;
        }
        if (key === '$not') {
            filters[key] = processNested(value, ctx);
            continue;
        }
        if (isOperatorOfType('where', key)) {
            throw new Error(`Only $and, $or and $not can only be used as root level operators. Found ${key}.`);
        }
        const attribute = meta.attributes[key];
        if (!attribute) {
            filters[qb.aliasColumn(key, alias)] = processAttributeWhere(null, value);
            continue;
        }
        if (isRelation(attribute.type) && 'target' in attribute) {
            // attribute
            const subAlias = createJoin(ctx, {
                alias: alias || qb.alias,
                attributeName: key,
                attribute
            });
            const nestedWhere = processRelationWhere(value, {
                db,
                qb,
                alias: subAlias,
                uid: attribute.target
            });
            // TODO: use a better merge logic (push to $and when collisions)
            Object.assign(filters, nestedWhere);
            continue;
        }
        if (isScalar(attribute.type)) {
            const columnName = toColumnName(meta, key);
            const aliasedColumnName = qb.aliasColumn(columnName, alias);
            filters[aliasedColumnName] = processAttributeWhere(attribute, value);
            continue;
        }
        throw new Error(`You cannot filter on ${attribute.type} types`);
    }
    return filters;
}
// TODO: add type casting per operator at some point
const applyOperator = (qb, column, operator, value)=>{
    if (Array.isArray(value) && !isOperatorOfType('array', operator)) {
        return qb.where((subQB)=>{
            value.forEach((subValue)=>subQB.orWhere((innerQB)=>{
                    applyOperator(innerQB, column, operator, subValue);
                }));
        });
    }
    switch(operator){
        case '$not':
            {
                qb.whereNot((qb)=>applyWhereToColumn(qb, column, value));
                break;
            }
        case '$in':
            {
                // @ts-ignore
                // TODO: fix in v5
                qb.whereIn(column, isKnexQuery(value) ? value : castArray(value));
                break;
            }
        case '$notIn':
            {
                // @ts-ignore
                // TODO: fix in v5
                qb.whereNotIn(column, isKnexQuery(value) ? value : castArray(value));
                break;
            }
        case '$eq':
            {
                if (value === null) {
                    qb.whereNull(column);
                    break;
                }
                qb.where(column, value);
                break;
            }
        case '$eqi':
            {
                if (value === null) {
                    qb.whereNull(column);
                    break;
                }
                qb.whereRaw(`${fieldLowerFn(qb)} LIKE LOWER(?)`, [
                    column,
                    `${value}`
                ]);
                break;
            }
        case '$ne':
            {
                if (value === null) {
                    qb.whereNotNull(column);
                    break;
                }
                qb.where(column, '<>', value);
                break;
            }
        case '$nei':
            {
                if (value === null) {
                    qb.whereNotNull(column);
                    break;
                }
                qb.whereRaw(`${fieldLowerFn(qb)} NOT LIKE LOWER(?)`, [
                    column,
                    `${value}`
                ]);
                break;
            }
        case '$gt':
            {
                qb.where(column, '>', value);
                break;
            }
        case '$gte':
            {
                qb.where(column, '>=', value);
                break;
            }
        case '$lt':
            {
                qb.where(column, '<', value);
                break;
            }
        case '$lte':
            {
                qb.where(column, '<=', value);
                break;
            }
        case '$null':
            {
                if (value) {
                    qb.whereNull(column);
                } else {
                    qb.whereNotNull(column);
                }
                break;
            }
        case '$notNull':
            {
                if (value) {
                    qb.whereNotNull(column);
                } else {
                    qb.whereNull(column);
                }
                break;
            }
        case '$between':
            {
                qb.whereBetween(column, value);
                break;
            }
        case '$startsWith':
            {
                qb.where(column, 'like', `${value}%`);
                break;
            }
        case '$startsWithi':
            {
                qb.whereRaw(`${fieldLowerFn(qb)} LIKE LOWER(?)`, [
                    column,
                    `${value}%`
                ]);
                break;
            }
        case '$endsWith':
            {
                qb.where(column, 'like', `%${value}`);
                break;
            }
        case '$endsWithi':
            {
                qb.whereRaw(`${fieldLowerFn(qb)} LIKE LOWER(?)`, [
                    column,
                    `%${value}`
                ]);
                break;
            }
        case '$contains':
            {
                qb.where(column, 'like', `%${value}%`);
                break;
            }
        case '$notContains':
            {
                qb.whereNot(column, 'like', `%${value}%`);
                break;
            }
        case '$containsi':
            {
                qb.whereRaw(`${fieldLowerFn(qb)} LIKE LOWER(?)`, [
                    column,
                    `%${value}%`
                ]);
                break;
            }
        case '$notContainsi':
            {
                qb.whereRaw(`${fieldLowerFn(qb)} NOT LIKE LOWER(?)`, [
                    column,
                    `%${value}%`
                ]);
                break;
            }
        // Experimental, only for internal use
        // Only on MySQL, PostgreSQL and CockroachDB.
        // https://knexjs.org/guide/query-builder.html#wherejsonsupersetof
        case '$jsonSupersetOf':
            {
                qb.whereJsonSupersetOf(column, value);
                break;
            }
        // TODO: Add more JSON operators: whereJsonObject, whereJsonPath, whereJsonSubsetOf
        // TODO: relational operators every/some/exists/size ...
        default:
            {
                throw new Error(`Undefined attribute level operator ${operator}`);
            }
    }
};
const applyWhereToColumn = (qb, column, columnWhere)=>{
    if (!isRecord$1(columnWhere)) {
        if (Array.isArray(columnWhere)) {
            return qb.whereIn(column, columnWhere);
        }
        return qb.where(column, columnWhere);
    }
    const keys = Object.keys(columnWhere);
    keys.forEach((operator)=>{
        const value = columnWhere[operator];
        applyOperator(qb, column, operator, value);
    });
};
const applyWhere = (qb, where)=>{
    if (!isArray(where) && !isRecord$1(where)) {
        throw new Error('Where must be an array or an object');
    }
    if (isArray(where)) {
        return qb.where((subQB)=>where.forEach((subWhere)=>applyWhere(subQB, subWhere)));
    }
    Object.keys(where).forEach((key)=>{
        if (key === '$and') {
            const value = where[key] ?? [];
            return qb.where((subQB)=>{
                value.forEach((v)=>applyWhere(subQB, v));
            });
        }
        if (key === '$or') {
            const value = where[key] ?? [];
            return qb.where((subQB)=>{
                value.forEach((v)=>subQB.orWhere((inner)=>applyWhere(inner, v)));
            });
        }
        if (key === '$not') {
            const value = where[key] ?? {};
            return qb.whereNot((qb)=>applyWhere(qb, value));
        }
        applyWhereToColumn(qb, key, where[key]);
    });
};
const fieldLowerFn = (qb)=>{
    // Postgres requires string to be passed
    if (qb.client.dialect === 'postgresql') {
        return 'LOWER(CAST(?? AS VARCHAR))';
    }
    return 'LOWER(??)';
};

const knexQueryDone = Symbol('knexQueryDone');
const knexPerformingQuery = Symbol('knexPerformingQuery');
class ReadableStrapiQuery extends Readable {
    _destroy(err, cb) {
        // If the stream is destroyed while a query is being made, then wait for a
        // kQueryDone event to be emitted before actually destroying the stream
        if (this[knexPerformingQuery]) {
            this.once(knexQueryDone, (er)=>cb(err || er));
        } else {
            cb(err);
        }
    }
    /**
   * Custom ._read() implementation
   *
   *  NOTE: Here "size" means the number of entities to be read from the database.
   *  Not the actual byte size, as it would mean that we need to return partial entities.
   *
   */ async _read(size) {
        const query = this._query;
        // Remove the original offset & limit properties from the query
        // Theoretically, they would be replaced by calling them again, but this is just to be sure
        query.clear('limit').clear('offset');
        // Define the maximum read size based on the limit and the requested size
        // NOTE: size is equal to _batchSize by default. Since we want to allow customizing it on
        // the fly, we need to use its value instead of batchSize when computing the maxReadSize value
        const maxReadSize = // if no limit is defined in the query, use the given size,
        // otherwise, use the smallest value between the two
        this._limit === null ? size : Math.min(size, this._limit);
        // Compute the limit for the next query
        const limit = // If a limit is defined
        this._limit !== null && // And reading `maxReadSize` would fetch too many entities (> _limit)
        this._fetched + maxReadSize > this._limit ? this._limit - this._fetched : maxReadSize;
        // If we don't have anything left to read (_limit === _fetched),
        // don't bother making the query and end the stream by pushing null
        if (limit <= 0) {
            this.push(null);
            return;
        }
        // Compute the offset (base offset + number of entities already fetched)
        const offset = this._offset + this._fetched;
        // Update the query with the new values (offset + limit)
        query.offset(offset).limit(limit);
        // Lock the ._destroy()
        this[knexPerformingQuery] = true;
        let results;
        let count;
        let err;
        try {
            // Execute the query and store the results & count
            results = await query;
            const { populate } = this._qb.state;
            // Applies the populate if needed
            if (populate) {
                await applyPopulate(results, populate, {
                    qb: this._qb,
                    uid: this._uid,
                    db: this._db
                });
            }
            // Map results if asked to
            if (this._mapResults) {
                results = fromRow(this._meta, results);
            }
            count = results.length;
        } catch (e) {
            err = e;
        }
        // Unlock the ._destroy()
        this[knexPerformingQuery] = false;
        // Tell ._destroy() that it's now safe to close the db connection
        if (this.destroyed) {
            this.emit(knexQueryDone);
            return;
        }
        // If there is an error, destroy with the given error
        if (err) {
            this.destroy(err);
            return;
        }
        // Update the amount of fetched entities
        this._fetched += count;
        // While there is at least one value to unpack
        for (const result of results){
            this.push(result);
        }
        // If the amount of fetched entities is smaller than the
        // maximum read size, Then push null to close the stream
        if (this._fetched === this._limit || count < this._batchSize) {
            this.push(null);
        }
    }
    constructor({ qb, db, uid, mapResults = true, batchSize = 500 }){
        super({
            objectMode: true,
            highWaterMark: batchSize
        });
        // Extract offset & limit from the query-builder's state
        const { offset, limit } = qb.state;
        // Original offset value
        this._offset = isFinite(offset) ? Number(offset) : 0;
        // Max amount of entities to fetch, force null as undefined value
        this._limit = isFinite(limit) ? Number(limit) : null;
        // Total amount of entities fetched
        this._fetched = 0;
        /**
     * Original query
     */ this._query = qb.getKnexQuery();
        // Query Builder instance
        this._qb = qb;
        // Database related properties
        this._db = db;
        this._uid = uid;
        this._meta = db.metadata.get(uid);
        // Stream params
        this._batchSize = batchSize;
        this._mapResults = mapResults;
        // States
        this[knexPerformingQuery] = false;
    }
}

const createQueryBuilder = (uid, db, initialState = {})=>{
    const meta = db.metadata.get(uid);
    const { tableName } = meta;
    const state = _.defaults({
        type: 'select',
        select: [],
        count: null,
        max: null,
        first: false,
        data: null,
        where: [],
        joins: [],
        populate: null,
        limit: null,
        offset: null,
        transaction: null,
        forUpdate: false,
        onConflict: null,
        merge: null,
        ignore: false,
        orderBy: [],
        groupBy: [],
        increments: [],
        decrements: [],
        aliasCounter: 0,
        filters: null,
        search: null
    }, initialState);
    const getAlias = ()=>{
        const alias = `t${state.aliasCounter}`;
        state.aliasCounter += 1;
        return alias;
    };
    return {
        alias: getAlias(),
        getAlias,
        state,
        clone () {
            return createQueryBuilder(uid, db, state);
        },
        select (args) {
            state.type = 'select';
            state.select = _.uniq(_.castArray(args));
            return this;
        },
        addSelect (args) {
            state.select = _.uniq([
                ...state.select,
                ..._.castArray(args)
            ]);
            return this;
        },
        insert (data) {
            state.type = 'insert';
            state.data = data;
            return this;
        },
        onConflict (args) {
            state.onConflict = args;
            return this;
        },
        merge (args) {
            state.merge = args;
            return this;
        },
        ignore () {
            state.ignore = true;
            return this;
        },
        delete () {
            state.type = 'delete';
            return this;
        },
        ref (name) {
            return db.connection.ref(toColumnName(meta, name));
        },
        update (data) {
            state.type = 'update';
            state.data = data;
            return this;
        },
        increment (column, amount = 1) {
            state.type = 'update';
            state.increments.push({
                column,
                amount
            });
            return this;
        },
        decrement (column, amount = 1) {
            state.type = 'update';
            state.decrements.push({
                column,
                amount
            });
            return this;
        },
        count (count = 'id') {
            state.type = 'count';
            state.count = count;
            return this;
        },
        max (column) {
            state.type = 'max';
            state.max = column;
            return this;
        },
        where (where = {}) {
            if (!_.isPlainObject(where)) {
                throw new Error('Where must be an object');
            }
            state.where.push(where);
            return this;
        },
        limit (limit) {
            state.limit = limit;
            return this;
        },
        offset (offset) {
            state.offset = offset;
            return this;
        },
        orderBy (orderBy) {
            state.orderBy = orderBy;
            return this;
        },
        groupBy (groupBy) {
            state.groupBy = groupBy;
            return this;
        },
        populate (populate) {
            state.populate = populate;
            return this;
        },
        search (query) {
            state.search = query;
            return this;
        },
        transacting (transaction) {
            state.transaction = transaction;
            return this;
        },
        forUpdate () {
            state.forUpdate = true;
            return this;
        },
        init (params = {}) {
            const { _q, filters, where, select, limit, offset, orderBy, groupBy, populate } = params;
            if (!_.isNil(where)) {
                this.where(where);
            }
            if (!_.isNil(_q)) {
                this.search(_q);
            }
            if (!_.isNil(select)) {
                this.select(select);
            } else {
                this.select('*');
            }
            if (!_.isNil(limit)) {
                this.limit(limit);
            }
            if (!_.isNil(offset)) {
                this.offset(offset);
            }
            if (!_.isNil(orderBy)) {
                this.orderBy(orderBy);
            }
            if (!_.isNil(groupBy)) {
                this.groupBy(groupBy);
            }
            if (!_.isNil(populate)) {
                this.populate(populate);
            }
            if (!_.isNil(filters)) {
                this.filters(filters);
            }
            return this;
        },
        filters (filters) {
            state.filters = filters;
        },
        first () {
            state.first = true;
            return this;
        },
        join (join) {
            if (!join.targetField) {
                state.joins.push(join);
                return this;
            }
            const model = db.metadata.get(uid);
            const attribute = model.attributes[join.targetField];
            createJoin({
                db,
                qb: this,
                uid
            }, {
                alias: this.alias,
                refAlias: join.alias,
                attributeName: join.targetField,
                attribute
            });
            return this;
        },
        mustUseAlias () {
            return [
                'select',
                'count'
            ].includes(state.type);
        },
        aliasColumn (key, alias) {
            if (typeof key !== 'string') {
                return key;
            }
            if (key.indexOf('.') >= 0) {
                return key;
            }
            if (!_.isNil(alias)) {
                return `${alias}.${key}`;
            }
            return this.mustUseAlias() ? `${this.alias}.${key}` : key;
        },
        raw: db.connection.raw.bind(db.connection),
        shouldUseSubQuery () {
            return [
                'delete',
                'update'
            ].includes(state.type) && state.joins.length > 0;
        },
        runSubQuery () {
            this.select('id');
            const subQB = this.getKnexQuery();
            const nestedSubQuery = db.getConnection().select('id').from(subQB.as('subQuery'));
            const connection = db.getConnection(tableName);
            return connection[state.type]().whereIn('id', nestedSubQuery);
        },
        processState () {
            state.orderBy = processOrderBy(state.orderBy, {
                qb: this,
                uid,
                db
            });
            if (!_.isNil(state.filters)) {
                if (_.isFunction(state.filters)) {
                    const filters = state.filters({
                        qb: this,
                        uid,
                        meta,
                        db
                    });
                    if (!_.isNil(filters)) {
                        state.where.push(filters);
                    }
                } else {
                    state.where.push(state.filters);
                }
            }
            state.where = processWhere(state.where, {
                qb: this,
                uid,
                db
            });
            state.populate = processPopulate(state.populate, {
                qb: this,
                uid,
                db
            });
            state.data = toRow(meta, state.data);
            this.processSelect();
        },
        shouldUseDistinct () {
            return state.joins.length > 0 && _.isEmpty(state.groupBy);
        },
        shouldUseDeepSort () {
            return state.orderBy.filter(({ column })=>column.indexOf('.') >= 0).filter(({ column })=>{
                const col = column.split('.');
                for(let i = 0; i < col.length - 1; i += 1){
                    const el = col[i];
                    // order by "rel"."xxx"
                    const isRelationAttribute = meta.attributes[el]?.type === 'relation';
                    // order by "t2"."xxx"
                    const isAliasedRelation = Object.values(state.joins).map((join)=>join.alias).includes(el);
                    if (isRelationAttribute || isAliasedRelation) {
                        return true;
                    }
                }
                return false;
            }).length > 0;
        },
        processSelect () {
            state.select = state.select.map((field)=>{
                if (isKnexQuery(field)) {
                    return field;
                }
                return toColumnName(meta, field);
            });
            if (this.shouldUseDistinct()) {
                const joinsOrderByColumns = state.joins.flatMap((join)=>{
                    return _.keys(join.orderBy).map((key)=>this.aliasColumn(key, join.alias));
                });
                const orderByColumns = state.orderBy.map(({ column })=>column);
                state.select = _.uniq([
                    ...joinsOrderByColumns,
                    ...orderByColumns,
                    ...state.select
                ]);
            }
        },
        getKnexQuery () {
            if (!state.type) {
                this.select('*');
            }
            const aliasedTableName = this.mustUseAlias() ? `${tableName} as ${this.alias}` : tableName;
            const qb = db.getConnection(aliasedTableName);
            if (this.shouldUseSubQuery()) {
                return this.runSubQuery();
            }
            this.processState();
            switch(state.type){
                case 'select':
                    {
                        qb.select(state.select.map((column)=>this.aliasColumn(column)));
                        if (this.shouldUseDistinct()) {
                            qb.distinct();
                        }
                        break;
                    }
                case 'count':
                    {
                        const dbColumnName = this.aliasColumn(toColumnName(meta, state.count));
                        if (this.shouldUseDistinct()) {
                            qb.countDistinct({
                                count: dbColumnName
                            });
                        } else {
                            qb.count({
                                count: dbColumnName
                            });
                        }
                        break;
                    }
                case 'max':
                    {
                        const dbColumnName = this.aliasColumn(toColumnName(meta, state.max));
                        qb.max({
                            max: dbColumnName
                        });
                        break;
                    }
                case 'insert':
                    {
                        qb.insert(state.data);
                        if (db.dialect.useReturning() && _.has('id', meta.attributes)) {
                            qb.returning('id');
                        }
                        break;
                    }
                case 'update':
                    {
                        if (state.data) {
                            qb.update(state.data);
                        }
                        break;
                    }
                case 'delete':
                    {
                        qb.delete();
                        break;
                    }
                case 'truncate':
                    {
                        qb.truncate();
                        break;
                    }
                default:
                    {
                        throw new Error('Unknown query type');
                    }
            }
            if (state.transaction) {
                qb.transacting(state.transaction);
            }
            if (state.forUpdate) {
                qb.forUpdate();
            }
            if (!_.isEmpty(state.increments)) {
                state.increments.forEach((incr)=>qb.increment(incr.column, incr.amount));
            }
            if (!_.isEmpty(state.decrements)) {
                state.decrements.forEach((decr)=>qb.decrement(decr.column, decr.amount));
            }
            if (state.onConflict) {
                if (state.merge) {
                    qb.onConflict(state.onConflict).merge(state.merge);
                } else if (state.ignore) {
                    qb.onConflict(state.onConflict).ignore();
                }
            }
            if (state.limit) {
                qb.limit(state.limit);
            }
            if (state.offset) {
                qb.offset(state.offset);
            }
            if (state.orderBy.length > 0) {
                qb.orderBy(state.orderBy);
            }
            if (state.first) {
                qb.first();
            }
            if (state.groupBy.length > 0) {
                qb.groupBy(state.groupBy);
            }
            // if there are joins and it is a delete or update use a sub query
            if (state.where) {
                applyWhere(qb, state.where);
            }
            // if there are joins and it is a delete or update use a sub query
            if (state.search) {
                qb.where((subQb)=>{
                    applySearch(subQb, state.search, {
                        qb: this,
                        db,
                        uid
                    });
                });
            }
            if (state.joins.length > 0) {
                applyJoins(qb, state.joins);
            }
            if (this.shouldUseDeepSort()) {
                return wrapWithDeepSort(qb, {
                    qb: this,
                    db,
                    uid
                });
            }
            return qb;
        },
        async execute ({ mapResults = true } = {}) {
            try {
                const qb = this.getKnexQuery();
                const transaction = transactionCtx.get();
                if (transaction) {
                    qb.transacting(transaction);
                }
                const rows = await qb;
                if (state.populate && !_.isNil(rows)) {
                    await applyPopulate(_.castArray(rows), state.populate, {
                        qb: this,
                        uid,
                        db
                    });
                }
                let results = rows;
                if (mapResults && state.type === 'select') {
                    results = fromRow(meta, rows);
                }
                return results;
            } catch (error) {
                if (error instanceof Error) {
                    db.dialect.transformErrors(error);
                } else {
                    throw error;
                }
            }
        },
        stream ({ mapResults = true } = {}) {
            if (state.type === 'select') {
                return new ReadableStrapiQuery({
                    qb: this,
                    db,
                    uid,
                    mapResults
                });
            }
            throw new DatabaseError(`query-builder.stream() has been called with an unsupported query type: "${state.type}"`);
        }
    };
};

const withDefaultPagination = (params)=>{
    const { page = 1, pageSize = 10, ...rest } = params;
    return {
        page: Number(page),
        pageSize: Number(pageSize),
        ...rest
    };
};
const withOffsetLimit = (params)=>{
    const { page, pageSize, ...rest } = withDefaultPagination(params);
    const offset = Math.max(page - 1, 0) * pageSize;
    const limit = pageSize;
    const query = {
        ...rest,
        limit,
        offset
    };
    return [
        query,
        {
            page,
            pageSize
        }
    ];
};
const createRepository = (uid, db)=>{
    return {
        findOne (params = {}) {
            return db.entityManager.findOne(uid, params);
        },
        findMany (params = {}) {
            return db.entityManager.findMany(uid, params);
        },
        findWithCount (params = {}) {
            return Promise.all([
                db.entityManager.findMany(uid, params),
                db.entityManager.count(uid, params)
            ]);
        },
        async findPage (params) {
            const [query, { page, pageSize }] = withOffsetLimit(params);
            const [results, total] = await Promise.all([
                db.entityManager.findMany(uid, query),
                db.entityManager.count(uid, query)
            ]);
            return {
                results,
                pagination: {
                    page,
                    pageSize,
                    pageCount: Math.ceil(total / pageSize),
                    total
                }
            };
        },
        create (params) {
            return db.entityManager.create(uid, params);
        },
        createMany (params) {
            return db.entityManager.createMany(uid, params);
        },
        update (params) {
            return db.entityManager.update(uid, params);
        },
        updateMany (params) {
            return db.entityManager.updateMany(uid, params);
        },
        delete (params) {
            return db.entityManager.delete(uid, params);
        },
        deleteMany (params = {}) {
            return db.entityManager.deleteMany(uid, params);
        },
        count (params) {
            return db.entityManager.count(uid, params);
        },
        attachRelations (id, data) {
            return db.entityManager.attachRelations(uid, id, data);
        },
        async updateRelations (id, data) {
            const trx = await db.transaction();
            try {
                await db.entityManager.updateRelations(uid, id, data, {
                    transaction: trx.get()
                });
                return await trx.commit();
            } catch (e) {
                await trx.rollback();
                throw e;
            }
        },
        deleteRelations (id) {
            return db.entityManager.deleteRelations(uid, id);
        },
        populate (entity, populate) {
            return db.entityManager.populate(uid, entity, populate);
        },
        load (entity, fields, params) {
            return db.entityManager.load(uid, entity, fields, params);
        },
        async loadPages (entity, field, params) {
            if (!isString$1(field)) {
                throw new Error(`Invalid load. Expected ${field} to be a string`);
            }
            const { attributes } = db.metadata.get(uid);
            const attribute = attributes[field];
            if (!attribute || attribute.type !== 'relation' || !attribute.relation || ![
                'oneToMany',
                'manyToMany'
            ].includes(attribute.relation)) {
                throw new Error(`Invalid load. Expected ${field} to be an anyToMany relational attribute`);
            }
            const [query, { page, pageSize }] = withOffsetLimit(params);
            const [results, { count: total }] = await Promise.all([
                db.entityManager.load(uid, entity, field, query),
                db.entityManager.load(uid, entity, field, {
                    ...query,
                    count: true
                })
            ]);
            return {
                results,
                pagination: {
                    page,
                    pageSize,
                    pageCount: Math.ceil(total / pageSize),
                    total
                }
            };
        }
    };
};

/* eslint-disable @typescript-eslint/naming-convention */ // allow __type
const getMorphToManyRowsLinkedToMorphOne = (rows, { uid, attributeName, typeColumn, db })=>rows.filter((row)=>{
        const relatedType = row[typeColumn.name];
        const field = row.field;
        const targetAttribute = db.metadata.get(relatedType).attributes[field];
        // ensure targeted field is the right one + check if it is a morphOne
        return targetAttribute?.target === uid && targetAttribute?.morphBy === attributeName && targetAttribute?.relation === 'morphOne';
    });
const deleteRelatedMorphOneRelationsAfterMorphToManyUpdate = async (rows, { uid, attributeName, joinTable, db, transaction: trx })=>{
    const { morphColumn } = joinTable;
    const { idColumn, typeColumn } = morphColumn;
    const morphOneRows = getMorphToManyRowsLinkedToMorphOne(rows, {
        uid,
        attributeName,
        typeColumn,
        db
    });
    const groupByType = groupBy(typeColumn.name);
    const groupByField = groupBy('field');
    const typeAndFieldIdsGrouped = pipe(groupByType, mapValues(groupByField))(morphOneRows);
    const orWhere = [];
    for (const [type, v] of Object.entries(typeAndFieldIdsGrouped)){
        for (const [field, arr] of Object.entries(v)){
            orWhere.push({
                [typeColumn.name]: type,
                field,
                [idColumn.name]: {
                    $in: map(idColumn.name, arr)
                }
            });
        }
    }
    if (!isEmpty(orWhere)) {
        await createQueryBuilder(joinTable.name, db).delete().where({
            $or: orWhere
        }).transacting(trx).execute();
    }
};
/**
 * Encoding utilities for polymorphic relations.
 *
 * In some scenarios is useful to encode both the id & __type of the relation
 * to have a unique identifier for the relation. (e.g. relations reordering)
 */ const encodePolymorphicId = (id, __type)=>{
    return `${id}:::${__type}`;
};
const encodePolymorphicRelation = curry(({ idColumn, typeColumn }, relation)=>{
    // Encode the id of the relation and the positional argument if it exist
    const newRelation = {
        ...relation,
        [idColumn]: encodePolymorphicId(relation[idColumn], relation[typeColumn])
    };
    if (relation.position) {
        const { before, after } = relation.position;
        const __type = relation.position.__type || relation.__type;
        newRelation.position = {
            ...relation.position
        };
        if (before) newRelation.position.before = encodePolymorphicId(before, __type);
        if (after) newRelation.position.after = encodePolymorphicId(after, __type);
    }
    return newRelation;
});

//  TODO: This is a short term solution, to not steal relations from the same document.
const getDocumentSiblingIdsQuery = (tableName, id)=>{
    // Find if the model is a content type or something else (e.g. component)
    // to only get the documentId if it's a content type
    const models = Array.from(strapi.db.metadata.values());
    const isContentType = models.find((model)=>{
        return model.tableName === tableName && model.attributes.documentId;
    });
    if (!isContentType) {
        return [
            id
        ];
    }
    // NOTE: SubQueries are wrapped in a function to not reuse the same connection,
    // which causes infinite self references
    return function(query) {
        query.select('id').from(tableName)// Get all child ids of the document id
        .whereIn('document_id', (documentIDSubQuery)=>{
            documentIDSubQuery.from(tableName)// get document id related to the current id
            .select('document_id').where('id', id);
        });
    };
};
/**
 * If some relations currently exist for this oneToX relation, on the one side, this function removes them and update the inverse order if needed.
 */ const deletePreviousOneToAnyRelations = async ({ id, attribute, relIdsToadd, db, transaction: trx })=>{
    if (!(isBidirectional(attribute) && isOneToAny(attribute))) {
        throw new Error('deletePreviousOneToAnyRelations can only be called for bidirectional oneToAny relations');
    }
    const { joinTable } = attribute;
    const { joinColumn, inverseJoinColumn } = joinTable;
    const con = db.getConnection();
    await con.delete().from(joinTable.name)// Exclude the ids of the current document
    .whereNotIn(joinColumn.name, getDocumentSiblingIdsQuery(joinColumn.referencedTable, id))// Include all the ids that are being connected
    .whereIn(inverseJoinColumn.name, relIdsToadd).where(joinTable.on || {}).transacting(trx);
    await cleanOrderColumns({
        attribute,
        db,
        inverseRelIds: relIdsToadd,
        transaction: trx
    });
};
/**
 * If a relation currently exists for this xToOne relations, this function removes it and update the inverse order if needed.
 */ const deletePreviousAnyToOneRelations = async ({ id, attribute, relIdToadd, db, transaction: trx })=>{
    const { joinTable } = attribute;
    const { joinColumn, inverseJoinColumn } = joinTable;
    const con = db.getConnection();
    if (!isAnyToOne(attribute)) {
        throw new Error('deletePreviousAnyToOneRelations can only be called for anyToOne relations');
    }
    // handling manyToOne
    if (isManyToAny(attribute)) {
        // if the database integrity was not broken relsToDelete is supposed to be of length 1
        const relsToDelete = await con.select(inverseJoinColumn.name).from(joinTable.name).where(joinColumn.name, id).whereNotIn(inverseJoinColumn.name, getDocumentSiblingIdsQuery(inverseJoinColumn.referencedTable, relIdToadd)).where(joinTable.on || {}).transacting(trx);
        const relIdsToDelete = map(inverseJoinColumn.name, relsToDelete);
        await createQueryBuilder(joinTable.name, db).delete().where({
            [joinColumn.name]: id,
            [inverseJoinColumn.name]: {
                $in: relIdsToDelete
            }
        }).where(joinTable.on || {}).transacting(trx).execute();
        await cleanOrderColumns({
            attribute,
            db,
            inverseRelIds: relIdsToDelete,
            transaction: trx
        });
    // handling oneToOne
    } else {
        await con.delete().from(joinTable.name).where(joinColumn.name, id)// Exclude the ids of the current document
        .whereNotIn(inverseJoinColumn.name, getDocumentSiblingIdsQuery(inverseJoinColumn.referencedTable, relIdToadd)).where(joinTable.on || {}).transacting(trx);
    }
};
/**
 * Delete all or some relations of entity field
 */ const deleteRelations = async ({ id, attribute, db, relIdsToNotDelete = [], relIdsToDelete = [], transaction: trx })=>{
    const { joinTable } = attribute;
    const { joinColumn, inverseJoinColumn } = joinTable;
    const all = relIdsToDelete === 'all';
    if (hasOrderColumn(attribute) || hasInverseOrderColumn(attribute)) {
        let lastId = 0;
        let done = false;
        const batchSize = 100;
        while(!done){
            const batchToDelete = await createQueryBuilder(joinTable.name, db).select(inverseJoinColumn.name).where({
                [joinColumn.name]: id,
                id: {
                    $gt: lastId
                },
                [inverseJoinColumn.name]: {
                    $notIn: relIdsToNotDelete
                },
                ...all ? {} : {
                    [inverseJoinColumn.name]: {
                        $in: relIdsToDelete
                    }
                }
            }).where(joinTable.on || {}).orderBy('id').limit(batchSize).transacting(trx).execute();
            done = batchToDelete.length < batchSize;
            lastId = batchToDelete[batchToDelete.length - 1]?.id || 0;
            const batchIds = map(inverseJoinColumn.name, batchToDelete);
            await createQueryBuilder(joinTable.name, db).delete().where({
                [joinColumn.name]: id,
                [inverseJoinColumn.name]: {
                    $in: batchIds
                }
            }).where(joinTable.on || {}).transacting(trx).execute();
            await cleanOrderColumns({
                attribute,
                db,
                id,
                inverseRelIds: batchIds,
                transaction: trx
            });
        }
    } else {
        await createQueryBuilder(joinTable.name, db).delete().where({
            [joinColumn.name]: id,
            [inverseJoinColumn.name]: {
                $notIn: relIdsToNotDelete
            },
            ...all ? {} : {
                [inverseJoinColumn.name]: {
                    $in: relIdsToDelete
                }
            }
        }).where(joinTable.on || {}).transacting(trx).execute();
    }
};
/**
 * Clean the order columns by ensuring the order value are continuous (ex: 1, 2, 3 and not 1, 5, 10)
 */ const cleanOrderColumns = async ({ id, attribute, db, inverseRelIds = [], transaction: trx })=>{
    if (!(hasOrderColumn(attribute) && id) && !(hasInverseOrderColumn(attribute) && !isEmpty(inverseRelIds))) {
        return;
    }
    const { joinTable } = attribute;
    const { joinColumn, inverseJoinColumn, orderColumnName, inverseOrderColumnName } = joinTable;
    /**
  UPDATE :joinTable: as a,
  (
    SELECT
      id,
      ROW_NUMBER() OVER ( PARTITION BY :joinColumn: ORDER BY :orderColumn:) AS src_order,
    FROM :joinTable:
    WHERE :joinColumn: = :id
  ) AS b
  SET :orderColumn: = b.src_order
  WHERE b.id = a.id;
  */ const updateOrderColumn = async ()=>{
        if (!hasOrderColumn(attribute) || !id) {
            return;
        }
        const selectRowsToOrder = (joinTableName)=>db.connection(joinTableName).select('id').rowNumber('src_order', orderColumnName, joinColumn.name).where(joinColumn.name, id).toSQL();
        switch(strapi.db.dialect.client){
            case 'mysql':
                {
                    // Here it's MariaDB and MySQL 8
                    const select = selectRowsToOrder(joinTable.name);
                    await db.getConnection().raw(`UPDATE ?? as a, ( ${select.sql} ) AS b
            SET ?? = b.src_order
            WHERE b.id = a.id`, [
                        joinTable.name,
                        ...select.bindings,
                        orderColumnName
                    ]).transacting(trx);
                    break;
                }
            default:
                {
                    const joinTableName = addSchema(db, joinTable.name);
                    const select = selectRowsToOrder(joinTableName);
                    // raw query as knex doesn't allow updating from a subquery
                    await db.connection.raw(`UPDATE ?? as a
            SET ?? = b.src_order
            FROM ( ${select.sql} ) AS b
            WHERE b.id = a.id`, [
                        joinTableName,
                        orderColumnName,
                        ...select.bindings
                    ]).transacting(trx);
                }
        }
    };
    /**
  UPDATE :joinTable: as a,
  (
    SELECT
      id,
      ROW_NUMBER() OVER ( PARTITION BY :inverseJoinColumn: ORDER BY :inverseOrderColumn:) AS inv_order
    FROM :joinTable:
    WHERE :inverseJoinColumn: IN (:inverseRelIds)
  ) AS b
  SET :inverseOrderColumn: = b.inv_order
  WHERE b.id = a.id;
  */ const updateInverseOrderColumn = async ()=>{
        if (!hasInverseOrderColumn(attribute) || isEmpty(inverseRelIds)) return;
        const selectRowsToOrder = (joinTableName)=>db.connection(joinTableName).select('id').rowNumber('inv_order', inverseOrderColumnName, inverseJoinColumn.name).where(inverseJoinColumn.name, 'in', inverseRelIds).toSQL();
        switch(strapi.db.dialect.client){
            case 'mysql':
                {
                    // Here it's MariaDB and MySQL 8
                    const select = selectRowsToOrder(joinTable.name);
                    await db.getConnection().raw(`UPDATE ?? as a, ( ${select.sql} ) AS b
            SET ?? = b.inv_order
            WHERE b.id = a.id`, [
                        joinTable.name,
                        ...select.bindings,
                        inverseOrderColumnName
                    ]).transacting(trx);
                    break;
                }
            default:
                {
                    const joinTableName = addSchema(db, joinTable.name);
                    const select = selectRowsToOrder(joinTableName);
                    // raw query as knex doesn't allow updating from a subquery
                    await db.connection.raw(`UPDATE ?? as a
            SET ?? = b.inv_order
            FROM ( ${select.sql} ) AS b
            WHERE b.id = a.id`, [
                        joinTableName,
                        inverseOrderColumnName,
                        ...select.bindings
                    ]).transacting(trx);
                }
        }
    };
    return Promise.all([
        updateOrderColumn(),
        updateInverseOrderColumn()
    ]);
};

/**
 * When connecting relations, the order you connect them matters.
 *
 * Example, if you connect the following relations:
 *   { id: 5, position: { before: 1 } }
 *   { id: 1, position: { before: 2 } }
 *   { id: 2, position: { end: true } }
 *
 * Going through the connect array, id 5 has to be connected before id 1,
 * so the order of id5 = id1 - 1. But the order value of id 1 is unknown.
 * The only way to know the order of id 1 is to connect it first.
 *
 * This function makes sure the relations are connected in the right order:
 *   { id: 2, position: { end: true } }
 *   { id: 1, position: { before: 2 } }
 *   { id: 5, position: { before: 1 } }
 *
 */ const sortConnectArray = (connectArr, initialArr = [], strictSort = true)=>{
    const sortedConnect = [];
    // Boolean to know if we have to recalculate the order of the relations
    let needsSorting = false;
    // Map to validate if relation is already in sortedConnect or DB.
    const relationInInitialArray = initialArr.reduce((acc, rel)=>({
            ...acc,
            [rel.id]: true
        }), {});
    // Map to store the first index where a relation id is connected
    const mappedRelations = connectArr.reduce((mapper, relation)=>{
        const adjacentRelId = relation.position?.before || relation.position?.after;
        if (!adjacentRelId || !relationInInitialArray[adjacentRelId] && !mapper[adjacentRelId]) {
            needsSorting = true;
        }
        /**
       * We do not allow duplicate relations to be connected, so we need to check for uniqueness with components
       * Note that the id here includes the uid for polymorphic relations
       *
       * So for normal relations, the same id means the same relation
       * For component relations, it means the unique combo of (id, component name)
       */ // Check if there's an existing relation with this id
        const existingRelation = mapper[relation.id];
        // Check if existing relation has a component or not
        const hasNoComponent = existingRelation && !('__component' in existingRelation);
        // Check if the existing relation has the same component as the new relation
        const hasSameComponent = existingRelation && existingRelation.__component === relation.__component;
        // If we have an existing relation that is not unique (no component or same component) we won't accept it
        if (existingRelation && (hasNoComponent || hasSameComponent)) {
            throw new InvalidRelationError(`The relation with id ${relation.id} is already connected. ` + 'You cannot connect the same relation twice.');
        }
        return {
            [relation.id]: {
                ...relation,
                computed: false
            },
            ...mapper
        };
    }, {});
    // If we don't need to sort the connect array, we can return it as is
    if (!needsSorting) return connectArr;
    // Recursively compute in which order the relation should be connected
    const computeRelation = (relation, relationsSeenInBranch)=>{
        const adjacentRelId = relation.position?.before || relation.position?.after;
        const adjacentRelation = mappedRelations[adjacentRelId];
        // If the relation has already been seen in the current branch,
        // it means there is a circular reference
        if (adjacentRelId && relationsSeenInBranch[adjacentRelId]) {
            throw new InvalidRelationError('A circular reference was found in the connect array. ' + 'One relation is trying to connect before/after another one that is trying to connect before/after it');
        }
        // This relation has already been computed
        if (mappedRelations[relation.id]?.computed) {
            return;
        }
        mappedRelations[relation.id].computed = true;
        // Relation does not have a before or after attribute or is in the initial array
        if (!adjacentRelId || relationInInitialArray[adjacentRelId]) {
            sortedConnect.push(relation);
            return;
        }
        // Look if id is referenced elsewhere in the array
        if (mappedRelations[adjacentRelId]) {
            computeRelation(adjacentRelation, {
                ...relationsSeenInBranch,
                [relation.id]: true
            });
            sortedConnect.push(relation);
        } else if (strictSort) {
            // If we reach this point, it means that the adjacent relation is not in the connect array
            // and it is not in the database.
            throw new InvalidRelationError(`There was a problem connecting relation with id ${relation.id} at position ${JSON.stringify(relation.position)}. The relation with id ${adjacentRelId} needs to be connected first.`);
        } else {
            // We are in non-strict mode so we can push the relation.
            sortedConnect.push({
                id: relation.id,
                position: {
                    end: true
                }
            });
        }
    };
    // Iterate over connectArr and populate sortedConnect
    connectArr.forEach((relation)=>computeRelation(relation, {}));
    return sortedConnect;
};
/**
 * Responsible for calculating the relations order when connecting them.
 *
 * The connect method takes an array of relations with positional attributes:
 * - before: the id of the relation to connect before
 * - after: the id of the relation to connect after
 * - end: it should be at the end
 * - start: it should be at the start
 *
 * Example:
 *  - Having a connect array like:
 *      [ { id: 4, before: 2 }, { id: 4, before: 3}, {id: 5, before: 4} ]
 * - With the initial relations:
 *      [ { id: 2, order: 4 }, { id: 3, order: 10 } ]
 * - Step by step, going through the connect array, the array of relations would be:
 *      [ { id: 4, order: 3.5 }, { id: 2, order: 4 }, { id: 3, order: 10 } ]
 *      [ { id: 2, order: 4 }, { id: 4, order: 3.5 }, { id: 3, order: 10 } ]
 *      [ { id: 2, order: 4 }, { id: 5, order: 3.5 },  { id: 4, order: 3.5 }, { id: 3, order: 10 } ]
 * - The final step would be to recalculate fractional order values.
 *      [ { id: 2, order: 4 }, { id: 5, order: 3.33 },  { id: 4, order: 3.66 }, { id: 3, order: 10 } ]
 *
 * @param {Array<*>} initArr - array of relations to initialize the class with
 * @param {string} idColumn - the column name of the id
 * @param {string} orderColumn - the column name of the order
 * @param {boolean} strict - if true, will throw an error if a relation is connected adjacent to
 *                               another one that does not exist
 * @return {*}
 */ const relationsOrderer = (initArr, idColumn, orderColumn, strict)=>{
    const computedRelations = castArray(initArr ?? []).map((r)=>({
            init: true,
            id: r[idColumn],
            order: Number(r[orderColumn]) || 1
        }));
    const maxOrder = maxBy('order', computedRelations)?.order || 0;
    const findRelation = (id)=>{
        const idx = computedRelations.findIndex((r)=>r.id === id);
        return {
            idx,
            relation: computedRelations[idx]
        };
    };
    const removeRelation = (r)=>{
        const { idx } = findRelation(r.id);
        if (idx >= 0) {
            computedRelations.splice(idx, 1);
        }
    };
    const insertRelation = (r)=>{
        let idx;
        if (r.position?.before) {
            const { idx: _idx, relation } = findRelation(r.position.before);
            if (relation.init) {
                r.order = relation.order - 0.5;
            } else {
                r.order = relation.order;
            }
            idx = _idx;
        } else if (r.position?.after) {
            const { idx: _idx, relation } = findRelation(r.position.after);
            if (relation.init) {
                r.order = relation.order + 0.5;
            } else {
                r.order = relation.order;
            }
            idx = _idx + 1;
        } else if (r.position?.start) {
            r.order = 0.5;
            idx = 0;
        } else {
            r.order = maxOrder + 0.5;
            idx = computedRelations.length;
        }
        // Insert the relation in the array
        computedRelations.splice(idx, 0, r);
    };
    return {
        disconnect (relations) {
            castArray(relations).forEach((relation)=>{
                removeRelation(relation);
            });
            return this;
        },
        connect (relations) {
            sortConnectArray(castArray(relations), computedRelations, strict).forEach((relation)=>{
                this.disconnect(relation);
                try {
                    insertRelation(relation);
                } catch (err) {
                    throw new Error(`There was a problem connecting relation with id ${relation.id} at position ${JSON.stringify(relation.position)}. The list of connect relations is not valid`);
                }
            });
            return this;
        },
        get () {
            return computedRelations;
        },
        /**
     * Get a map between the relation id and its order
     */ getOrderMap () {
            return _$1(computedRelations).groupBy('order').reduce((acc, relations)=>{
                if (relations[0]?.init) return acc;
                relations.forEach((relation, idx)=>{
                    acc[relation.id] = Math.floor(relation.order) + (idx + 1) / (relations.length + 1);
                });
                return acc;
            }, {});
        }
    };
};

const isRecord = (value)=>isObject(value) && !isNil(value);
const toId = (value)=>{
    if (isRecord(value) && 'id' in value && isValidId(value.id)) {
        return value.id;
    }
    if (isValidId(value)) {
        return value;
    }
    throw new Error(`Invalid id, expected a string or integer, got ${JSON.stringify(value)}`);
};
const toIds = (value)=>castArray(value || []).map(toId);
const isValidId = (value)=>isString$1(value) || isInteger(value);
const isValidObjectId = (value)=>isRecord(value) && 'id' in value && isValidId(value.id);
const toIdArray = (data)=>{
    const array = castArray(data).filter((datum)=>!isNil(datum)).map((datum)=>{
        // if it is a string or an integer return an obj with id = to datum
        if (isValidId(datum)) {
            return {
                id: datum,
                __pivot: {}
            };
        }
        // if it is an object check it has at least a valid id
        if (!isValidObjectId(datum)) {
            throw new Error(`Invalid id, expected a string or integer, got ${datum}`);
        }
        return datum;
    });
    return uniqWith(isEqual, array);
};
const toAssocs = (data)=>{
    if (isArray(data) || isString$1(data) || isNumber$1(data) || isNull(data) || isRecord(data) && 'id' in data) {
        return {
            set: isNull(data) ? data : toIdArray(data)
        };
    }
    if (data?.set) {
        return {
            set: isNull(data.set) ? data.set : toIdArray(data.set)
        };
    }
    return {
        options: {
            strict: data?.options?.strict
        },
        connect: toIdArray(data?.connect).map((elm)=>({
                id: elm.id,
                position: elm.position ? elm.position : {
                    end: true
                },
                __pivot: elm.__pivot ?? {},
                __type: elm.__type
            })),
        disconnect: toIdArray(data?.disconnect)
    };
};
const processData = (metadata, data = {}, { withDefaults = false } = {})=>{
    const { attributes } = metadata;
    const obj = {};
    for (const attributeName of Object.keys(attributes)){
        const attribute = attributes[attributeName];
        if (isScalarAttribute(attribute)) {
            const field = createField(attribute);
            if (isUndefined(data[attributeName])) {
                if (!isUndefined(attribute.default) && withDefaults) {
                    if (typeof attribute.default === 'function') {
                        obj[attributeName] = attribute.default();
                    } else {
                        obj[attributeName] = attribute.default;
                    }
                }
                continue;
            }
            if ('validate' in field && typeof field.validate === 'function' && data[attributeName] !== null) {
                field.validate(data[attributeName]);
            }
            const val = data[attributeName] === null ? null : field.toDB(data[attributeName]);
            obj[attributeName] = val;
        }
        if (isRelationalAttribute(attribute)) {
            // oneToOne & manyToOne
            if ('joinColumn' in attribute && attribute.joinColumn && attribute.owner) {
                const joinColumnName = attribute.joinColumn.name;
                // allow setting to null
                const attrValue = !isUndefined(data[attributeName]) ? data[attributeName] : data[joinColumnName];
                if (isNull(attrValue)) {
                    obj[joinColumnName] = attrValue;
                } else if (!isUndefined(attrValue)) {
                    obj[joinColumnName] = toId(attrValue);
                }
                continue;
            }
            if ('morphColumn' in attribute && attribute.morphColumn && attribute.owner) {
                const { idColumn, typeColumn, typeField = '__type' } = attribute.morphColumn;
                const value = data[attributeName];
                if (value === null) {
                    Object.assign(obj, {
                        [idColumn.name]: null,
                        [typeColumn.name]: null
                    });
                    continue;
                }
                if (!isUndefined(value)) {
                    if (!has('id', value) || !has(typeField, value)) {
                        throw new Error(`Expects properties ${typeField} an id to make a morph association`);
                    }
                    Object.assign(obj, {
                        [idColumn.name]: value.id,
                        [typeColumn.name]: value[typeField]
                    });
                }
            }
        }
    }
    return obj;
};
const createEntityManager = (db)=>{
    const repoMap = {};
    return {
        async findOne (uid, params) {
            const states = await db.lifecycles.run('beforeFindOne', uid, {
                params
            });
            const result = await this.createQueryBuilder(uid).init(params).first().execute();
            await db.lifecycles.run('afterFindOne', uid, {
                params,
                result
            }, states);
            return result;
        },
        // should we name it findOne because people are used to it ?
        async findMany (uid, params) {
            const states = await db.lifecycles.run('beforeFindMany', uid, {
                params
            });
            const result = await this.createQueryBuilder(uid).init(params).execute();
            await db.lifecycles.run('afterFindMany', uid, {
                params,
                result
            }, states);
            return result;
        },
        async count (uid, params = {}) {
            const states = await db.lifecycles.run('beforeCount', uid, {
                params
            });
            const res = await this.createQueryBuilder(uid).init(pick([
                '_q',
                'where',
                'filters'
            ], params)).count().first().execute();
            const result = Number(res.count);
            await db.lifecycles.run('afterCount', uid, {
                params,
                result
            }, states);
            return result;
        },
        async create (uid, params = {}) {
            const states = await db.lifecycles.run('beforeCreate', uid, {
                params
            });
            const metadata = db.metadata.get(uid);
            const { data } = params;
            if (!isPlainObject(data)) {
                throw new Error('Create expects a data object');
            }
            const dataToInsert = processData(metadata, data, {
                withDefaults: true
            });
            const res = await this.createQueryBuilder(uid).insert(dataToInsert).execute();
            const id = isRecord(res[0]) ? res[0].id : res[0];
            const trx = await strapi.db.transaction();
            try {
                await this.attachRelations(uid, id, data, {
                    transaction: trx.get()
                });
                await trx.commit();
            } catch (e) {
                await trx.rollback();
                await this.createQueryBuilder(uid).where({
                    id
                }).delete().execute();
                throw e;
            }
            // TODO: in case there is no select or populate specified return the inserted data ?
            // TODO: do not trigger the findOne lifecycles ?
            const result = await this.findOne(uid, {
                where: {
                    id
                },
                select: params.select,
                populate: params.populate,
                filters: params.filters
            });
            await db.lifecycles.run('afterCreate', uid, {
                params,
                result
            }, states);
            return result;
        },
        // TODO: where do we handle relation processing for many queries ?
        async createMany (uid, params = {}) {
            const states = await db.lifecycles.run('beforeCreateMany', uid, {
                params
            });
            const metadata = db.metadata.get(uid);
            const { data } = params;
            if (!isArray(data)) {
                throw new Error('CreateMany expects data to be an array');
            }
            const dataToInsert = data.map((datum)=>processData(metadata, datum, {
                    withDefaults: true
                }));
            if (isEmpty(dataToInsert)) {
                throw new Error('Nothing to insert');
            }
            const createdEntries = await this.createQueryBuilder(uid).insert(dataToInsert).execute();
            const result = {
                count: data.length,
                ids: createdEntries.map((entry)=>typeof entry === 'object' ? entry?.id : entry)
            };
            await db.lifecycles.run('afterCreateMany', uid, {
                params,
                result
            }, states);
            return result;
        },
        async update (uid, params = {}) {
            const states = await db.lifecycles.run('beforeUpdate', uid, {
                params
            });
            const metadata = db.metadata.get(uid);
            const { where, data } = params;
            if (!isPlainObject(data)) {
                throw new Error('Update requires a data object');
            }
            if (isEmpty(where)) {
                throw new Error('Update requires a where parameter');
            }
            const entity = await this.createQueryBuilder(uid).select('*').where(where).first().execute({
                mapResults: false
            });
            if (!entity) {
                return null;
            }
            const { id } = entity;
            const dataToUpdate = processData(metadata, data);
            if (!isEmpty(dataToUpdate)) {
                await this.createQueryBuilder(uid).where({
                    id
                }).update(dataToUpdate).execute();
            }
            const trx = await strapi.db.transaction();
            try {
                await this.updateRelations(uid, id, data, {
                    transaction: trx.get()
                });
                await trx.commit();
            } catch (e) {
                await trx.rollback();
                await this.createQueryBuilder(uid).where({
                    id
                }).update(entity).execute();
                throw e;
            }
            // TODO: do not trigger the findOne lifecycles ?
            const result = await this.findOne(uid, {
                where: {
                    id
                },
                select: params.select,
                populate: params.populate,
                filters: params.filters
            });
            await db.lifecycles.run('afterUpdate', uid, {
                params,
                result
            }, states);
            return result;
        },
        // TODO: where do we handle relation processing for many queries ?
        async updateMany (uid, params = {}) {
            const states = await db.lifecycles.run('beforeUpdateMany', uid, {
                params
            });
            const metadata = db.metadata.get(uid);
            const { where, data } = params;
            const dataToUpdate = processData(metadata, data);
            if (isEmpty(dataToUpdate)) {
                throw new Error('Update requires data');
            }
            const updatedRows = await this.createQueryBuilder(uid).where(where).update(dataToUpdate).execute();
            const result = {
                count: updatedRows
            };
            await db.lifecycles.run('afterUpdateMany', uid, {
                params,
                result
            }, states);
            return result;
        },
        async delete (uid, params = {}) {
            const states = await db.lifecycles.run('beforeDelete', uid, {
                params
            });
            const { where, select, populate } = params;
            if (isEmpty(where)) {
                throw new Error('Delete requires a where parameter');
            }
            // TODO: do not trigger the findOne lifecycles ?
            const entity = await this.findOne(uid, {
                select: select && [
                    'id'
                ].concat(select),
                where,
                populate
            });
            if (!entity) {
                return null;
            }
            const { id } = entity;
            await this.createQueryBuilder(uid).where({
                id
            }).delete().execute();
            const trx = await strapi.db.transaction();
            try {
                await this.deleteRelations(uid, id, {
                    transaction: trx.get()
                });
                await trx.commit();
            } catch (e) {
                await trx.rollback();
                throw e;
            }
            await db.lifecycles.run('afterDelete', uid, {
                params,
                result: entity
            }, states);
            return entity;
        },
        // TODO: where do we handle relation processing for many queries ?
        async deleteMany (uid, params = {}) {
            const states = await db.lifecycles.run('beforeDeleteMany', uid, {
                params
            });
            const { where } = params;
            const deletedRows = await this.createQueryBuilder(uid).where(where).delete().execute();
            const result = {
                count: deletedRows
            };
            await db.lifecycles.run('afterDeleteMany', uid, {
                params,
                result
            }, states);
            return result;
        },
        /**
     * Attach relations to a new entity
     */ async attachRelations (uid, id, data, options) {
            const { attributes } = db.metadata.get(uid);
            const { transaction: trx } = options ?? {};
            for (const attributeName of Object.keys(attributes)){
                const attribute = attributes[attributeName];
                const isValidLink = has(attributeName, data) && !isNil(data[attributeName]);
                if (attribute.type !== 'relation' || !isValidLink) {
                    continue;
                }
                const cleanRelationData = toAssocs(data[attributeName]);
                if (attribute.relation === 'morphOne' || attribute.relation === 'morphMany') {
                    /**
           * morphOne and morphMany relations
           */ const { target, morphBy } = attribute;
                    const targetAttribute = db.metadata.get(target).attributes[morphBy];
                    if (targetAttribute.type !== 'relation') {
                        throw new Error(`Expected target attribute ${target}.${morphBy} to be a relation attribute`);
                    }
                    if (targetAttribute.relation === 'morphToOne') {
                        // set columns
                        const { idColumn, typeColumn } = targetAttribute.morphColumn;
                        const relId = toId(cleanRelationData.set?.[0]);
                        await this.createQueryBuilder(target).update({
                            [idColumn.name]: id,
                            [typeColumn.name]: uid
                        }).where({
                            id: relId
                        }).transacting(trx).execute();
                    } else if (targetAttribute.relation === 'morphToMany') {
                        const { joinTable } = targetAttribute;
                        const { joinColumn, morphColumn } = joinTable;
                        const { idColumn, typeColumn } = morphColumn;
                        if (isEmpty(cleanRelationData.set)) {
                            continue;
                        }
                        const rows = cleanRelationData.set?.map((data, idx)=>{
                            return {
                                [joinColumn.name]: data.id,
                                [idColumn.name]: id,
                                [typeColumn.name]: uid,
                                ...'on' in joinTable && joinTable.on || {},
                                ...data.__pivot || {},
                                order: idx + 1,
                                field: attributeName
                            };
                        }) ?? [];
                        await this.createQueryBuilder(joinTable.name).insert(rows).transacting(trx).execute();
                    }
                    continue;
                } else if (attribute.relation === 'morphToOne') {
                    continue;
                } else if (attribute.relation === 'morphToMany') {
                    /**
           * morphToMany
           */ const { joinTable } = attribute;
                    const { joinColumn, morphColumn } = joinTable;
                    const { idColumn, typeColumn, typeField = '__type' } = morphColumn;
                    if (isEmpty(cleanRelationData.set) && isEmpty(cleanRelationData.connect)) {
                        continue;
                    }
                    // set happens before connect/disconnect
                    const dataset = cleanRelationData.set || cleanRelationData.connect || [];
                    const rows = dataset.map((data, idx)=>({
                            [joinColumn.name]: id,
                            [idColumn.name]: data.id,
                            [typeColumn.name]: data[typeField],
                            ...'on' in joinTable && joinTable.on || {},
                            ...data.__pivot || {},
                            order: idx + 1
                        }));
                    const orderMap = relationsOrderer([], morphColumn.idColumn.name, 'order', true // Always make a strict connect when inserting
                    ).connect(// Merge id & __type to get a single id key
                    dataset.map(encodePolymorphicRelation({
                        idColumn: 'id',
                        typeColumn: typeField
                    }))).get()// set the order based on the order of the ids
                    .reduce((acc, rel, idx)=>({
                            ...acc,
                            [rel.id]: idx + 1
                        }), {});
                    rows.forEach((row)=>{
                        const rowId = row[morphColumn.idColumn.name];
                        const rowType = row[morphColumn.typeColumn.name];
                        const encodedId = encodePolymorphicId(rowId, rowType);
                        row.order = orderMap[encodedId];
                    });
                    // delete previous relations
                    await deleteRelatedMorphOneRelationsAfterMorphToManyUpdate(rows, {
                        uid,
                        attributeName,
                        joinTable,
                        db,
                        transaction: trx
                    });
                    await this.createQueryBuilder(joinTable.name).insert(rows).transacting(trx).execute();
                    continue;
                }
                if ('joinColumn' in attribute && attribute.joinColumn && attribute.owner) {
                    const relIdsToAdd = toIds(cleanRelationData.set);
                    if (attribute.relation === 'oneToOne' && isBidirectional(attribute) && relIdsToAdd.length) {
                        await this.createQueryBuilder(uid).where({
                            [attribute.joinColumn.name]: relIdsToAdd,
                            id: {
                                $ne: id
                            }
                        }).update({
                            [attribute.joinColumn.name]: null
                        }).transacting(trx).execute();
                    }
                    continue;
                }
                // oneToOne oneToMany on the non owning side
                if ('joinColumn' in attribute && attribute.joinColumn && !attribute.owner) {
                    // need to set the column on the target
                    const { target } = attribute;
                    // TODO: check it is an id & the entity exists (will throw due to FKs otherwise so not a big pbl in SQL)
                    const relIdsToAdd = toIds(cleanRelationData.set);
                    await this.createQueryBuilder(target).where({
                        [attribute.joinColumn.referencedColumn]: id
                    }).update({
                        [attribute.joinColumn.referencedColumn]: null
                    }).transacting(trx).execute();
                    await this.createQueryBuilder(target).update({
                        [attribute.joinColumn.referencedColumn]: id
                    })// NOTE: works if it is an array or a single id
                    .where({
                        id: relIdsToAdd
                    }).transacting(trx).execute();
                }
                if ('joinTable' in attribute && attribute.joinTable) {
                    // need to set the column on the target
                    const { joinTable } = attribute;
                    const { joinColumn, inverseJoinColumn, orderColumnName, inverseOrderColumnName } = joinTable;
                    const relsToAdd = (cleanRelationData.set || cleanRelationData.connect) ?? [];
                    const relIdsToadd = toIds(relsToAdd);
                    if (isBidirectional(attribute) && isOneToAny(attribute)) {
                        await deletePreviousOneToAnyRelations({
                            id,
                            attribute,
                            relIdsToadd,
                            db,
                            transaction: trx
                        });
                    }
                    // prepare new relations to insert
                    const insert = uniqBy('id', relsToAdd).map((data)=>{
                        return {
                            [joinColumn.name]: id,
                            [inverseJoinColumn.name]: data.id,
                            ...'on' in joinTable && joinTable.on || {},
                            ...data.__pivot || {}
                        };
                    });
                    // add order value
                    if (cleanRelationData.set && hasOrderColumn(attribute)) {
                        insert.forEach((data, idx)=>{
                            data[orderColumnName] = idx + 1;
                        });
                    } else if (cleanRelationData.connect && hasOrderColumn(attribute)) {
                        // use position attributes to calculate order
                        const orderMap = relationsOrderer([], inverseJoinColumn.name, joinTable.orderColumnName, true // Always make an strict connect when inserting
                        ).connect(relsToAdd).get()// set the order based on the order of the ids
                        .reduce((acc, rel, idx)=>({
                                ...acc,
                                [rel.id]: idx
                            }), {});
                        insert.forEach((row)=>{
                            row[orderColumnName] = orderMap[row[inverseJoinColumn.name]];
                        });
                    }
                    // add inv_order value
                    if (hasInverseOrderColumn(attribute)) {
                        const maxResults = await db.getConnection().select(inverseJoinColumn.name).max(inverseOrderColumnName, {
                            as: 'max'
                        }).whereIn(inverseJoinColumn.name, relIdsToadd).where(joinTable.on || {}).groupBy(inverseJoinColumn.name).from(joinTable.name).transacting(trx);
                        const maxMap = maxResults.reduce((acc, res)=>Object.assign(acc, {
                                [res[inverseJoinColumn.name]]: res.max
                            }), {});
                        insert.forEach((rel)=>{
                            rel[inverseOrderColumnName] = (maxMap[rel[inverseJoinColumn.name]] || 0) + 1;
                        });
                    }
                    if (insert.length === 0) {
                        continue;
                    }
                    // insert new relations
                    await this.createQueryBuilder(joinTable.name).insert(insert).transacting(trx).execute();
                }
            }
        },
        /**
     * Updates relations of an existing entity
     */ // TODO: check relation exists (handled by FKs except for polymorphics)
        async updateRelations (uid, id, data, options) {
            const { attributes } = db.metadata.get(uid);
            const { transaction: trx } = options ?? {};
            for (const attributeName of Object.keys(attributes)){
                const attribute = attributes[attributeName];
                if (attribute.type !== 'relation' || !has(attributeName, data)) {
                    continue;
                }
                const cleanRelationData = toAssocs(data[attributeName]);
                if (attribute.relation === 'morphOne' || attribute.relation === 'morphMany') {
                    const { target, morphBy } = attribute;
                    const targetAttribute = db.metadata.get(target).attributes[morphBy];
                    if (targetAttribute.type === 'relation' && targetAttribute.relation === 'morphToOne') {
                        // set columns
                        const { idColumn, typeColumn } = targetAttribute.morphColumn;
                        // update instead of deleting because the relation is directly on the entity table
                        // and not in a join table
                        await this.createQueryBuilder(target).update({
                            [idColumn.name]: null,
                            [typeColumn.name]: null
                        }).where({
                            [idColumn.name]: id,
                            [typeColumn.name]: uid
                        }).transacting(trx).execute();
                        if (!isNull(cleanRelationData.set)) {
                            const relId = toIds(cleanRelationData.set?.[0]);
                            await this.createQueryBuilder(target).update({
                                [idColumn.name]: id,
                                [typeColumn.name]: uid
                            }).where({
                                id: relId
                            }).transacting(trx).execute();
                        }
                    } else if (targetAttribute.type === 'relation' && targetAttribute.relation === 'morphToMany') {
                        const { joinTable } = targetAttribute;
                        const { joinColumn, morphColumn } = joinTable;
                        const { idColumn, typeColumn } = morphColumn;
                        const hasSet = !isEmpty(cleanRelationData.set);
                        const hasConnect = !isEmpty(cleanRelationData.connect);
                        const hasDisconnect = !isEmpty(cleanRelationData.disconnect);
                        // for connect/disconnect without a set, only modify those relations
                        if (!hasSet && (hasConnect || hasDisconnect)) {
                            // delete disconnects and connects (to prevent duplicates when we add them later)
                            const idsToDelete = [
                                ...cleanRelationData.disconnect || [],
                                ...cleanRelationData.connect || []
                            ];
                            if (!isEmpty(idsToDelete)) {
                                const where = {
                                    $or: idsToDelete.map((item)=>{
                                        return {
                                            [idColumn.name]: id,
                                            [typeColumn.name]: uid,
                                            [joinColumn.name]: item.id,
                                            ...joinTable.on || {},
                                            field: attributeName
                                        };
                                    })
                                };
                                await this.createQueryBuilder(joinTable.name).delete().where(where).transacting(trx).execute();
                            }
                            // connect relations
                            if (hasConnect) {
                                // Query database to find the order of the last relation
                                const start = await this.createQueryBuilder(joinTable.name).where({
                                    [idColumn.name]: id,
                                    [typeColumn.name]: uid,
                                    ...joinTable.on || {},
                                    ...data.__pivot || {}
                                }).max('order').first().transacting(trx).execute();
                                const startOrder = start?.max || 0;
                                const rows = (cleanRelationData.connect ?? []).map((data, idx)=>({
                                        [joinColumn.name]: data.id,
                                        [idColumn.name]: id,
                                        [typeColumn.name]: uid,
                                        ...joinTable.on || {},
                                        ...data.__pivot || {},
                                        order: startOrder + idx + 1,
                                        field: attributeName
                                    }));
                                await this.createQueryBuilder(joinTable.name).insert(rows).transacting(trx).execute();
                            }
                            continue;
                        }
                        // delete all relations
                        await this.createQueryBuilder(joinTable.name).delete().where({
                            [idColumn.name]: id,
                            [typeColumn.name]: uid,
                            ...joinTable.on || {},
                            field: attributeName
                        }).transacting(trx).execute();
                        if (hasSet) {
                            const rows = (cleanRelationData.set ?? []).map((data, idx)=>({
                                    [joinColumn.name]: data.id,
                                    [idColumn.name]: id,
                                    [typeColumn.name]: uid,
                                    ...joinTable.on || {},
                                    ...data.__pivot || {},
                                    order: idx + 1,
                                    field: attributeName
                                }));
                            await this.createQueryBuilder(joinTable.name).insert(rows).transacting(trx).execute();
                        }
                    }
                    continue;
                }
                if (attribute.relation === 'morphToOne') {
                    continue;
                }
                if (attribute.relation === 'morphToMany') {
                    const { joinTable } = attribute;
                    const { joinColumn, morphColumn } = joinTable;
                    const { idColumn, typeColumn, typeField = '__type' } = morphColumn;
                    const hasSet = !isEmpty(cleanRelationData.set);
                    const hasConnect = !isEmpty(cleanRelationData.connect);
                    const hasDisconnect = !isEmpty(cleanRelationData.disconnect);
                    // for connect/disconnect without a set, only modify those relations
                    if (!hasSet && (hasConnect || hasDisconnect)) {
                        // delete disconnects and connects (to prevent duplicates when we add them later)
                        const idsToDelete = [
                            ...cleanRelationData.disconnect || [],
                            ...cleanRelationData.connect || []
                        ];
                        const rowsToDelete = [
                            ...(cleanRelationData.disconnect ?? []).map((data, idx)=>({
                                    [joinColumn.name]: id,
                                    [idColumn.name]: data.id,
                                    [typeColumn.name]: data[typeField],
                                    ...'on' in joinTable && joinTable.on || {},
                                    ...data.__pivot || {},
                                    order: idx + 1
                                })),
                            ...(cleanRelationData.connect ?? []).map((data, idx)=>({
                                    [joinColumn.name]: id,
                                    [idColumn.name]: data.id,
                                    // @ts-expect-error TODO
                                    [typeColumn.name]: data[typeField],
                                    ...'on' in joinTable && joinTable.on || {},
                                    ...data.__pivot || {},
                                    order: idx + 1
                                }))
                        ];
                        const adjacentRelations = await this.createQueryBuilder(joinTable.name).where({
                            $or: [
                                {
                                    [joinColumn.name]: id,
                                    [idColumn.name]: {
                                        $in: compact(cleanRelationData.connect?.map((r)=>r.position?.after || r.position?.before))
                                    }
                                },
                                {
                                    [joinColumn.name]: id,
                                    order: this.createQueryBuilder(joinTable.name).max('order').where({
                                        [joinColumn.name]: id
                                    }).where(joinTable.on || {}).transacting(trx).getKnexQuery()
                                }
                            ]
                        }).where(joinTable.on || {}).transacting(trx).execute();
                        if (!isEmpty(idsToDelete)) {
                            const where = {
                                $or: idsToDelete.map((item)=>{
                                    return {
                                        [idColumn.name]: item.id,
                                        [typeColumn.name]: item[typeField],
                                        [joinColumn.name]: id,
                                        ...joinTable.on || {}
                                    };
                                })
                            };
                            // delete previous relations
                            await this.createQueryBuilder(joinTable.name).delete().where(where).transacting(trx).execute();
                            await deleteRelatedMorphOneRelationsAfterMorphToManyUpdate(rowsToDelete, {
                                uid,
                                attributeName,
                                joinTable,
                                db,
                                transaction: trx
                            });
                        }
                        // connect relations
                        if (hasConnect) {
                            const dataset = cleanRelationData.connect || [];
                            const rows = dataset.map((data)=>({
                                    [joinColumn.name]: id,
                                    [idColumn.name]: data.id,
                                    [typeColumn.name]: data[typeField],
                                    ...joinTable.on || {},
                                    ...data.__pivot || {},
                                    field: attributeName
                                }));
                            const orderMap = relationsOrderer(// Merge id & __type to get a single id key
                            adjacentRelations.map(encodePolymorphicRelation({
                                idColumn: idColumn.name,
                                typeColumn: typeColumn.name
                            })), idColumn.name, 'order', cleanRelationData.options?.strict).connect(// Merge id & __type to get a single id key
                            dataset.map(encodePolymorphicRelation({
                                idColumn: 'id',
                                typeColumn: '__type'
                            }))).getOrderMap();
                            rows.forEach((row)=>{
                                const rowId = row[idColumn.name];
                                const rowType = row[typeColumn.name];
                                const encodedId = encodePolymorphicId(rowId, rowType);
                                row.order = orderMap[encodedId];
                            });
                            await this.createQueryBuilder(joinTable.name).insert(rows).transacting(trx).execute();
                        }
                        continue;
                    }
                    if (hasSet) {
                        // delete all relations for this entity
                        await this.createQueryBuilder(joinTable.name).delete().where({
                            [joinColumn.name]: id,
                            ...joinTable.on || {}
                        }).transacting(trx).execute();
                        const rows = (cleanRelationData.set ?? []).map((data, idx)=>({
                                [joinColumn.name]: id,
                                [idColumn.name]: data.id,
                                [typeColumn.name]: data[typeField],
                                field: attributeName,
                                ...joinTable.on || {},
                                ...data.__pivot || {},
                                order: idx + 1
                            }));
                        await deleteRelatedMorphOneRelationsAfterMorphToManyUpdate(rows, {
                            uid,
                            attributeName,
                            joinTable,
                            db,
                            transaction: trx
                        });
                        await this.createQueryBuilder(joinTable.name).insert(rows).transacting(trx).execute();
                    }
                    continue;
                }
                if ('joinColumn' in attribute && attribute.joinColumn && attribute.owner) {
                    continue;
                }
                // oneToOne oneToMany on the non owning side.
                // Since it is a join column no need to remove previous relations
                if ('joinColumn' in attribute && attribute.joinColumn && !attribute.owner) {
                    // need to set the column on the target
                    const { target } = attribute;
                    await this.createQueryBuilder(target).where({
                        [attribute.joinColumn.referencedColumn]: id
                    }).update({
                        [attribute.joinColumn.referencedColumn]: null
                    }).transacting(trx).execute();
                    if (!isNull(cleanRelationData.set)) {
                        const relIdsToAdd = toIds(cleanRelationData.set);
                        await this.createQueryBuilder(target).where({
                            id: relIdsToAdd
                        }).update({
                            [attribute.joinColumn.referencedColumn]: id
                        }).transacting(trx).execute();
                    }
                }
                if (attribute.joinTable) {
                    const { joinTable } = attribute;
                    const { joinColumn, inverseJoinColumn, orderColumnName, inverseOrderColumnName } = joinTable;
                    const select = [
                        joinColumn.name,
                        inverseJoinColumn.name
                    ];
                    if (hasOrderColumn(attribute)) {
                        select.push(orderColumnName);
                    }
                    if (hasInverseOrderColumn(attribute)) {
                        select.push(inverseOrderColumnName);
                    }
                    // only delete relations
                    if (isNull(cleanRelationData.set)) {
                        await deleteRelations({
                            id,
                            attribute,
                            db,
                            relIdsToDelete: 'all',
                            transaction: trx
                        });
                    } else {
                        const isPartialUpdate = !has('set', cleanRelationData);
                        let relIdsToaddOrMove;
                        if (isPartialUpdate) {
                            if (isAnyToOne(attribute)) ;
                            relIdsToaddOrMove = toIds(cleanRelationData.connect);
                            const relIdsToDelete = toIds(differenceWith(isEqual, cleanRelationData.disconnect, cleanRelationData.connect ?? []));
                            if (!isEmpty(relIdsToDelete)) {
                                await deleteRelations({
                                    id,
                                    attribute,
                                    db,
                                    relIdsToDelete,
                                    transaction: trx
                                });
                            }
                            if (isEmpty(cleanRelationData.connect)) {
                                continue;
                            }
                            // Fetch current relations to handle ordering
                            let currentMovingRels = [];
                            if (hasOrderColumn(attribute) || hasInverseOrderColumn(attribute)) {
                                currentMovingRels = await this.createQueryBuilder(joinTable.name).select(select).where({
                                    [joinColumn.name]: id,
                                    [inverseJoinColumn.name]: {
                                        $in: relIdsToaddOrMove
                                    }
                                }).where(joinTable.on || {}).transacting(trx).execute();
                            }
                            // prepare relations to insert
                            const insert = uniqBy('id', cleanRelationData.connect).map((relToAdd)=>({
                                    [joinColumn.name]: id,
                                    [inverseJoinColumn.name]: relToAdd.id,
                                    ...joinTable.on || {},
                                    ...relToAdd.__pivot || {}
                                }));
                            if (hasOrderColumn(attribute)) {
                                // Get all adjacent relations and the one with the highest order
                                const adjacentRelations = await this.createQueryBuilder(joinTable.name).where({
                                    $or: [
                                        {
                                            [joinColumn.name]: id,
                                            [inverseJoinColumn.name]: {
                                                $in: compact(cleanRelationData.connect?.map((r)=>r.position?.after || r.position?.before))
                                            }
                                        },
                                        {
                                            [joinColumn.name]: id,
                                            [orderColumnName]: this.createQueryBuilder(joinTable.name).max(orderColumnName).where({
                                                [joinColumn.name]: id
                                            }).where(joinTable.on || {}).transacting(trx).getKnexQuery()
                                        }
                                    ]
                                }).where(joinTable.on || {}).transacting(trx).execute();
                                const orderMap = relationsOrderer(adjacentRelations, inverseJoinColumn.name, joinTable.orderColumnName, cleanRelationData.options?.strict).connect(cleanRelationData.connect ?? []).getOrderMap();
                                insert.forEach((row)=>{
                                    row[orderColumnName] = orderMap[row[inverseJoinColumn.name]];
                                });
                            }
                            // add inv order value
                            if (hasInverseOrderColumn(attribute)) {
                                const nonExistingRelsIds = difference(relIdsToaddOrMove, map(inverseJoinColumn.name, currentMovingRels));
                                const maxResults = await db.getConnection().select(inverseJoinColumn.name).max(inverseOrderColumnName, {
                                    as: 'max'
                                }).whereIn(inverseJoinColumn.name, nonExistingRelsIds).where(joinTable.on || {}).groupBy(inverseJoinColumn.name).from(joinTable.name).transacting(trx);
                                const maxMap = maxResults.reduce((acc, res)=>Object.assign(acc, {
                                        [res[inverseJoinColumn.name]]: res.max
                                    }), {});
                                insert.forEach((row)=>{
                                    row[inverseOrderColumnName] = (maxMap[row[inverseJoinColumn.name]] || 0) + 1;
                                });
                            }
                            // insert rows
                            const query = this.createQueryBuilder(joinTable.name).insert(insert).onConflict(joinTable.pivotColumns).transacting(trx);
                            if (hasOrderColumn(attribute)) {
                                query.merge([
                                    orderColumnName
                                ]);
                            } else {
                                query.ignore();
                            }
                            await query.execute();
                            // remove gap between orders
                            await cleanOrderColumns({
                                attribute,
                                db,
                                id,
                                transaction: trx
                            });
                        } else {
                            if (isAnyToOne(attribute)) {
                                cleanRelationData.set = cleanRelationData.set?.slice(-1);
                            }
                            // overwrite all relations
                            relIdsToaddOrMove = toIds(cleanRelationData.set);
                            await deleteRelations({
                                id,
                                attribute,
                                db,
                                relIdsToDelete: 'all',
                                relIdsToNotDelete: relIdsToaddOrMove,
                                transaction: trx
                            });
                            if (isEmpty(cleanRelationData.set)) {
                                continue;
                            }
                            const insert = uniqBy('id', cleanRelationData.set).map((relToAdd)=>({
                                    [joinColumn.name]: id,
                                    [inverseJoinColumn.name]: relToAdd.id,
                                    ...joinTable.on || {},
                                    ...relToAdd.__pivot || {}
                                }));
                            // add order value
                            if (hasOrderColumn(attribute)) {
                                insert.forEach((row, idx)=>{
                                    row[orderColumnName] = idx + 1;
                                });
                            }
                            // add inv order value
                            if (hasInverseOrderColumn(attribute)) {
                                const existingRels = await this.createQueryBuilder(joinTable.name).select(inverseJoinColumn.name).where({
                                    [joinColumn.name]: id,
                                    [inverseJoinColumn.name]: {
                                        $in: relIdsToaddOrMove
                                    }
                                }).where(joinTable.on || {}).transacting(trx).execute();
                                const inverseRelsIds = map(inverseJoinColumn.name, existingRels);
                                const nonExistingRelsIds = difference(relIdsToaddOrMove, inverseRelsIds);
                                const maxResults = await db.getConnection().select(inverseJoinColumn.name).max(inverseOrderColumnName, {
                                    as: 'max'
                                }).whereIn(inverseJoinColumn.name, nonExistingRelsIds).where(joinTable.on || {}).groupBy(inverseJoinColumn.name).from(joinTable.name).transacting(trx);
                                const maxMap = maxResults.reduce((acc, res)=>Object.assign(acc, {
                                        [res[inverseJoinColumn.name]]: res.max
                                    }), {});
                                insert.forEach((row)=>{
                                    row[inverseOrderColumnName] = (maxMap[row[inverseJoinColumn.name]] || 0) + 1;
                                });
                            }
                            // insert rows
                            const query = this.createQueryBuilder(joinTable.name).insert(insert).onConflict(joinTable.pivotColumns).transacting(trx);
                            if (hasOrderColumn(attribute)) {
                                query.merge([
                                    orderColumnName
                                ]);
                            } else {
                                query.ignore();
                            }
                            await query.execute();
                        }
                        // Delete the previous relations for oneToAny relations
                        if (isBidirectional(attribute) && isOneToAny(attribute)) {
                            await deletePreviousOneToAnyRelations({
                                id,
                                attribute,
                                relIdsToadd: relIdsToaddOrMove,
                                db,
                                transaction: trx
                            });
                        }
                        // Delete the previous relations for anyToOne relations
                        if (isAnyToOne(attribute)) {
                            await deletePreviousAnyToOneRelations({
                                id,
                                attribute,
                                relIdToadd: relIdsToaddOrMove[0],
                                db,
                                transaction: trx
                            });
                        }
                    }
                }
            }
        },
        /**
     * Delete relational associations of an existing entity
     * This removes associations but doesn't do cascade deletions for components for example. This will be handled on the entity service layer instead
     * NOTE: Most of the deletion should be handled by ON DELETE CASCADE for dialects that have FKs
     *
     * @param {EntityManager} em - entity manager instance
     * @param {Metadata} metadata - model metadta
     * @param {ID} id - entity ID
     */ async deleteRelations (uid, id, options) {
            const { attributes } = db.metadata.get(uid);
            const { transaction: trx } = options ?? {};
            for (const attributeName of Object.keys(attributes)){
                const attribute = attributes[attributeName];
                if (attribute.type !== 'relation') {
                    continue;
                }
                /*
          if morphOne | morphMany
            if morphBy is morphToOne
              set null
            if morphBy is morphToOne
              delete links
        */ if (attribute.relation === 'morphOne' || attribute.relation === 'morphMany') {
                    const { target, morphBy } = attribute;
                    const targetAttribute = db.metadata.get(target).attributes[morphBy];
                    if (targetAttribute.type === 'relation' && targetAttribute.relation === 'morphToOne') {
                        // set columns
                        const { idColumn, typeColumn } = targetAttribute.morphColumn;
                        await this.createQueryBuilder(target).update({
                            [idColumn.name]: null,
                            [typeColumn.name]: null
                        }).where({
                            [idColumn.name]: id,
                            [typeColumn.name]: uid
                        }).transacting(trx).execute();
                    } else if (targetAttribute.type === 'relation' && targetAttribute.relation === 'morphToMany') {
                        const { joinTable } = targetAttribute;
                        const { morphColumn } = joinTable;
                        const { idColumn, typeColumn } = morphColumn;
                        await this.createQueryBuilder(joinTable.name).delete().where({
                            [idColumn.name]: id,
                            [typeColumn.name]: uid,
                            ...joinTable.on || {},
                            field: attributeName
                        }).transacting(trx).execute();
                    }
                    continue;
                }
                /*
          if morphToOne
            nothing to do
        */ if (attribute.relation === 'morphToOne') ;
                /*
            if morphToMany
            delete links
        */ if (attribute.relation === 'morphToMany') {
                    const { joinTable } = attribute;
                    const { joinColumn } = joinTable;
                    await this.createQueryBuilder(joinTable.name).delete().where({
                        [joinColumn.name]: id,
                        ...joinTable.on || {}
                    }).transacting(trx).execute();
                    continue;
                }
                // do not need to delete links when using foreign keys
                if (db.dialect.usesForeignKeys()) {
                    return;
                }
                // NOTE: we do not remove existing associations with the target as it should handled by unique FKs instead
                if ('joinColumn' in attribute && attribute.joinColumn && attribute.owner) {
                    continue;
                }
                // oneToOne oneToMany on the non owning side.
                if ('joinColumn' in attribute && attribute.joinColumn && !attribute.owner) {
                    // need to set the column on the target
                    const { target } = attribute;
                    await this.createQueryBuilder(target).where({
                        [attribute.joinColumn.referencedColumn]: id
                    }).update({
                        [attribute.joinColumn.referencedColumn]: null
                    }).transacting(trx).execute();
                }
                if ('joinTable' in attribute && attribute.joinTable) {
                    await deleteRelations({
                        id,
                        attribute,
                        db,
                        relIdsToDelete: 'all',
                        transaction: trx
                    });
                }
            }
        },
        // TODO: add lifecycle events
        async populate (uid, entity, populate) {
            const entry = await this.findOne(uid, {
                select: [
                    'id'
                ],
                where: {
                    id: entity.id
                },
                populate
            });
            return {
                ...entity,
                ...entry
            };
        },
        // TODO: add lifecycle events
        async load (uid, entity, fields, populate) {
            const { attributes } = db.metadata.get(uid);
            const fieldsArr = castArray(fields);
            fieldsArr.forEach((field)=>{
                const attribute = attributes[field];
                if (!attribute || attribute.type !== 'relation') {
                    throw new Error(`Invalid load. Expected ${field} to be a relational attribute`);
                }
            });
            const entry = await this.findOne(uid, {
                select: [
                    'id'
                ],
                where: {
                    id: entity.id
                },
                populate: fieldsArr.reduce((acc, field)=>{
                    acc[field] = populate || true;
                    return acc;
                }, {})
            });
            if (!entry) {
                return null;
            }
            if (Array.isArray(fields)) {
                return pick(fields, entry);
            }
            return entry[fields];
        },
        // cascading
        // aggregations
        // -> avg
        // -> min
        // -> max
        // -> grouping
        // formulas
        // custom queries
        // utilities
        // -> map result
        // -> map input
        // extra features
        // -> virtuals
        // -> private
        createQueryBuilder (uid) {
            return createQueryBuilder(uid, db);
        },
        getRepository (uid) {
            if (!repoMap[uid]) {
                repoMap[uid] = createRepository(uid, db);
            }
            return repoMap[uid];
        }
    };
};

const createStorage = (opts)=>{
    const { db, tableName } = opts;
    const hasMigrationTable = ()=>db.getSchemaConnection().hasTable(tableName);
    const createMigrationTable = ()=>{
        return db.getSchemaConnection().createTable(tableName, (table)=>{
            table.increments('id');
            table.string('name');
            table.datetime('time', {
                useTz: false
            });
        });
    };
    return {
        async logMigration ({ name }) {
            await db.getConnection().insert({
                name,
                time: new Date()
            }).into(tableName);
        },
        async unlogMigration ({ name }) {
            await db.getConnection(tableName).del().where({
                name
            });
        },
        async executed () {
            if (!await hasMigrationTable()) {
                await createMigrationTable();
                return [];
            }
            const logs = await db.getConnection(tableName).select().from(tableName).orderBy('time');
            return logs.map((log)=>log.name);
        }
    };
};

const wrapTransaction = (db)=>(fn)=>()=>{
            return db.transaction(({ trx })=>Promise.resolve(fn(trx, db)));
        };

const transformLogMessage = (level, message)=>{
    if (typeof message === 'string') {
        return {
            level,
            message
        };
    }
    if (typeof message === 'object' && message !== null) {
        if ('event' in message && 'name' in message) {
            return {
                level,
                message: `[internal migration]: ${message.event} ${message?.name}`,
                timestamp: Date.now()
            };
        }
    }
    // NOTE: the message typing are too loose so in practice we should never arrive here.
    return '';
};

// TODO: check multiple commands in one sql statement
const migrationResolver = ({ name, path, context })=>{
    const { db } = context;
    if (!path) {
        throw new Error(`Migration ${name} has no path`);
    }
    // if sql file run with knex raw
    if (path.match(/\.sql$/)) {
        const sql = fse.readFileSync(path, 'utf8');
        return {
            name,
            up: wrapTransaction(db)((knex)=>knex.raw(sql)),
            async down () {
                throw new Error('Down migration is not supported for sql files');
            }
        };
    }
    // NOTE: we can add some ts register if we want to handle ts migration files at some point
    // eslint-disable-next-line @typescript-eslint/no-var-requires
    const migration = require(path);
    return {
        name,
        up: wrapTransaction(db)(migration.up),
        down: wrapTransaction(db)(migration.down)
    };
};
const createUserMigrationProvider = (db)=>{
    const dir = db.config.settings.migrations.dir;
    fse.ensureDirSync(dir);
    const context = {
        db
    };
    const umzugProvider = new Umzug({
        storage: createStorage({
            db,
            tableName: 'strapi_migrations'
        }),
        logger: {
            info (message) {
                // NOTE: only log internal migration in debug mode
                db.logger.info(transformLogMessage('info', message));
            },
            warn (message) {
                db.logger.warn(transformLogMessage('warn', message));
            },
            error (message) {
                db.logger.error(transformLogMessage('error', message));
            },
            debug (message) {
                db.logger.debug(transformLogMessage('debug', message));
            }
        },
        context,
        migrations: {
            glob: [
                '*.{js,sql}',
                {
                    cwd: dir
                }
            ],
            resolve: migrationResolver
        }
    });
    return {
        async shouldRun () {
            const pendingMigrations = await umzugProvider.pending();
            return pendingMigrations.length > 0 && db.config?.settings?.runMigrations === true;
        },
        async up () {
            await umzugProvider.up();
        },
        async down () {
            await umzugProvider.down();
        }
    };
};

const QUERIES = {
    async postgres (knex, params) {
        const res = await knex.raw(`
    SELECT :tableName:.id as id, string_agg(DISTINCT :inverseJoinColumn:::character varying, ',') as other_ids
    FROM :tableName:
    LEFT JOIN :joinTableName: ON :tableName:.id = :joinTableName:.:joinColumn:
    WHERE :tableName:.document_id IS NULL
    GROUP BY :tableName:.id, :joinTableName:.:joinColumn:
    LIMIT 1;
  `, params);
        return res.rows;
    },
    async mysql (knex, params) {
        const [res] = await knex.raw(`
    SELECT :tableName:.id as id, group_concat(DISTINCT :inverseJoinColumn:) as other_ids
    FROM :tableName:
    LEFT JOIN :joinTableName: ON :tableName:.id = :joinTableName:.:joinColumn:
    WHERE :tableName:.document_id IS NULL
    GROUP BY :tableName:.id, :joinTableName:.:joinColumn:
    LIMIT 1;
  `, params);
        return res;
    },
    async sqlite (knex, params) {
        return knex.raw(`
    SELECT :tableName:.id as id, group_concat(DISTINCT :inverseJoinColumn:) as other_ids
    FROM :tableName:
    LEFT JOIN :joinTableName: ON :tableName:.id = :joinTableName:.:joinColumn:
    WHERE :tableName:.document_id IS NULL
    GROUP BY :joinTableName:.:joinColumn:
    LIMIT 1;
    `, params);
    }
};
const getNextIdsToCreateDocumentId = async (db, knex, { joinColumn, inverseJoinColumn, tableName, joinTableName })=>{
    const res = await QUERIES[db.dialect.client](knex, {
        joinColumn,
        inverseJoinColumn,
        tableName,
        joinTableName
    });
    if (res.length > 0) {
        const row = res[0];
        const otherIds = row.other_ids ? row.other_ids.split(',').map((v)=>parseInt(v, 10)) : [];
        return [
            row.id,
            ...otherIds
        ];
    }
    return [];
};
// Migrate document ids for tables that have localizations
const migrateDocumentIdsWithLocalizations = async (db, knex, meta)=>{
    const singularName = meta.singularName.toLowerCase();
    const joinColumn = snakeCase(`${singularName}_id`);
    const inverseJoinColumn = snakeCase(`inv_${singularName}_id`);
    let ids;
    do {
        ids = await getNextIdsToCreateDocumentId(db, knex, {
            joinColumn,
            inverseJoinColumn,
            tableName: meta.tableName,
            joinTableName: snakeCase(`${meta.tableName}_localizations_links`)
        });
        if (ids.length > 0) {
            await knex(meta.tableName).update({
                document_id: createId()
            }).whereIn('id', ids);
        }
    }while (ids.length > 0)
};
// Migrate document ids for tables that don't have localizations
const migrationDocumentIds = async (db, knex, meta)=>{
    let updatedRows;
    do {
        updatedRows = await knex(meta.tableName).update({
            document_id: createId()
        }).whereIn('id', knex(meta.tableName).select('id').from(knex(meta.tableName).select('id').whereNull('document_id').limit(1).as('sub_query')));
    }while (updatedRows > 0)
};
const createDocumentIdColumn = async (knex, tableName)=>{
    await knex.schema.alterTable(tableName, (table)=>{
        table.string('document_id');
    });
};
const hasLocalizationsJoinTable = async (knex, tableName)=>{
    const joinTableName = snakeCase(`${tableName}_localizations_links`);
    return knex.schema.hasTable(joinTableName);
};
const createdDocumentId = {
    name: '5.0.0-02-created-document-id',
    async up (knex, db) {
        // do sth
        for (const meta of db.metadata.values()){
            const hasTable = await knex.schema.hasTable(meta.tableName);
            if (!hasTable) {
                continue;
            }
            if ('documentId' in meta.attributes) {
                // add column if doesn't exist
                const hasDocumentIdColumn = await knex.schema.hasColumn(meta.tableName, 'document_id');
                if (hasDocumentIdColumn) {
                    continue;
                }
                await createDocumentIdColumn(knex, meta.tableName);
                if (await hasLocalizationsJoinTable(knex, meta.tableName)) {
                    await migrateDocumentIdsWithLocalizations(db, knex, meta);
                } else {
                    await migrationDocumentIds(db, knex, meta);
                }
            }
        }
    },
    async down () {
        throw new Error('not implemented');
    }
};

const debug = createDebug('strapi::database::migration');
const renameIdentifiersLongerThanMaxLength = {
    name: '5.0.0-rename-identifiers-longer-than-max-length',
    async up (knex, db) {
        const md = db.metadata;
        const diffs = findDiffs(md);
        // migrate indexes before tables so we know to target the original tableName
        for (const indexDiff of diffs.indexes){
            await renameIndex(knex, db, indexDiff);
        }
        // migrate columns before table names so we know to target the original tableName
        for (const columnDiff of diffs.columns){
            const { full, short } = columnDiff;
            const tableName = full.tableName;
            const hasTable = await knex.schema.hasTable(tableName);
            if (hasTable) {
                // tablebuilder methods MUST be synchronous and so you cannot use async inside it, which is why we check the column here
                const hasColumn = await knex.schema.hasColumn(tableName, full.columnName);
                if (hasColumn) {
                    await knex.schema.alterTable(tableName, async (table)=>{
                        debug(`renaming column ${full.columnName} to ${short.columnName}`);
                        table.renameColumn(full.columnName, short.columnName);
                    });
                }
            }
        }
        // migrate table names
        for (const tableDiff of diffs.tables){
            const hasTable = await knex.schema.hasTable(tableDiff.full.tableName);
            if (hasTable) {
                debug(`renaming table ${tableDiff.full.tableName} to ${tableDiff.short.tableName}`);
                await knex.schema.renameTable(tableDiff.full.tableName, tableDiff.short.tableName);
            }
        }
    },
    async down () {
        throw new Error('not implemented');
    }
};
const renameIndex = async (knex, db, diff)=>{
    const client = db.config.connection.client;
    const short = diff.short;
    const full = diff.full;
    if (full.indexName === short.indexName) {
        debug(`not renaming index ${full.indexName} because name hasn't changed`);
        return;
    }
    // fk indexes can't be easily renamed, and will be recreated by db sync
    // if this misses something due to the loose string matching, it's not critical, it just means index will be rebuilt in db sync
    if (short.indexName.endsWith('fk') || full.indexName.endsWith('fk')) {
        return;
    }
    debug(`renaming index from ${full.indexName} to ${short.indexName}`);
    // If schema creation has never actually run before, none of these will exist, and they will throw an error
    // we have no way of running an "if exists" other than a per-dialect manual check, which we won't do
    // because even if it fails for some other reason, the schema sync will recreate them anyway
    // Therefore, we wrap this in a nested transaction (considering we are running this migration in a transaction)
    // so that we can suppress the error
    try {
        await knex.transaction(async (trx)=>{
            if (client === 'mysql' || client === 'mariadb') {
                await knex.raw('ALTER TABLE ?? RENAME INDEX ?? TO ??', [
                    full.tableName,
                    full.indexName,
                    short.indexName
                ]).transacting(trx);
            } else if (client === 'pg' || client === 'postgres') {
                await knex.raw('ALTER INDEX ?? RENAME TO ??', [
                    full.indexName,
                    short.indexName
                ]).transacting(trx);
            } else if ([
                'sqlite',
                'sqlite3',
                'better-sqlite3'
            ].includes(client)) {
                // SQLite doesn't support renaming, so rather than trying to drop/recreate we'll let db sync handle it
                debug(`SQLite does not support index renaming, not renaming index ${full.indexName}`);
            } else {
                debug(`No db client name matches, not renaming index ${full.indexName}`);
            }
        });
    } catch (err) {
        debug(`error creating index: ${JSON.stringify(err)}`);
    }
};
const findDiffs = (shortMap)=>{
    const diffs = {
        tables: [],
        columns: [],
        indexes: []
    };
    const shortArr = Array.from(shortMap.entries());
    shortArr.forEach(([, shortObj], index)=>{
        const fullTableName = identifiers.getUnshortenedName(shortObj.tableName);
        if (!fullTableName) {
            throw new Error(`Missing full table name for ${shortObj.tableName}`);
        }
        // find table name diffs
        if (shortObj.tableName !== fullTableName) {
            diffs.tables.push({
                full: {
                    index,
                    key: 'tableName',
                    tableName: fullTableName
                },
                short: {
                    index,
                    key: 'tableName',
                    tableName: shortObj.tableName
                }
            });
        }
        // find column name diffs
        // eslint-disable-next-line guard-for-in
        for(const attrKey in shortObj.attributes){
            if (shortObj.attributes[attrKey].type === 'relation') {
                continue;
            }
            // TODO: add more type checks so we don't need any
            const attr = shortObj.attributes[attrKey];
            const shortColumnName = attr.columnName;
            const longColumnName = identifiers.getUnshortenedName(shortColumnName);
            if (!shortColumnName || !longColumnName) {
                throw new Error(`missing column name(s) for attribute ${JSON.stringify(attr, null, 2)}`);
            }
            if (shortColumnName && longColumnName && shortColumnName !== longColumnName) {
                diffs.columns.push({
                    short: {
                        index,
                        tableName: fullTableName,
                        key: `attributes.${attrKey}`,
                        columnName: shortColumnName
                    },
                    full: {
                        index,
                        tableName: fullTableName,
                        key: `attributes.${attrKey}`,
                        columnName: longColumnName
                    }
                });
            }
        }
        // find index name diffs
        // eslint-disable-next-line guard-for-in
        for(const attrKey in shortObj.indexes){
            const shortIndexName = shortObj.indexes[attrKey].name;
            const longIndexName = identifiers.getUnshortenedName(shortIndexName);
            if (!longIndexName) {
                throw new Error(`Missing full index name for ${shortIndexName}`);
            }
            if (shortIndexName && longIndexName && shortIndexName !== longIndexName) {
                diffs.indexes.push({
                    short: {
                        index,
                        tableName: fullTableName,
                        key: `indexes.${attrKey}`,
                        indexName: shortIndexName
                    },
                    full: {
                        index,
                        tableName: fullTableName,
                        key: `indexes.${attrKey}`,
                        indexName: longIndexName
                    }
                });
            }
        }
    });
    return diffs;
};

/**
 * In v4, content types with disabled i18n did not have any locale column.
 * In v5, we need to add a `locale` column to all content types.
 * Other downstream migrations will make use of this column.
 *
 * This function creates the `locale` column if it doesn't exist.
 */ const createLocaleColumn = async (db, tableName)=>{
    await db.schema.alterTable(tableName, (table)=>{
        table.string('locale');
    });
};
const createdLocale = {
    name: '5.0.0-03-created-locale',
    async up (knex, db) {
        for (const meta of db.metadata.values()){
            const hasTable = await knex.schema.hasTable(meta.tableName);
            if (!hasTable) {
                continue;
            }
            // Ignore non-content types
            const uid = meta.uid;
            const model = strapi.getModel(uid);
            if (!model) {
                continue;
            }
            // Create locale column if it doesn't exist
            const hasLocaleColumn = await knex.schema.hasColumn(meta.tableName, 'locale');
            if (meta.attributes.locale && !hasLocaleColumn) {
                await createLocaleColumn(knex, meta.tableName);
            }
        }
    },
    async down () {
        throw new Error('not implemented');
    }
};

/**
 * In v4, content types with disabled D&P did not have any `published_at` column.
 * In v5, we need to add a `published_at` column to all content types.
 * Other downstream migrations will make use of this column.
 *
 * This function creates the `published_at` column if it doesn't exist.
 */ const createPublishedAtColumn = async (db, tableName)=>{
    await db.schema.alterTable(tableName, (table)=>{
        table.string('published_at');
    });
    // Non DP content types should have their `published_at` column set to a date
    await db(tableName).update({
        published_at: new Date()
    });
};
const createdPublishedAt = {
    name: '5.0.0-04-created-published-at',
    async up (knex, db) {
        for (const meta of db.metadata.values()){
            const hasTable = await knex.schema.hasTable(meta.tableName);
            if (!hasTable) {
                continue;
            }
            // Ignore non-content types
            const uid = meta.uid;
            const model = strapi.getModel(uid);
            if (!model) {
                continue;
            }
            // Create publishedAt column if it doesn't exist
            const hasPublishedAtColumn = await knex.schema.hasColumn(meta.tableName, 'published_at');
            if (meta.attributes.publishedAt && !hasPublishedAtColumn) {
                await createPublishedAtColumn(knex, meta.tableName);
            }
        }
    },
    async down () {
        throw new Error('not implemented');
    }
};

/**
 * In V4 slug fields contained a unique index.
 * In V5 slug fields should not have a unique index.
 *
 * This migration drops existing unique indexes from slug fields so downstream migrations
 * can work on the data without violating the unique index.
 */ const dropIndex = async (knex, tableName, columnName)=>{
    try {
        await knex.schema.alterTable(tableName, (table)=>{
            // NOTE: Can not use "identifiers" utility, as the 5.0.0-01 migration does not rename this particular index
            // to `tableName_columnName_uq`.
            table.dropUnique([
                columnName
            ], `${tableName}_${columnName}_unique`);
        });
    } catch (error) {
    // If unique index does not exist, do nothing
    }
};
const dropSlugFieldsIndex = {
    name: '5.0.0-05-drop-slug-fields-index',
    async up (knex, db) {
        for (const meta of db.metadata.values()){
            const hasTable = await knex.schema.hasTable(meta.tableName);
            if (!hasTable) {
                continue;
            }
            for (const attribute of Object.values(meta.attributes)){
                if (attribute.type === 'uid' && attribute.columnName) {
                    await dropIndex(knex, meta.tableName, attribute.columnName);
                }
            }
        }
    },
    async down () {
        throw new Error('not implemented');
    }
};

/**
 * List of all the internal migrations. The array order will be the order in which they are executed.
 *
 * {
 *   name: 'some-name',
 *   async up(knex: Knex, db: Database) {},
 *   async down(knex: Knex, db: Database) {},
 * },
 */ const internalMigrations = [
    renameIdentifiersLongerThanMaxLength,
    createdDocumentId,
    createdLocale,
    createdPublishedAt,
    dropSlugFieldsIndex
];

const createInternalMigrationProvider = (db)=>{
    const context = {
        db
    };
    const migrations = [
        ...internalMigrations
    ];
    const umzugProvider = new Umzug({
        storage: createStorage({
            db,
            tableName: 'strapi_migrations_internal'
        }),
        logger: {
            info (message) {
                // NOTE: only log internal migration in debug mode
                db.logger.debug(transformLogMessage('info', message));
            },
            warn (message) {
                db.logger.warn(transformLogMessage('warn', message));
            },
            error (message) {
                db.logger.error(transformLogMessage('error', message));
            },
            debug (message) {
                db.logger.debug(transformLogMessage('debug', message));
            }
        },
        context,
        migrations: ()=>migrations.map((migration)=>{
                return {
                    name: migration.name,
                    up: wrapTransaction(context.db)(migration.up),
                    down: wrapTransaction(context.db)(migration.down)
                };
            })
    });
    return {
        async register (migration) {
            migrations.push(migration);
        },
        async shouldRun () {
            const pendingMigrations = await umzugProvider.pending();
            return pendingMigrations.length > 0;
        },
        async up () {
            await umzugProvider.up();
        },
        async down () {
            await umzugProvider.down();
        }
    };
};

const createMigrationsProvider = (db)=>{
    const userProvider = createUserMigrationProvider(db);
    const internalProvider = createInternalMigrationProvider(db);
    const providers = [
        userProvider,
        internalProvider
    ];
    return {
        providers: {
            internal: internalProvider
        },
        async shouldRun () {
            const shouldRunResponses = await Promise.all(providers.map((provider)=>provider.shouldRun()));
            return shouldRunResponses.some((shouldRun)=>shouldRun);
        },
        async up () {
            for (const provider of providers){
                if (await provider.shouldRun()) {
                    await provider.up();
                }
            }
        },
        async down () {
            for (const provider of providers){
                if (await provider.shouldRun()) {
                    await provider.down();
                }
            }
        }
    };
};

/**
 * For each model try to run it's lifecycles function if any is defined
 */ const modelsLifecyclesSubscriber = async (event)=>{
    const { model } = event;
    if (model.lifecycles && event.action in model.lifecycles) {
        await model.lifecycles[event.action]?.(event);
    }
};

// NOTE: we could add onCreate & onUpdate on field level to do this instead
const timestampsLifecyclesSubscriber = {
    /**
   * Init createdAt & updatedAt before create
   */ beforeCreate (event) {
        const { data } = event.params;
        const now = new Date();
        _$1.defaults(data, {
            createdAt: now,
            updatedAt: now
        });
    },
    /**
   * Init createdAt & updatedAt before create
   * @param {Event} event
   */ beforeCreateMany (event) {
        const { data } = event.params;
        const now = new Date();
        if (_$1.isArray(data)) {
            data.forEach((data)=>_$1.defaults(data, {
                    createdAt: now,
                    updatedAt: now
                }));
        }
    },
    /**
   * Update updatedAt before update
   * @param {Event} event
   */ beforeUpdate (event) {
        const { data } = event.params;
        const now = new Date();
        _$1.assign(data, {
            updatedAt: now
        });
    },
    /**
   * Update updatedAt before update
   * @param {Event} event
   */ beforeUpdateMany (event) {
        const { data } = event.params;
        const now = new Date();
        if (_$1.isArray(data)) {
            data.forEach((data)=>_$1.assign(data, {
                    updatedAt: now
                }));
        }
    }
};

const isValidSubscriber = (subscriber)=>{
    return typeof subscriber === 'function' || typeof subscriber === 'object' && subscriber !== null;
};

const createLifecyclesProvider = (db)=>{
    let subscribers = [
        timestampsLifecyclesSubscriber,
        modelsLifecyclesSubscriber
    ];
    let isLifecycleHooksDisabled = false;
    return {
        subscribe (subscriber) {
            strict(isValidSubscriber(subscriber), 'Invalid subscriber. Expected function or object');
            subscribers.push(subscriber);
            return ()=>subscribers.splice(subscribers.indexOf(subscriber), 1);
        },
        clear () {
            subscribers = [];
        },
        disable () {
            isLifecycleHooksDisabled = true;
        },
        enable () {
            isLifecycleHooksDisabled = false;
        },
        createEvent (action, uid, properties, state) {
            const model = db.metadata.get(uid);
            return {
                action,
                model,
                state,
                ...properties
            };
        },
        /**
     * @param {string} action
     * @param {string} uid
     * @param {{ params?: any, result?: any }} properties
     * @param {Map<any, any>} states
     */ async run (action, uid, properties, states = new Map()) {
            if (isLifecycleHooksDisabled) return states;
            for(let i = 0; i < subscribers.length; i += 1){
                const subscriber = subscribers[i];
                if (typeof subscriber === 'function') {
                    const state = states.get(subscriber) || {};
                    const event = this.createEvent(action, uid, properties, state);
                    await subscriber(event);
                    if (event.state) {
                        states.set(subscriber, event.state || state);
                    }
                    continue;
                }
                const hasAction = action in subscriber;
                const hasModel = !subscriber.models || subscriber.models.includes(uid);
                if (hasAction && hasModel) {
                    const state = states.get(subscriber) || {};
                    const event = this.createEvent(action, uid, properties, state);
                    await subscriber[action]?.(event);
                    if (event.state) {
                        states.set(subscriber, event.state);
                    }
                }
            }
            return states;
        }
    };
};

const clientMap = {
    sqlite: 'better-sqlite3',
    mysql: 'mysql2',
    postgres: 'pg'
};
function isClientValid(config) {
    return Object.keys(clientMap).includes(config.client);
}
const createConnection = (userConfig, strapiConfig)=>{
    if (!isClientValid(userConfig)) {
        throw new Error(`Unsupported database client ${userConfig.client}`);
    }
    const knexConfig = {
        ...userConfig,
        client: clientMap[userConfig.client]
    };
    // initialization code to run upon opening a new connection
    if (strapiConfig?.pool?.afterCreate) {
        knexConfig.pool = knexConfig.pool || {};
        // if the user has set their own afterCreate in config, we will replace it and call it
        const userAfterCreate = knexConfig.pool?.afterCreate;
        const strapiAfterCreate = strapiConfig.pool.afterCreate;
        knexConfig.pool.afterCreate = (conn, done)=>{
            strapiAfterCreate(conn, (err, nativeConn)=>{
                if (err) {
                    return done(err, nativeConn);
                }
                if (userAfterCreate) {
                    return userAfterCreate(nativeConn, done);
                }
                return done(null, nativeConn);
            });
        };
    }
    return knex(knexConfig);
};

const getLinksWithoutMappedBy = (db)=>{
    const relationsToUpdate = {};
    db.metadata.forEach((modelMetadata)=>{
        const attributes = modelMetadata.attributes;
        // For each relation attribute, add the joinTable name to tablesToUpdate
        Object.values(attributes).forEach((attribute)=>{
            if (attribute.type !== 'relation') {
                return;
            }
            if ('inversedBy' in attribute && attribute.inversedBy) {
                const invRelation = db.metadata.get(attribute.target).attributes[attribute.inversedBy];
                // Both relations use inversedBy.
                if ('inversedBy' in invRelation && invRelation.inversedBy) {
                    relationsToUpdate[attribute.joinTable.name] = {
                        relation: attribute,
                        invRelation: invRelation
                    };
                }
            }
        });
    });
    return Object.values(relationsToUpdate);
};
const isLinkTableEmpty = async (db, linkTableName)=>{
    // If the table doesn't exist, it's empty
    const exists = await db.getSchemaConnection().hasTable(linkTableName);
    if (!exists) return true;
    const result = await db.getConnection().from(linkTableName).count('* as count');
    return Number(result[0].count) === 0;
};
/**
 * Validates bidirectional relations before starting the server.
 * - If both sides use inversedBy, one of the sides must switch to mappedBy.
 *    When this happens, two join tables exist in the database.
 *    This makes sure you switch the side which does not delete any data.
 *
 * @param {*} db
 * @return {*}
 */ const validateBidirectionalRelations = async (db)=>{
    const invalidLinks = getLinksWithoutMappedBy(db);
    for (const { relation, invRelation } of invalidLinks){
        const modelMetadata = db.metadata.get(invRelation.target);
        const invModelMetadata = db.metadata.get(relation.target);
        // Generate the join table name based on the relation target table and attribute name.
        const joinTableName = identifiers.getJoinTableName(snakeCase(modelMetadata.tableName), snakeCase(invRelation.inversedBy));
        const inverseJoinTableName = identifiers.getJoinTableName(snakeCase(invModelMetadata.tableName), snakeCase(relation.inversedBy));
        const joinTableEmpty = await isLinkTableEmpty(db, joinTableName);
        const inverseJoinTableEmpty = await isLinkTableEmpty(db, inverseJoinTableName);
        if (joinTableEmpty) {
            process.emitWarning(`Error on attribute "${invRelation.inversedBy}" in model "${modelMetadata.singularName}" (${modelMetadata.uid}).` + ` Please modify your ${modelMetadata.singularName} schema by renaming the key "inversedBy" to "mappedBy".` + ` Ex: { "inversedBy": "${relation.inversedBy}" } -> { "mappedBy": "${relation.inversedBy}" }`);
        } else if (inverseJoinTableEmpty) {
            // Its safe to delete the inverse join table
            process.emitWarning(`Error on attribute "${relation.inversedBy}" in model "${invModelMetadata.singularName}" (${invModelMetadata.uid}).` + ` Please modify your ${invModelMetadata.singularName} schema by renaming the key "inversedBy" to "mappedBy".` + ` Ex: { "inversedBy": "${invRelation.inversedBy}" } -> { "mappedBy": "${invRelation.inversedBy}" }`);
        } else ;
    }
};

/**
 * Validates if relations data and tables are in a valid state before
 * starting the server.
 */ const validateRelations = async (db)=>{
    await validateBidirectionalRelations(db);
};

/**
 * Validate if the database is in a valid state before starting the server.
 */ async function validateDatabase(db) {
    await validateRelations(db);
}

const isMorphRelationWithPivot = (attribute, pivot)=>{
    return attribute.type === 'relation' && 'relation' in attribute && 'joinTable' in attribute && 'name' in attribute.joinTable && 'pivotColumns' in attribute.joinTable && attribute.joinTable.pivotColumns.includes(pivot);
};
const filterMorphRelationalAttributes = (attributes, pivot)=>{
    return Object.values(attributes).filter((attribute)=>isMorphRelationWithPivot(attribute, pivot));
};
/**
 * Removes morph relation data with invalid or non-existent morph type.
 *
 * This function iterates over the database metadata to identify morph relationships
 * (relations with a `joinTable` containing the specified pivot column) and removes
 * any entries in the relation's join table where the morph type is invalid.
 *
 * Note: This function does not check for orphaned IDs, only orphaned morph types.
 *
 * @param db - The database object containing metadata and a Knex connection.
 * @param options.pivot - The name of the column in the join table representing the morph type.
 */ const removeOrphanMorphType = async (db, { pivot })=>{
    db.logger.debug(`Removing orphaned morph type: ${JSON.stringify(pivot)}`);
    const mdValues = db.metadata.values();
    for (const model of mdValues){
        const attributes = filterMorphRelationalAttributes(model.attributes || {}, pivot);
        for (const attribute of attributes){
            const joinTableName = attribute.joinTable.name;
            // Query distinct morph types from the join table
            const morphTypes = await db.connection(joinTableName).distinct(pivot).pluck(pivot);
            for (const morphType of morphTypes){
                // Check if metadata for the morph type exists
                const deleteComponentType = await (async ()=>{
                    try {
                        return !db.metadata.get(morphType); // If no metadata found, mark for deletion
                    } catch  {
                        db.logger.debug(`Metadata for morph type "${morphType}" in table "${joinTableName}" not found`);
                        return true; // Return true to delete if metadata is missing
                    }
                })();
                if (deleteComponentType) {
                    db.logger.debug(`Removing invalid morph type "${morphType}" from table "${joinTableName}".`);
                    try {
                        await db.connection(joinTableName).where(pivot, morphType).del();
                    } catch (error) {
                        const errorMessage = error instanceof Error ? error.message : String(error);
                        db.logger.error(`Failed to remove invalid morph type "${morphType}" from table "${joinTableName}": ${errorMessage}`);
                    }
                }
            }
        }
    }
};

// lodash/fp curry does not handle async functions properly, and creates very "ugly" types,
// so we will use our own version to ensure curried functions are typed correctly
// TODO: Export this from root @strapi/utils so we don't have copies of it between packages
/**
 * @internal
 */ const asyncCurry = (fn)=>{
    const curried = (...args)=>{
        if (args.length >= fn.length) {
            return fn(...args);
        }
        return (...moreArgs)=>curried(...args, ...moreArgs);
    };
    return curried;
};

const createRepairManager = (db)=>{
    return {
        removeOrphanMorphType: asyncCurry(removeOrphanMorphType)(db)
    };
};

const afterCreate = (db)=>(nativeConnection, done)=>{
        // run initialize for it since commands such as postgres SET and sqlite PRAGMA are per-connection
        db.dialect.initialize(nativeConnection).then(()=>{
            return done(null, nativeConnection);
        });
    };
class Database {
    async init({ models }) {
        if (typeof this.config.connection.connection === 'function') {
            /*
       * User code needs to be able to access `connection.connection` directly as if
       * it were always an object. For a connection function, that doesn't happen
       * until the pool is created, so we need to do that here
       *
       * TODO: In the next major version, we need to replace all internal code that
       * directly references `connection.connection` prior to init, and make a breaking
       * change that it cannot be relied on to exist before init so that we can call
       * this feature stable.
       */ this.logger.debug('Forcing Knex to make real connection to db');
            // sqlite does not support connection pooling so acquireConnection doesn't work
            if (this.config.connection.client === 'sqlite') {
                await this.connection.raw('SELECT 1');
            } else {
                await this.connection.client.acquireConnection();
            }
        }
        this.metadata.loadModels(models);
        await validateDatabase(this);
        return this;
    }
    query(uid) {
        if (!this.metadata.has(uid)) {
            throw new Error(`Model ${uid} not found`);
        }
        return this.entityManager.getRepository(uid);
    }
    inTransaction() {
        return !!transactionCtx.get();
    }
    async transaction(cb) {
        const notNestedTransaction = !transactionCtx.get();
        const trx = notNestedTransaction ? await this.connection.transaction() : transactionCtx.get();
        async function commit() {
            if (notNestedTransaction) {
                await transactionCtx.commit(trx);
            }
        }
        async function rollback() {
            if (notNestedTransaction) {
                await transactionCtx.rollback(trx);
            }
        }
        if (!cb) {
            return {
                commit,
                rollback,
                get: ()=>trx
            };
        }
        return transactionCtx.run(trx, async ()=>{
            try {
                const callbackParams = {
                    trx,
                    commit,
                    rollback,
                    onCommit: transactionCtx.onCommit,
                    onRollback: transactionCtx.onRollback
                };
                const res = await cb(callbackParams);
                await commit();
                return res;
            } catch (error) {
                await rollback();
                throw error;
            }
        });
    }
    getSchemaName() {
        return this.connection.client.connectionSettings.schema;
    }
    getConnection(tableName) {
        const schema = this.getSchemaName();
        const connection = tableName ? this.connection(tableName) : this.connection;
        return schema ? connection.withSchema(schema) : connection;
    }
    // Returns basic info about the database connection
    getInfo() {
        const connectionSettings = this.connection?.client?.connectionSettings || {};
        const client = this.dialect?.client || '';
        let displayName = '';
        let schema;
        // For SQLite, get the relative filename
        if (client === 'sqlite') {
            const absolutePath = connectionSettings?.filename;
            if (absolutePath) {
                displayName = path$1.relative(process.cwd(), absolutePath);
            }
        } else {
            displayName = connectionSettings?.database;
            schema = connectionSettings?.schema;
        }
        return {
            displayName,
            schema,
            client
        };
    }
    getSchemaConnection(trx = this.connection) {
        const schema = this.getSchemaName();
        return schema ? trx.schema.withSchema(schema) : trx.schema;
    }
    queryBuilder(uid) {
        return this.entityManager.createQueryBuilder(uid);
    }
    async destroy() {
        await this.lifecycles.clear();
        await this.connection.destroy();
    }
    constructor(config){
        this.config = {
            ...config,
            settings: {
                forceMigration: true,
                runMigrations: true,
                ...config.settings ?? {}
            }
        };
        this.logger = config.logger ?? console;
        this.dialect = getDialect(this);
        let knexConfig = this.config.connection;
        // for object connections, we can configure the dialect synchronously
        if (typeof this.config.connection.connection !== 'function') {
            this.dialect.configure();
        } else {
            this.logger.warn('Knex connection functions are currently experimental. Attempting to access the connection object before database initialization will result in errors.');
            knexConfig = {
                ...this.config.connection,
                connection: async ()=>{
                    // @ts-expect-error confirmed it was a function above
                    const conn = await this.config.connection.connection();
                    this.dialect.configure(conn);
                    return conn;
                }
            };
        }
        this.metadata = createMetadata([]);
        this.connection = createConnection(knexConfig, {
            pool: {
                afterCreate: afterCreate(this)
            }
        });
        this.schema = createSchemaProvider(this);
        this.migrations = createMigrationsProvider(this);
        this.lifecycles = createLifecyclesProvider(this);
        this.entityManager = createEntityManager(this);
        this.repair = createRepairManager(this);
    }
}

export { Database, index as errors, isKnexQuery };
//# sourceMappingURL=index.mjs.map
